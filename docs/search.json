[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vers une mesure continue du Genre: quels enjeux pour l’analyse économique?",
    "section": "",
    "text": "Introduction\nTRAVAIL EN COURS\nAvec ses cheveux courts, lors de son élection, miss France 2024 a défrayé la chronique.\nAu vue des réactions épidermiques, la dunkerquoise Eve Gilles semblait transgresser là une norme de genre instituée.\nAvec cet exemple, qui peut sembler trivial, nous souhaitons aborder la question fondamentale de l’identité, et plus spécifiquement, de l’identité de genre.\nL’identité peut être définie comme le sentiment que l’on a de soi (“A person’ sense of self”) , c’est une notion multiple, protéiforme, difficile à appréhender et plus encore: à mesurer.\nMais pourquoi les économistes devraient-ils s’intéresser à cette variable identité?\nComment et pourquoi intègrent-ils cette notion dans leurs modèles?\nSi la nécessité de proposer des modèles intégrant cette variable nous semble pertinente, vient alors la question de la difficile mesure de ce concept fondamental.\nEnfin, quelles répercussions socio-économiques peut-on observer à travers la mise en lien de cette mesure de l’identité et des variables économiques?",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "construction_indice.html",
    "href": "construction_indice.html",
    "title": "1  Notre Mesure: Le Cultural Gender Normativity Index (CGNI)",
    "section": "",
    "text": "1.1 Indice Alternatif: Méthode de LASSO\ncode R\nsummary(my_data_frame$Library)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  1.0000  1.0000  0.8347  1.0000  1.0000 \n\n\ncode R\nmy_data_frame$SEXE&lt;-as.factor(my_data_frame$SEXE)\nreg_lm&lt;- lm(Sex~ Knitting+ \n                  Cards_games+  \n                  Gambling+ \n                  Cooking+ \n                  DIY+\n                  Vegetable_garden+ \n                  Ornamental_garden+  \n                  Fishing_hunting+ \n                  Collection+\n                  Vehicle_custom + \n                  Making_music +\n                  Diary +\n                  Writing +  \n                  Painting +  \n                  Montage + \n                  Circus +\n                  Pottery + \n                  Theater + \n                  Drawing + \n                  Dancing +  \n                  Photography +\n                  Genealogy + \n                  Science +\n                  None +\n                  No_Amateur +\n                  Video_games +\n                  TV +\n                  Radio+\n                  Library+\n                  Museums +  \n                  Internet + \n                  Concert, data=my_data_frame)\n\n\n\nn &lt;- nrow(my_data_frame)\n\n# Indices pour la division (2/3 pour l'entraînement, 1/3 pour le test)\ntrain_index &lt;- sample(1:n, size = 2 * n / 3)  # 2/3 des indices pour l'entraînement\n\n# Créer l'ensemble d'entraînement et l'ensemble de test\ntrain_data &lt;- my_data_frame[train_index, ]  # Enregistrement d'entraînement\ntest_data &lt;- my_data_frame[-train_index, ]  # Enregistrement de test\n\n# Vérifier les tailles\ncat(\"Nombre d'observations dans l'ensemble d'entraînement :\", nrow(train_data), \"\\n\")\n\n\nNombre d'observations dans l'ensemble d'entraînement : 6156 \n\n\ncode R\ncat(\"Nombre d'observations dans l'ensemble de test :\", nrow(test_data), \"\\n\")\n\n\nNombre d'observations dans l'ensemble de test : 3078 \n\n\ncode R\n# Charger les bibliothèques nécessaires\nlibrary(glmnet)\nlibrary(pROC)\n\n# Définir la matrice X pour l'entraînement\nx &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Ornamental_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage + Circus + Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + No_Amateur +\n                  Video_games + TV + Radio + Library + Museums + Internet + Concert,\n                  train_data)[, -1]\n\n# Variable cible y pour l'entraînement\ny &lt;- train_data$SEXE\n\n# Ajuster le modèle LASSO avec validation croisée\ncv_lasso &lt;- cv.glmnet(x, y, alpha = 1, family = \"binomial\")\nbest_lambda &lt;- cv_lasso$lambda.min  # Lambda optimal\n\n# Vérifie les coefficients pour le lambda optimal\nprint(coef(cv_lasso, s = \"lambda.min\"))\n\n\n33 x 1 sparse Matrix of class \"dgCMatrix\"\n                             s1\n(Intercept)       -5.521795e-01\nKnitting           2.882558e+00\nCards_games        2.349254e-01\nGambling          -3.337312e-01\nCooking            1.162588e+00\nDIY               -1.086545e+00\nVegetable_garden  -3.464071e-01\nOrnamental_garden  3.256615e-01\nFishing_hunting   -1.450190e+00\nCollection        -5.394222e-01\nVehicle_custom    -1.510231e+00\nMaking_music      -1.484874e-01\nDiary              1.379585e+00\nWriting            .           \nPainting           4.704994e-01\nMontage           -9.872001e-01\nCircus             .           \nPottery            4.123501e-01\nTheater           -8.086209e-02\nDrawing           -2.584548e-02\nDancing            1.596506e+00\nPhotography       -4.617016e-01\nGenealogy         -2.927618e-01\nScience           -6.851022e-01\nNone              -9.890995e-02\nNo_Amateur         3.514798e-01\nVideo_games       -1.754886e-01\nTV                 4.929155e-01\nRadio             -1.240134e-01\nLibrary           -9.026366e-16\nMuseums           -1.205780e-01\nInternet           1.147213e-01\nConcert            8.777883e-02\n\n\ncode R\nprint(best_lambda)\n\n\n[1] 0.001109779\n\n\ncode R\n# Préparer X_test (même traitement que pour l'entraînement)\nx_test &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                       Vegetable_garden + Ornamental_garden + Fishing_hunting + \n                       Collection + Vehicle_custom + Making_music + Diary + Writing + \n                       Painting + Montage + Circus + Pottery + Theater + Drawing + \n                       Dancing + Photography + Genealogy + Science + None + No_Amateur +\n                       Video_games + TV + Radio + Library + Museums + Internet + Concert,\n                       test_data)[, -1]\n\n# Prédire les probabilités sur les données de test avec le meilleur lambda\npreds &lt;- predict(cv_lasso, newx = x_test, s = \"lambda.min\", type = \"response\")\n\n# Variable cible y_test pour l'ensemble de test\ny_test &lt;- test_data$SEXE\n\n# Calcul de l'AUC avec pROC\nroc_curve &lt;- roc(y_test, preds)\nauc_value &lt;- auc(roc_curve)\nprint(paste(\"AUC:\", auc_value))\n\n\n[1] \"AUC: 0.873070159752027\"\n\n\ncode R\n# Calculer la courbe ROC\nroc_curve &lt;- roc(y_test, preds)\n\n# Afficher la courbe ROC\nplot(roc_curve, main = \"Courbe ROC\", col = \"blue\", lwd = 2)\n\n# Optionnel : Ajouter la ligne de base (diagonale)\nabline(a = 0, b = 1, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n\n\ncode R\n# Afficher les coefficients pour le meilleur lambda\ncoefficients &lt;- coef(cv_lasso, s = \"lambda.min\")\n\n# Convertir en data.frame pour une meilleure lisibilité\ncoefficients_df &lt;- as.data.frame(as.matrix(coefficients))\ncolnames(coefficients_df) &lt;- \"Coefficient\"\ncoefficients_df$Variable &lt;- rownames(coefficients_df)\n\n# Filtrer pour ne garder que les variables avec des coefficients non nuls\ncoefficients_non_zero &lt;- coefficients_df[coefficients_df$Coefficient != 0, ]\n\n# Afficher les variables gardées et leurs coefficients\nprint(coefficients_non_zero)\n\n\n                    Coefficient          Variable\n(Intercept)       -5.521795e-01       (Intercept)\nKnitting           2.882558e+00          Knitting\nCards_games        2.349254e-01       Cards_games\nGambling          -3.337312e-01          Gambling\nCooking            1.162588e+00           Cooking\nDIY               -1.086545e+00               DIY\nVegetable_garden  -3.464071e-01  Vegetable_garden\nOrnamental_garden  3.256615e-01 Ornamental_garden\nFishing_hunting   -1.450190e+00   Fishing_hunting\nCollection        -5.394222e-01        Collection\nVehicle_custom    -1.510231e+00    Vehicle_custom\nMaking_music      -1.484874e-01      Making_music\nDiary              1.379585e+00             Diary\nPainting           4.704994e-01          Painting\nMontage           -9.872001e-01           Montage\nPottery            4.123501e-01           Pottery\nTheater           -8.086209e-02           Theater\nDrawing           -2.584548e-02           Drawing\nDancing            1.596506e+00           Dancing\nPhotography       -4.617016e-01       Photography\nGenealogy         -2.927618e-01         Genealogy\nScience           -6.851022e-01           Science\nNone              -9.890995e-02              None\nNo_Amateur         3.514798e-01        No_Amateur\nVideo_games       -1.754886e-01       Video_games\nTV                 4.929155e-01                TV\nRadio             -1.240134e-01             Radio\nLibrary           -9.026366e-16           Library\nMuseums           -1.205780e-01           Museums\nInternet           1.147213e-01          Internet\nConcert            8.777883e-02           Concert\n\n\ncode R\n###CREATION INDICE\n\n# Récupérer les coefficients du modèle pour le meilleur lambda\ncoefficients &lt;- coef(cv_lasso, s = \"lambda.min\")\n\n# Convertir en data.frame et filtrer les variables non nulles\ncoefficients_df &lt;- as.data.frame(as.matrix(coefficients))\ncolnames(coefficients_df) &lt;- \"Coefficient\"\ncoefficients_df$Variable &lt;- rownames(coefficients_df)\ncoefficients_non_zero &lt;- coefficients_df[coefficients_df$Coefficient != 0, ]\n\n# Préparer la matrice X des pratiques pour l'ensemble de test (ou d'entraînement si nécessaire)\nx_test &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                       Vegetable_garden + Ornamental_garden + Fishing_hunting + \n                       Collection + Vehicle_custom + Making_music + Diary + Writing + \n                       Painting + Montage + Circus + Pottery + Theater + Drawing + \n                       Dancing + Photography + Genealogy + Science + None + No_Amateur +\n                       Video_games + TV + Radio + Library + Museums + Internet + Concert,\n                       test_data)[, -1]  # Assurez-vous d'enlever l'intercept avec [, -1]\n\n# Sélectionner les variables pertinentes\nmatched_vars &lt;- intersect(rownames(coefficients_non_zero), colnames(x_test))\nx_test &lt;- x_test[, matched_vars, drop = FALSE]\ncoef_vector &lt;- coefficients_non_zero$Coefficient[matched_vars]  # Associer les coefficients\n\nprint(paste(\"Dimension de x_test :\", dim(x_test)[1], \"x\", dim(x_test)[2]))\n\n\n[1] \"Dimension de x_test : 3078 x 30\"\n\n\ncode R\nprint(paste(\"Longueur de coef_vector :\", length(coef_vector)))\n\n\n[1] \"Longueur de coef_vector : 30\"\n\n\ncode R\nprint(paste(\"Nombre de valeurs NA dans x_test :\", sum(is.na(x_test))))\n\n\n[1] \"Nombre de valeurs NA dans x_test : 0\"\n\n\ncode R\nprint(paste(\"Nombre de valeurs NA dans coef_vector :\", sum(is.na(coef_vector))))\n\n\n[1] \"Nombre de valeurs NA dans coef_vector : 30\"\n\n\ncode R\nprint(\"Variables dans coefficients_non_zero :\")\n\n\n[1] \"Variables dans coefficients_non_zero :\"\n\n\ncode R\nprint(coefficients_non_zero$Variable)\n\n\n [1] \"(Intercept)\"       \"Knitting\"          \"Cards_games\"      \n [4] \"Gambling\"          \"Cooking\"           \"DIY\"              \n [7] \"Vegetable_garden\"  \"Ornamental_garden\" \"Fishing_hunting\"  \n[10] \"Collection\"        \"Vehicle_custom\"    \"Making_music\"     \n[13] \"Diary\"             \"Painting\"          \"Montage\"          \n[16] \"Pottery\"           \"Theater\"           \"Drawing\"          \n[19] \"Dancing\"           \"Photography\"       \"Genealogy\"        \n[22] \"Science\"           \"None\"              \"No_Amateur\"       \n[25] \"Video_games\"       \"TV\"                \"Radio\"            \n[28] \"Library\"           \"Museums\"           \"Internet\"         \n[31] \"Concert\"          \n\n\ncode R\nprint(\"Colonnes de x_test :\")\n\n\n[1] \"Colonnes de x_test :\"\n\n\ncode R\nprint(colnames(x_test))\n\n\n [1] \"Knitting\"          \"Cards_games\"       \"Gambling\"         \n [4] \"Cooking\"           \"DIY\"               \"Vegetable_garden\" \n [7] \"Ornamental_garden\" \"Fishing_hunting\"   \"Collection\"       \n[10] \"Vehicle_custom\"    \"Making_music\"      \"Diary\"            \n[13] \"Painting\"          \"Montage\"           \"Pottery\"          \n[16] \"Theater\"           \"Drawing\"           \"Dancing\"          \n[19] \"Photography\"       \"Genealogy\"         \"Science\"          \n[22] \"None\"              \"No_Amateur\"        \"Video_games\"      \n[25] \"TV\"                \"Radio\"             \"Library\"          \n[28] \"Museums\"           \"Internet\"          \"Concert\"          \n\n\ncode R\n# Exclure \"(Intercept)\" des coefficients\ncoefficients_filtered &lt;- coefficients_non_zero[coefficients_non_zero$Variable != \"(Intercept)\", ]\n\n# Aligner les coefficients sur x_test\ncoef_vector &lt;- coefficients_filtered$Coefficient[match(colnames(x_test), coefficients_filtered$Variable)]\n\n\n\n# Calcul des scores\ntest_data$score &lt;- x_test %*% coef_vector\n\n# Normalisation des scores\nmin_score &lt;- min(test_data$score, na.rm = TRUE)\nmax_score &lt;- max(test_data$score, na.rm = TRUE)\n\nif (max_score &gt; min_score) {\n  test_data$score_normalise &lt;- (test_data$score - min_score) / (max_score - min_score)\n} else {\n  test_data$score_normalise &lt;- 0\n}\n\n# Visualisation avec ggplot2\nlibrary(ggplot2)\nggplot(test_data, aes(x = score_normalise, color = SEXE, fill = SEXE)) +\n  geom_density(alpha = 0.4) + \n  labs(title = \"Densité du Score Normalisé\", x = \"Score Normalisé\", y = \"Densité\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\ncode R\n# Préparer la matrice X pour l'ensemble complet (train + test)\nx_full &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                       Vegetable_garden + Ornamental_garden + Fishing_hunting + \n                       Collection + Vehicle_custom + Making_music + Diary + Writing + \n                       Painting + Montage + Circus + Pottery + Theater + Drawing + \n                       Dancing + Photography + Genealogy + Science + None + No_Amateur +\n                       Video_games + TV + Radio + Library + Museums + Internet + Concert,\n                       my_data_frame)[, -1]  # Exclure l'intercept\n\n# Sélectionner les variables pertinentes (identiques à celles du modèle LASSO)\nmatched_vars &lt;- intersect(rownames(coefficients_non_zero), colnames(x_full))\nx_full &lt;- x_full[, matched_vars, drop = FALSE]  # Garder uniquement les variables sélectionnées\n# Aligner les coefficients sur x_full\ncoef_vector_full &lt;- coefficients_filtered$Coefficient[match(colnames(x_full), coefficients_filtered$Variable)]\n\n# Calcul des scores pour l'ensemble complet\nmy_data_frame$score &lt;- x_full %*% coef_vector_full\n# Normalisation des scores\nmin_score_full &lt;- min(my_data_frame$score, na.rm = TRUE)\nmax_score_full &lt;- max(my_data_frame$score, na.rm = TRUE)\n\nif (max_score_full &gt; min_score_full) {\n  my_data_frame$score_normalise &lt;- (my_data_frame$score - min_score_full) / (max_score_full - min_score_full)\n} else {\n  my_data_frame$score_normalise &lt;- 0\n}\n# Visualisation du score normalisé pour l'ensemble complet avec ggplot2\nlibrary(ggplot2)\nggplot(my_data_frame, aes(x = score_normalise, color = SEXE, fill = SEXE)) +\n  geom_density(alpha = 0.4) + \n  labs(title = \"Densité du Score Normalisé (Ensemble Complet)\", x = \"Score Normalisé\", y = \"Densité\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notre Mesure: Le Cultural Gender Normativity Index (CGNI)</span>"
    ]
  },
  {
    "objectID": "construction_indice.html#comparaisons",
    "href": "construction_indice.html#comparaisons",
    "title": "1  Notre Mesure: Le Cultural Gender Normativity Index (CGNI)",
    "section": "1.2 Comparaisons",
    "text": "1.2 Comparaisons\n\n\ncode R\n# Calculer la corrélation entre indice_normalise et score_normalise\ncorrelation_value &lt;- cor(my_data_frame$identity, my_data_frame$score_normalise, use = \"complete.obs\")\nprint(paste(\"Corrélation entre indice_normalise et score_normalise :\", correlation_value))\n\n\n[1] \"Corrélation entre indice_normalise et score_normalise : -0.645386557366119\"\n\n\ncode R\n# Visualiser la relation entre indice_normalise et score_normalise\nlibrary(ggplot2)\nggplot(my_data_frame, aes(x = identity, y = score_normalise)) +\n  geom_point(alpha = 0.5) +\n  labs(title = \"Relation entre indice_normalise et score_normalise\", \n       x = \"Indice Normalisé\", \n       y = \"Score Normalisé\") +\n  theme_minimal() +\n  geom_smooth(method = \"lm\", col = \"red\", se = FALSE)  # Ajouter une droite de régression linéaire\n\n\n\n\n\n\n\n\n\n\n\ncode R\nn_2 &lt;- nrow(my_data_frame)\n\n# Indices pour la division (2/3 pour l'entraînement, 1/3 pour le test)\ntrain_index &lt;- sample(1:n_2, size = 2 * n_2 / 3)  # 2/3 des indices pour l'entraînement\n\n# Créer l'ensemble d'entraînement et l'ensemble de test\ntrain_data &lt;- my_data_frame[train_index, ]  # Enregistrement d'entraînement\ntest_data &lt;- my_data_frame[-train_index, ]  # Enregistrement de test\n\n# Vérifier les tailles\ncat(\"Nombre d'observations dans l'ensemble d'entraînement :\", nrow(train_data), \"\\n\")\n\n\nNombre d'observations dans l'ensemble d'entraînement : 6156 \n\n\ncode R\ncat(\"Nombre d'observations dans l'ensemble de test :\", nrow(test_data), \"\\n\")\n\n\nNombre d'observations dans l'ensemble de test : 3078 \n\n\ncode R\n# Charger les bibliothèques nécessaires\nlibrary(glmnet)\nlibrary(pROC)\n\n# Définir la matrice X pour l'entraînement\nx_2 &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage +  Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + \n                  Video_games + Library +  Concert,\n                  train_data)[, -1]\n\n# Variable cible y pour l'entraînement\ny_2 &lt;- train_data$SEXE\n\n# Ajuster le modèle LASSO avec validation croisée\ncv_lasso_2 &lt;- cv.glmnet(x_2, y_2, alpha = 1, family = \"binomial\")\nbest_lambda_2 &lt;- cv_lasso_2$lambda.min  # Lambda optimal\n\n# Vérifie les coefficients pour le lambda optimal\nprint(coef(cv_lasso_2, s = \"lambda.min\"))\n\n\n26 x 1 sparse Matrix of class \"dgCMatrix\"\n                          s1\n(Intercept)       0.11260864\nKnitting          3.01800722\nCards_games       0.16677278\nGambling         -0.34566529\nCooking           1.12798392\nDIY              -1.01219567\nVegetable_garden -0.30731087\nFishing_hunting  -1.40787072\nCollection       -0.69110001\nVehicle_custom   -1.68777530\nMaking_music     -0.13299836\nDiary             1.46711705\nWriting          -0.16958639\nPainting          0.48089960\nMontage          -1.00019427\nPottery           0.52939803\nTheater          -0.06515215\nDrawing          -0.15971724\nDancing           1.52751004\nPhotography      -0.50794702\nGenealogy        -0.33199701\nScience          -0.87343121\nNone             -0.11072248\nVideo_games      -0.16572230\nLibrary          -0.01094454\nConcert           0.01127190\n\n\ncode R\nprint(best_lambda_2)\n\n\n[1] 0.0005315669\n\n\ncode R\n# Préparer X_test (même traitement que pour l'entraînement)\nx_test_2 &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage +  Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + \n                  Video_games + Library +  Concert,\n                       test_data)[, -1]\n\n# Prédire les probabilités sur les données de test avec le meilleur lambda\npreds_2 &lt;- predict(cv_lasso_2, newx = x_test_2, s = \"lambda.min\", type = \"response\")\n\n# Variable cible y_test pour l'ensemble de test\ny_test_2 &lt;- test_data$SEXE\n\n# Calcul de l'AUC avec pROC\nroc_curve_2 &lt;- roc(y_test_2, preds_2)\nauc_value_2 &lt;- auc(roc_curve_2)\nprint(paste(\"AUC:\", auc_value_2))\n\n\n[1] \"AUC: 0.868197882559135\"\n\n\ncode R\n# Calculer la courbe ROC\nroc_curve_2 &lt;- roc(y_test_2, preds_2)\n\n# Afficher la courbe ROC\nplot(roc_curve_2, main = \"Courbe ROC 2\", col = \"blue\", lwd = 2)\n\n# Optionnel : Ajouter la ligne de base (diagonale)\nabline(a = 0, b = 1, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n\n\ncode R\n# Afficher les coefficients pour le meilleur lambda\ncoefficients_2 &lt;- coef(cv_lasso_2, s = \"lambda.min\")\n\n# Convertir en data.frame pour une meilleure lisibilité\ncoefficients_df_2 &lt;- as.data.frame(as.matrix(coefficients_2))\ncolnames(coefficients_df_2) &lt;- \"Coefficient\"\ncoefficients_df_2$Variable &lt;- rownames(coefficients_df_2)\n\n# Filtrer pour ne garder que les variables avec des coefficients non nuls\ncoefficients_non_zero_2 &lt;- coefficients_df_2[coefficients_df_2$Coefficient != 0, ]\n\n# Afficher les variables gardées et leurs coefficients\nprint(coefficients_non_zero_2)\n\n\n                 Coefficient         Variable\n(Intercept)       0.11260864      (Intercept)\nKnitting          3.01800722         Knitting\nCards_games       0.16677278      Cards_games\nGambling         -0.34566529         Gambling\nCooking           1.12798392          Cooking\nDIY              -1.01219567              DIY\nVegetable_garden -0.30731087 Vegetable_garden\nFishing_hunting  -1.40787072  Fishing_hunting\nCollection       -0.69110001       Collection\nVehicle_custom   -1.68777530   Vehicle_custom\nMaking_music     -0.13299836     Making_music\nDiary             1.46711705            Diary\nWriting          -0.16958639          Writing\nPainting          0.48089960         Painting\nMontage          -1.00019427          Montage\nPottery           0.52939803          Pottery\nTheater          -0.06515215          Theater\nDrawing          -0.15971724          Drawing\nDancing           1.52751004          Dancing\nPhotography      -0.50794702      Photography\nGenealogy        -0.33199701        Genealogy\nScience          -0.87343121          Science\nNone             -0.11072248             None\nVideo_games      -0.16572230      Video_games\nLibrary          -0.01094454          Library\nConcert           0.01127190          Concert\n\n\ncode R\n###CREATION INDICE\n\n# Récupérer les coefficients du modèle pour le meilleur lambda\ncoefficients_2 &lt;- coef(cv_lasso_2, s = \"lambda.min\")\n\n# Convertir en data.frame et filtrer les variables non nulles\ncoefficients_df_2 &lt;- as.data.frame(as.matrix(coefficients_2))\ncolnames(coefficients_df_2) &lt;- \"Coefficient\"\ncoefficients_df_2$Variable &lt;- rownames(coefficients_df_2)\ncoefficients_non_zero_2 &lt;- coefficients_df_2[coefficients_df_2$Coefficient != 0, ]\n\n# Préparer la matrice X des pratiques pour l'ensemble de test (ou d'entraînement si nécessaire)\nx_test_2 &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage +  Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + \n                  Video_games + Library +  Concert,\n                       test_data)[, -1]  # Assurez-vous d'enlever l'intercept avec [, -1]\n\n# Sélectionner les variables pertinentes\nmatched_vars_2 &lt;- intersect(rownames(coefficients_non_zero_2), colnames(x_test_2))\nx_test_2 &lt;- x_test_2[, matched_vars_2, drop = FALSE]\ncoef_vector_2 &lt;- coefficients_non_zero_2$Coefficient[matched_vars_2]  # Associer les coefficients\n\n#print(paste(\"Dimension de x_test :\", dim(x_test)[1], \"x\", dim(x_test)[2]))\n#print(paste(\"Longueur de coef_vector :\", length(coef_vector)))\n#print(paste(\"Nombre de valeurs NA dans x_test :\", sum(is.na(x_test))))\n#print(paste(\"Nombre de valeurs NA dans coef_vector :\", sum(is.na(coef_vector))))\n\n#print(\"Variables dans coefficients_non_zero :\")\n#print(coefficients_non_zero$Variable)\n\n#print(\"Colonnes de x_test :\")\n#print(colnames(x_test))\n\n\n# Exclure \"(Intercept)\" des coefficients\ncoefficients_filtered_2 &lt;- coefficients_non_zero_2[coefficients_non_zero_2$Variable != \"(Intercept)\", ]\n\n# Aligner les coefficients sur x_test\ncoef_vector_2 &lt;- coefficients_filtered_2$Coefficient[match(colnames(x_test_2), coefficients_filtered_2$Variable)]\n\n\n\n# Calcul des scores\ntest_data$score_2 &lt;- x_test_2 %*% coef_vector_2\n\n# Normalisation des scores\nmin_score_2 &lt;- min(test_data$score_2, na.rm = TRUE)\nmax_score_2 &lt;- max(test_data$score_2, na.rm = TRUE)\n\nif (max_score_2 &gt; min_score_2) {\n  test_data$score_normalise_2 &lt;- (test_data$score_2 - min_score_2) / (max_score_2 - min_score_2)\n} else {\n  test_data$score_normalise_2 &lt;- 0\n}\n\n# Visualisation avec ggplot2\nlibrary(ggplot2)\nggplot(test_data, aes(x = score_normalise_2, color = SEXE, fill = SEXE)) +\n  geom_density(alpha = 0.4) + \n  labs(title = \"Densité du Score Normalisé 2\", x = \"Score Normalisé 2\", y = \"Densité\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ncode R\n# Préparer la matrice X pour l'ensemble complet (train + test)\nx_full_2 &lt;- model.matrix(SEXE ~ Knitting + Cards_games + Gambling + Cooking + DIY +\n                  Vegetable_garden + Fishing_hunting + \n                  Collection + Vehicle_custom + Making_music + Diary + Writing + \n                  Painting + Montage +  Pottery + Theater + Drawing + \n                  Dancing + Photography + Genealogy + Science + None + \n                  Video_games + Library +  Concert,\n                       my_data_frame)[, -1]  # Exclure l'intercept\n\n# Sélectionner les variables pertinentes (identiques à celles du modèle LASSO)\nmatched_vars_2 &lt;- intersect(rownames(coefficients_non_zero_2), colnames(x_full_2))\nx_full_2 &lt;- x_full_2[, matched_vars_2, drop = FALSE]  # Garder uniquement les variables sélectionnées\n# Aligner les coefficients sur x_full\ncoef_vector_full_2 &lt;- coefficients_filtered_2$Coefficient[match(colnames(x_full_2), coefficients_filtered_2$Variable)]\n\n# Calcul des scores pour l'ensemble complet\nmy_data_frame$score_2 &lt;- x_full_2 %*% coef_vector_full_2\n# Normalisation des scores\nmin_score_full_2 &lt;- min(my_data_frame$score_2, na.rm = TRUE)\nmax_score_full_2 &lt;- max(my_data_frame$score_2, na.rm = TRUE)\n\nif (max_score_full_2 &gt; min_score_full_2) {\n  my_data_frame$score_normalise_2 &lt;- (my_data_frame$score_2 - min_score_full_2) / (max_score_full_2 - min_score_full_2)\n} else {\n  my_data_frame$score_normalise_2 &lt;- 0\n}\n# Visualisation du score normalisé pour l'ensemble complet avec ggplot2\nlibrary(ggplot2)\nggplot(my_data_frame, aes(x = score_normalise_2, color = SEXE, fill = SEXE)) +\n  geom_density(alpha = 0.4) + \n  labs(title = \"Densité du Score Normalisé 2(Ensemble Complet)\", x = \"Score Normalisé\", y = \"Densité\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ncode R\n# Calculer la corrélation entre indice_normalise et score_normalise\ncorrelation_value_2 &lt;- cor(my_data_frame$identity, my_data_frame$score_normalise_2, use = \"complete.obs\")\nprint(paste(\"Corrélation entre indice_normalise et score_normalise 2:\", correlation_value))\n\n\n[1] \"Corrélation entre indice_normalise et score_normalise 2: -0.645386557366119\"\n\n\ncode R\n# Visualiser la relation entre indice_normalise et score_normalise\nlibrary(ggplot2)\nggplot(my_data_frame, aes(x = identity, y = score_normalise_2)) +\n  geom_point(alpha = 0.5) +\n  labs(title = \"Relation entre indice_normalise et score_normalise 2\", \n       x = \"Indice Normalisé\", \n       y = \"Score Normalisé\") +\n  theme_minimal() +\n  geom_smooth(method = \"lm\", col = \"red\", se = FALSE)  # Ajouter une droite de régression linéaire\n\n\n\n\n\n\n\n\n\ncode R\n# Créer un data frame pour stocker les résultats\nresult_table_score_2 &lt;- data.frame(Activity_2 = character(0), Accuracy_2 = numeric(0))\n\ncultural_activities_2 &lt;- c(\n   \"Knitting\", \"Cards_games\", \"Gambling\", \"Cooking\", \"DIY\",\n   \"Vegetable_garden\", \"Fishing_hunting\", \"Collection\", \"Vehicle_custom\",\n   \"Making_music\", \"Diary\", \"Writing\", \"Painting\", \"Montage\",\n   \"Pottery\", \"Theater\", \"Drawing\", \"Dancing\", \"Photography\",\n   \"Genealogy\", \"Science\", \"None\", \"Video_games\", \"Library\", \"Concert\"\n)\n\nfor (activity_2 in cultural_activities_2) {\n  # Effectuer une régression Probit pour l'activité culturelle actuelle\n  model_formula_2 &lt;- as.formula(paste(activity_2, \"~ score_normalise_2\"))\n  model_2 &lt;- glm(model_formula_2, data = my_data_frame, family = binomial(link = \"probit\"))\n \n  # Calculer les prédictions\n  predicted_2 &lt;- ifelse(predict(model_2, type = \"response\") &gt;= 0.5, 1, 0)\n \n  # Calculer la précision\n  correct_predictions_2 &lt;- sum(predicted_2 == my_data_frame[[activity_2]])\n  total_predictions_2 &lt;- nrow(my_data_frame)\n  accuracy_2 &lt;- (correct_predictions_2 / total_predictions_2) * 100\n \n  # Ajouter le résultat au data frame\n  result_table_score_2 &lt;- rbind(result_table_score_2, data.frame(Activity_2 = activity_2, Accuracy_2 = accuracy_2))\n}\n\n# Afficher le tableau des résultats\nprint(result_table_score_2)\n\n\n         Activity_2 Accuracy_2\n1          Knitting   92.92831\n2       Cards_games   56.44358\n3          Gambling   78.77410\n4           Cooking   68.72428\n5               DIY   59.97401\n6  Vegetable_garden   72.07061\n7   Fishing_hunting   90.25341\n8        Collection   92.67923\n9    Vehicle_custom   96.58869\n10     Making_music   65.97358\n11            Diary   84.53541\n12          Writing   87.48105\n13         Painting   78.68746\n14          Montage   84.54624\n15          Pottery   89.50617\n16          Theater   86.10570\n17          Drawing   76.72731\n18          Dancing   76.80312\n19      Photography   74.53974\n20        Genealogy   88.21746\n21          Science   88.30409\n22             None   71.20425\n23      Video_games   61.47932\n24          Library   83.47412\n25          Concert   82.06628\n\n\n\n\ncode R\nmy_data_frame$score_scale &lt;- cut(\n  my_data_frame$score_normalise,\n  breaks = 7,  # Automatically divide into 7 slices\n  labels = c(\"Very Masculine\", \"1\", \"2\", \"3\", \"4\", \"5\", \"Very Feminine\"), \n  include.lowest = TRUE  \n)\ntable1 &lt;-\n  my_data_frame |&gt; \n  tbl_summary(include = c(score_scale),\n  by=Sex ,)|&gt; \n    add_p()\ntable1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\np-value2\n\n\n\n\nscore_scale\n\n\n\n\n&lt;0.001\n\n\n    Very Masculine\n18 (0.4%)\n0 (0%)\n\n\n\n\n    1\n405 (9.7%)\n15 (0.3%)\n\n\n\n\n    2\n1,871 (45%)\n412 (8.1%)\n\n\n\n\n    3\n1,659 (40%)\n2,075 (41%)\n\n\n\n\n    4\n189 (4.5%)\n1,646 (32%)\n\n\n\n\n    5\n19 (0.5%)\n792 (16%)\n\n\n\n\n    Very Feminine\n1 (&lt;0.1%)\n132 (2.6%)\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\ncode R\n# Proportions de 'score_scale' par genre\ntable_score_gender &lt;- table(my_data_frame$score_scale, my_data_frame$Sex)\ntable_score_gender_percent &lt;- prop.table(table_score_gender, 2) * 100  # Calcul par genre\ntable_score_gender_percent\n\n\n                \n                         Men       Women\n  Very Masculine  0.43248438  0.00000000\n  1               9.73089861  0.29574132\n  2              44.95434887  8.12302839\n  3              39.86064392 40.91088328\n  4               4.54108602 32.45268139\n  5               0.45651129 15.61514196\n  Very Feminine   0.02402691  2.60252366\n\n\ncode R\n# Proportions de 'satisfaction' par genre\ntable_satisfaction_gender &lt;- table(my_data_frame$satisfaction, my_data_frame$Sex)\ntable_satisfaction_gender_percent &lt;- prop.table(table_satisfaction_gender, 2) * 100  # Calcul par genre\ntable_satisfaction_gender_percent\n\n\n        \n              Men    Women\n  High   35.15399 32.66917\n  Low    35.80366 39.75143\n  Medium 29.04235 27.57940\n\n\n\n\ncode R\n# Charger les bibliothèques nécessaires\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(scales)\n\n# Création du graphique avec ggplot\np &lt;- ggplot(as.data.frame(table_score_gender_percent), \n            aes(x = Var1, y = Freq, fill = Var2, text = paste0(\"Proportion: \", percent(Freq / 100)))) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  labs(title = \"Répartition des scores par genre\",\n       x = \"Score (1-7)\", y = \"Proportion (%)\") +\n  scale_y_continuous(labels = percent_format(scale = 1)) +\n  theme_minimal() +\n  theme(legend.title = element_blank())\n\n# Convertir en graphique interactif avec ggplotly\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\ncode R\ntable1 &lt;-\n  my_data_frame |&gt; \n  tbl_summary(include = c(identity_scale),\n  by=Sex ,)|&gt; \n    add_p()\ntable1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\np-value2\n\n\n\n\nidentity_scale\n\n\n\n\n&lt;0.001\n\n\n    Very Feminine\n9 (0.2%)\n218 (4.3%)\n\n\n\n\n    1\n403 (9.7%)\n1,506 (30%)\n\n\n\n\n    2\n2,139 (51%)\n2,669 (53%)\n\n\n\n\n    3\n985 (24%)\n576 (11%)\n\n\n\n\n    4\n509 (12%)\n90 (1.8%)\n\n\n\n\n    5\n96 (2.3%)\n10 (0.2%)\n\n\n\n\n    Very Masculine\n21 (0.5%)\n3 (&lt;0.1%)\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\ncode R\n# Proportions de 'score_scale' par genre\ntable_identity_gender &lt;- table(my_data_frame$identity_scale, my_data_frame$Sex)\ntable_identity_gender_percent &lt;- prop.table(table_identity_gender, 2) * 100  # Calcul par genre\ntable_identity_gender_percent\n\n\n                \n                         Men       Women\n  Very Feminine   0.21624219  4.29810726\n  1               9.68284479 29.69242902\n  2              51.39356079 52.62223975\n  3              23.66650649 11.35646688\n  4              12.22969726  1.77444795\n  5               2.30658337  0.19716088\n  Very Masculine  0.50456511  0.05914826\n\n\ncode R\n# Création du graphique avec ggplot\np &lt;- ggplot(as.data.frame(table_identity_gender_percent), \n            aes(x = Var1, y = Freq, fill = Var2, text = paste0(\"Proportion: \", percent(Freq / 100)))) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  labs(title = \"Répartition de l'identity scale par genre\",\n       x = \"Score (1-7)\", y = \"Proportion (%)\") +\n  scale_y_continuous(labels = percent_format(scale = 1)) +\n  theme_minimal() +\n  theme(legend.title = element_blank())\n\n# Convertir en graphique interactif avec ggplotly\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\ncode R\ntable1 &lt;-\n  my_data_frame |&gt; \n  tbl_summary(include = c(CLASSIF),\n  by=score_scale ,)|&gt; \n    add_p()\ntable1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nVery Masculine N = 181\n1 N = 4201\n2 N = 2,2831\n3 N = 3,7341\n4 N = 1,8351\n5 N = 8111\nVery Feminine N = 1331\np-value\n\n\n\n\nCLASSIF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    1\n0 (0%)\n14 (8.2%)\n72 (9.1%)\n70 (6.4%)\n23 (4.3%)\n6 (3.2%)\n1 (3.1%)\n\n\n\n\n    2\n3 (38%)\n63 (37%)\n236 (30%)\n221 (20%)\n59 (11%)\n14 (7.5%)\n1 (3.1%)\n\n\n\n\n    3\n0 (0%)\n24 (14%)\n105 (13%)\n99 (9.1%)\n39 (7.4%)\n13 (7.0%)\n2 (6.3%)\n\n\n\n\n    4\n3 (38%)\n22 (13%)\n83 (10%)\n97 (8.9%)\n56 (11%)\n17 (9.1%)\n5 (16%)\n\n\n\n\n    5\n0 (0%)\n26 (15%)\n140 (18%)\n191 (18%)\n103 (19%)\n44 (24%)\n10 (31%)\n\n\n\n\n    6\n1 (13%)\n20 (12%)\n151 (19%)\n380 (35%)\n245 (46%)\n87 (47%)\n13 (41%)\n\n\n\n\n    7\n0 (0%)\n0 (0%)\n4 (0.5%)\n12 (1.1%)\n2 (0.4%)\n2 (1.1%)\n0 (0%)\n\n\n\n\n    8\n1 (13%)\n1 (0.6%)\n4 (0.5%)\n16 (1.5%)\n3 (0.6%)\n4 (2.1%)\n0 (0%)\n\n\n\n\n    9\n0 (0%)\n0 (0%)\n0 (0%)\n2 (0.2%)\n0 (0%)\n0 (0%)\n0 (0%)\n\n\n\n\n    Unknown\n10\n250\n1,488\n2,646\n1,305\n624\n101\n\n\n\n\n\n1 n (%)\n\n\n\n\n\n\n\n\ncode R\n# Proportions de 'score_scale' par profession\ntable_identity_gender &lt;- table(my_data_frame$CLASSIF, my_data_frame$score_scale)\ntable_identity_gender_percent &lt;- prop.table(table_identity_gender, 2) * 100  # Calcul par genre\ntable_identity_gender_percent\n\n\n   \n    Very Masculine          1          2          3          4          5\n  1      0.0000000  8.2352941  9.0566038  6.4338235  4.3396226  3.2085561\n  2     37.5000000 37.0588235 29.6855346 20.3125000 11.1320755  7.4866310\n  3      0.0000000 14.1176471 13.2075472  9.0992647  7.3584906  6.9518717\n  4     37.5000000 12.9411765 10.4402516  8.9154412 10.5660377  9.0909091\n  5      0.0000000 15.2941176 17.6100629 17.5551471 19.4339623 23.5294118\n  6     12.5000000 11.7647059 18.9937107 34.9264706 46.2264151 46.5240642\n  7      0.0000000  0.0000000  0.5031447  1.1029412  0.3773585  1.0695187\n  8     12.5000000  0.5882353  0.5031447  1.4705882  0.5660377  2.1390374\n  9      0.0000000  0.0000000  0.0000000  0.1838235  0.0000000  0.0000000\n   \n    Very Feminine\n  1     3.1250000\n  2     3.1250000\n  3     6.2500000\n  4    15.6250000\n  5    31.2500000\n  6    40.6250000\n  7     0.0000000\n  8     0.0000000\n  9     0.0000000\n\n\ncode R\n# Création du graphique avec ggplot\np &lt;- ggplot(as.data.frame(table_identity_gender_percent), \n            aes(x = Var1, y = Freq, fill = Var2, text = paste0(\"Proportion: \", percent(Freq / 100)))) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n \n  labs(title = \"Répartition des professions par score scale\",\n       x = \"Profession\", y = \"Proportion (%)\") +\n  scale_y_continuous(labels = percent_format(scale = 1)) +\n  theme_minimal() +\n  theme(legend.title = element_blank())\n\n# Convertir en graphique interactif avec ggplotly\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\ncode R\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(plotly)\n\n# Créer un tableau de fréquence pour la heatmap\nheatmap_data &lt;- my_data_frame %&gt;%\n  count(score_scale, satisfaction)  # Compte les occurrences\n\n# Ajouter une colonne pour l'affichage interactif\nheatmap_data &lt;- heatmap_data %&gt;%\n  mutate(info_text = paste0(\"Score: \", score_scale, \n                            \"\\nSatisfaction: \", satisfaction, \n                            \"\\nNombre d'observations: \", n))\n\n# Créer la heatmap avec ggplot\np &lt;- ggplot(heatmap_data, aes(x = as.factor(score_scale), \n                              y = as.factor(satisfaction), \n                              fill = n, text = info_text)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"white\", high = \"blue\") +\n  labs(title = \"Heatmap de la relation entre satisfaction et score\",\n       x = \"Score Scale\", y = \"Satisfaction\", fill = \"Fréquence\") +\n  theme_minimal()\n\n# Rendre le graphique interactif avec des infobulles personnalisées\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\ncode R\n# Créer un tableau de fréquence pour la heatmap\nheatmap_data &lt;- my_data_frame %&gt;%\n  count(identity_scale, satisfaction)  # Compte les occurrences\n\n# Ajouter une colonne pour l'affichage interactif\nheatmap_data &lt;- heatmap_data %&gt;%\n  mutate(info_text = paste0(\"Identity: \", identity_scale, \n                            \"\\nSatisfaction: \", satisfaction, \n                            \"\\nNombre d'observations: \", n))\n\n# Créer la heatmap avec ggplot\np &lt;- ggplot(heatmap_data, aes(x = as.factor(identity_scale), \n                              y = as.factor(satisfaction), \n                              fill = n, text = info_text)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"white\", high = \"blue\") +\n  labs(title = \"Heatmap de la relation entre satisfaction et identity scale\",\n       x = \"Score Scale\", y = \"Satisfaction\", fill = \"Fréquence\") +\n  theme_minimal()\n\n# Rendre le graphique interactif avec des infobulles personnalisées\nggplotly(p, tooltip = \"text\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notre Mesure: Le Cultural Gender Normativity Index (CGNI)</span>"
    ]
  },
  {
    "objectID": "construction_indice.html#ecarts-aux-normes-et-satisfaction",
    "href": "construction_indice.html#ecarts-aux-normes-et-satisfaction",
    "title": "1  Notre Mesure: Le Cultural Gender Normativity Index (CGNI)",
    "section": "1.3 Ecarts aux normes et satisfaction",
    "text": "1.3 Ecarts aux normes et satisfaction\n\n\ncode R\nmean_gender &lt;- tapply(my_data_frame$identity, my_data_frame$Sex, mean)\nsd_gender &lt;- tapply(my_data_frame$identity, my_data_frame$Sex, sd)\n\nmy_data_frame$distance_abs&lt;- abs((my_data_frame$identity - mean_gender[my_data_frame$Sex]) / sd_gender[my_data_frame$Sex])\n\nggplot(my_data_frame, aes(x = distance_abs, color = Sex, fill = Sex)) +\n  geom_density(alpha = 0.4) +\n  labs(title = \"Density of Distance to the Norm, by Sex\", \n       x = \"Distance to the Norm (Z-score)\", y = \"Density\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\ncode R\n# Charger dplyr\nlibrary(dplyr)\n\n# Assurer que Sex est un facteur avec les niveaux appropriés\nmy_data_frame$Sex &lt;- factor(my_data_frame$Sex, levels = c(\"Men\", \"Women\"))\n\n# Calculer les moyennes et écarts-types par sexe avec dplyr\nmean_sd_by_sex &lt;- my_data_frame %&gt;%\n  group_by(Sex) %&gt;%\n  summarise(\n    mean_gender = mean(score_normalise, na.rm = TRUE),\n    sd_gender = sd(score_normalise, na.rm = TRUE)\n  )\n\n# Joindre les moyennes et écarts-types au dataframe original\nmy_data_frame &lt;- my_data_frame %&gt;%\n  left_join(mean_sd_by_sex, by = \"Sex\")\n\n# Calculer la distance absolue à la moyenne (Z-score)\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(distance_abs_2 = abs((score_normalise - mean_gender) / sd_gender))\n\n# Visualisation\nggplot(my_data_frame, aes(x = distance_abs_2, color = Sex, fill = Sex)) +\n  geom_density(alpha = 0.4) +\n  labs(title = \"Density of Distance to the Norm (Score), by Sex\", \n       x = \"Distance to the Norm (Z-score)\", y = \"Density\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal() +\n  geom_vline(data = my_data_frame, aes(xintercept = mean(distance_abs_2[Sex == \"Men\"]), color = \"Men\"), linetype = \"dashed\") +\n  geom_vline(data = my_data_frame, aes(xintercept = mean(distance_abs_2[Sex == \"Women\"]), color = \"Women\"), linetype = \"dashed\") +\n  theme(legend.title = element_blank())  # Enlever le titre de la légende\n\n\n\n\n\n\n\n\n\n\n\ncode R\n# Charger le package MASS pour polr\nlibrary(MASS)\n\n# Modèle de régression ordinale (polr)\nmodel &lt;- polr(as.factor(satisfaction) ~ distance_abs_2, data = my_data_frame, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model)\n\n\nCall:\npolr(formula = as.factor(satisfaction) ~ distance_abs_2, data = my_data_frame, \n    method = \"logistic\")\n\nCoefficients:\n                 Value Std. Error t value\ndistance_abs_2 0.02273    0.03199  0.7105\n\nIntercepts:\n           Value    Std. Error t value \nHigh|Low    -0.6543   0.0340   -19.2524\nLow|Medium   0.9511   0.0348    27.3139\n\nResidual Deviance: 20135.53 \nAIC: 20141.53 \n(9 observations effacées parce que manquantes)\n\n\ncode R\n# Modèle de régression ordinale avec interaction entre sexe et distance aux normes\nmodel_interaction &lt;- polr(as.factor(satisfaction) ~ Sex * distance_abs_2, data = my_data_frame, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_interaction)\n\n\nCall:\npolr(formula = as.factor(satisfaction) ~ Sex * distance_abs_2, \n    data = my_data_frame, method = \"logistic\")\n\nCoefficients:\n                           Value Std. Error t value\nSexWomen                 0.11297    0.06463   1.748\ndistance_abs_2           0.07744    0.04621   1.676\nSexWomen:distance_abs_2 -0.10629    0.06407  -1.659\n\nIntercepts:\n           Value    Std. Error t value \nHigh|Low    -0.5961   0.0477   -12.4889\nLow|Medium   1.0098   0.0486    20.7948\n\nResidual Deviance: 20132.29 \nAIC: 20142.29 \n(9 observations effacées parce que manquantes)\n\n\n\n\ncode R\n# Charger la bibliothèque Plotly\nlibrary(plotly)\n\n# Regroupement de distance_abs_2 en catégories (bins)\nmy_data_frame$distance_abs_2_bins &lt;- cut(my_data_frame$distance_abs_2, \n                                          breaks = 10,  # Divise en 10 intervalles\n                                          labels = FALSE, include.lowest = TRUE)\n\n# Comptage des occurrences pour chaque combinaison de Sexe, Satisfaction et Distance\nlibrary(dplyr)\ncount_data &lt;- my_data_frame %&gt;%\n  count(Sex, satisfaction, distance_abs_2_bins)\n\n# Création de la heatmap interactive avec Plotly\nfig &lt;- plot_ly(count_data, \n               x = ~distance_abs_2_bins, \n               y = ~as.factor(satisfaction), \n               z = ~n, \n               type = \"heatmap\", \n               colors = colorRamp(c(\"white\", \"blue\")), \n               colorbar = list(title = \"Nombre d'individus\"))\n\n# Ajouter des titres\nfig &lt;- fig %&gt;%\n  layout(title = \"Heatmap de Satisfaction par Sexe et Distance aux Normes\",\n         xaxis = list(title = \"Distance aux Normes (Binned)\"),\n         yaxis = list(title = \"Satisfaction\"))\n\n# Afficher la heatmap interactive\nfig\n\n\n\n\n\n\n\n\ncode R\nggplot(my_data_frame, aes(x = distance_abs_2, y = as.factor(satisfaction), color = Sex)) +\n  geom_point(alpha = 0.7) +\n  labs(title = \"Interaction entre Sexe et Distance aux Normes sur Satisfaction\",\n       x = \"Distance aux Normes (Z-score)\", y = \"Satisfaction\") +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal() +\n  facet_wrap(~Sex)\n\n\n\n\n\n\n\n\n\n\n\ncode R\n# 1. Charger les librairies nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\n\n# 2. Vérifier les valeurs manquantes dans le dataframe\n#summary(my_data_frame)\n\n# 3. Supprimer les lignes contenant des valeurs manquantes dans les colonnes pertinentes\nmy_data_frame_clean &lt;- my_data_frame[complete.cases(my_data_frame[c(\"satisfaction\", \"Sex\", \"distance_abs_2\")]), ]\n\n# Vérification de la taille du dataframe nettoyé\nnrow(my_data_frame_clean)  # Assure-toi que la taille est correcte\n\n\n[1] 9225\n\n\ncode R\n# 4. Convertir les variables catégoriques en facteurs avec les niveaux appropriés\nmy_data_frame_clean$satisfaction &lt;- factor(my_data_frame_clean$satisfaction, levels = c(\"Low\", \"Medium\", \"High\"))\nmy_data_frame_clean$Sex &lt;- factor(my_data_frame_clean$Sex, levels = c(\"Men\", \"Women\"))\n\n# 5. Ajuster le modèle de régression logistique ordinale\nmodel_clean &lt;- polr(as.factor(satisfaction) ~ distance_abs_2, data = my_data_frame_clean, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_clean)\n\n\nCall:\npolr(formula = as.factor(satisfaction) ~ distance_abs_2, data = my_data_frame_clean, \n    method = \"logistic\")\n\nCoefficients:\n                  Value Std. Error t value\ndistance_abs_2 -0.09192    0.03231  -2.845\n\nIntercepts:\n            Value    Std. Error t value \nLow|Medium   -0.5649   0.0338   -16.7203\nMedium|High   0.5994   0.0339    17.7059\n\nResidual Deviance: 20127.93 \nAIC: 20133.93 \n\n\ncode R\n# 6. Calculer les probabilités pour chaque niveau de satisfaction\npred_prob_clean &lt;- predict(model_clean, type = \"probs\")\n\n# Ajouter les probabilités au dataframe nettoyé\nmy_data_frame_clean$prob_high &lt;- pred_prob_clean[, \"High\"]\nmy_data_frame_clean$prob_medium &lt;- pred_prob_clean[, \"Medium\"]\nmy_data_frame_clean$prob_low &lt;- pred_prob_clean[, \"Low\"]\n\n# 7. Visualiser les résultats\nggplot(my_data_frame_clean, aes(x = distance_abs_2)) +\n  geom_line(aes(y = prob_high, color = \"High\"), size = 1) +\n  geom_line(aes(y = prob_medium, color = \"Medium\"), size = 1) +\n  geom_line(aes(y = prob_low, color = \"Low\"), size = 1) +\n  labs(title = \"Probabilité d'être satisfait selon l'écart aux normes\",\n       x = \"Distance aux Normes (Z-score)\",\n       y = \"Probabilité\") +\n  scale_color_manual(values = c(\"High\" = \"blue\", \"Medium\" = \"orange\", \"Low\" = \"red\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\ncode R\n# 1. Charger les librairies nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\n\n# 2. Vérifier les valeurs manquantes dans le dataframe\n#summary(my_data_frame)\n\n# 3. Supprimer les lignes contenant des valeurs manquantes dans les colonnes pertinentes\nmy_data_frame_clean &lt;- my_data_frame[complete.cases(my_data_frame[c(\"satisfaction\", \"Sex\", \"distance_abs_2\")]), ]\n\n# Vérification de la taille du dataframe nettoyé\nnrow(my_data_frame_clean)  # Assure-toi que la taille est correcte\n\n\n[1] 9225\n\n\ncode R\n# 4. Convertir les variables catégoriques en facteurs avec les niveaux appropriés\nmy_data_frame_clean$satisfaction &lt;- factor(my_data_frame_clean$satisfaction, levels = c(\"Low\", \"Medium\", \"High\"))\nmy_data_frame_clean$Sex &lt;- factor(my_data_frame_clean$Sex, levels = c(\"Men\", \"Women\"))\n\n# 5. Ajuster le modèle de régression logistique ordinale avec interaction entre Sex et distance_abs_2\nmodel_clean_sex &lt;- polr(as.factor(satisfaction) ~ distance_abs_2 * Sex, data = my_data_frame_clean, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_clean_sex)\n\n\nCall:\npolr(formula = as.factor(satisfaction) ~ distance_abs_2 * Sex, \n    data = my_data_frame_clean, method = \"logistic\")\n\nCoefficients:\n                           Value Std. Error t value\ndistance_abs_2          -0.11679    0.04617 -2.5298\nSexWomen                -0.18175    0.06454 -2.8160\ndistance_abs_2:SexWomen  0.05407    0.06464  0.8365\n\nIntercepts:\n            Value    Std. Error t value \nLow|Medium   -0.6607   0.0474   -13.9416\nMedium|High   0.5049   0.0472    10.7040\n\nResidual Deviance: 20114.33 \nAIC: 20124.33 \n\n\ncode R\n# 6. Calculer les probabilités pour chaque niveau de satisfaction par sexe\npred_prob_clean_sex &lt;- predict(model_clean_sex, type = \"probs\")\n\n# Ajouter les probabilités au dataframe nettoyé\nmy_data_frame_clean$prob_high &lt;- pred_prob_clean_sex[, \"High\"]\nmy_data_frame_clean$prob_medium &lt;- pred_prob_clean_sex[, \"Medium\"]\nmy_data_frame_clean$prob_low &lt;- pred_prob_clean_sex[, \"Low\"]\n\n# 7. Visualiser les résultats en fonction de l'écart aux normes et du sexe (avec facet)\nggplot(my_data_frame_clean, aes(x = distance_abs_2)) +\n  geom_line(aes(y = prob_high, color = \"High\"), size = 1) +\n  geom_line(aes(y = prob_medium, color = \"Medium\"), size = 1) +\n  geom_line(aes(y = prob_low, color = \"Low\"), size = 1) +\n  labs(title = \"Probabilité d'être satisfait selon l'écart aux normes et par sexe\",\n       x = \"Distance aux Normes (Z-score)\",\n       y = \"Probabilité\") +\n  scale_color_manual(values = c(\"High\" = \"blue\", \"Medium\" = \"orange\", \"Low\" = \"red\")) +\n  theme_minimal() +\n  facet_wrap(~ Sex) +  # Facette par Sexe\n  theme(legend.title = element_blank())  # Enlever le titre de la légende\n\n\n\n\n\n\n\n\n\n\n\ncode R\n# 1. Charger les librairies nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# 2. Vérifier les valeurs manquantes dans le dataframe\n#summary(my_data_frame)\n\n# 3. Supprimer les lignes contenant des valeurs manquantes dans les colonnes pertinentes\nmy_data_frame_clean &lt;- my_data_frame[complete.cases(my_data_frame[c(\"satisfaction\", \"Sex\", \"distance_abs_2\")]), ]\n\n# Vérification de la taille du dataframe nettoyé\nnrow(my_data_frame_clean)  # Assure-toi que la taille est correcte\n\n\n[1] 9225\n\n\ncode R\n# 4. Convertir les variables catégoriques en facteurs avec les niveaux appropriés\nmy_data_frame_clean$satisfaction &lt;- factor(my_data_frame_clean$satisfaction, levels = c(\"Low\", \"Medium\", \"High\"))\nmy_data_frame_clean$Sex &lt;- factor(my_data_frame_clean$Sex, levels = c(\"Men\", \"Women\"))\n\n# 5. Ajuster le modèle de régression logistique ordinale avec interaction entre Sex et distance_abs_2\nmodel_clean_sex &lt;- polr(as.factor(satisfaction) ~ distance_abs_2 * Sex, data = my_data_frame_clean, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_clean_sex)\n\n\nCall:\npolr(formula = as.factor(satisfaction) ~ distance_abs_2 * Sex, \n    data = my_data_frame_clean, method = \"logistic\")\n\nCoefficients:\n                           Value Std. Error t value\ndistance_abs_2          -0.11679    0.04617 -2.5298\nSexWomen                -0.18175    0.06454 -2.8160\ndistance_abs_2:SexWomen  0.05407    0.06464  0.8365\n\nIntercepts:\n            Value    Std. Error t value \nLow|Medium   -0.6607   0.0474   -13.9416\nMedium|High   0.5049   0.0472    10.7040\n\nResidual Deviance: 20114.33 \nAIC: 20124.33 \n\n\ncode R\n# 6. Calculer les probabilités pour chaque niveau de satisfaction par sexe\npred_prob_clean_sex &lt;- predict(model_clean_sex, type = \"probs\")\n\n# Ajouter les probabilités au dataframe nettoyé\nmy_data_frame_clean$prob_high &lt;- pred_prob_clean_sex[, \"High\"]\nmy_data_frame_clean$prob_medium &lt;- pred_prob_clean_sex[, \"Medium\"]\nmy_data_frame_clean$prob_low &lt;- pred_prob_clean_sex[, \"Low\"]\n\n# 7. Visualisation avec ggplot et ajout de commentaires pour les courbes\np &lt;- ggplot(my_data_frame_clean, aes(x = distance_abs_2)) +\n  geom_line(aes(y = prob_high, color = \"High\"), size = 1) +\n  geom_line(aes(y = prob_medium, color = \"Medium\"), size = 1) +\n  geom_line(aes(y = prob_low, color = \"Low\"), size = 1) +\n  labs(title = \"Probabilité d'être satisfait selon l'écart aux normes et par sexe\",\n       x = \"Distance aux Normes (Z-score)\",\n       y = \"Probabilité\") +\n  scale_color_manual(values = c(\"High\" = \"blue\", \"Medium\" = \"orange\", \"Low\" = \"red\")) +\n  theme_minimal() +\n  facet_wrap(~ Sex) +  # Facette par Sexe\n  theme(legend.title = element_blank())  # Enlever le titre de la légende\n\n# 8. Rendre le graphique interactif avec plotly et ajouter des annotations\np_interactive &lt;- ggplotly(p)\n\n# Ajouter des annotations pour chaque courbe\np_interactive &lt;- p_interactive %&gt;%\n  layout(\n    annotations = list(\n      list(\n        x = 0.5, y = 0.8, \n        text = \"Probabilité High\", \n        showarrow = TRUE, \n        arrowhead = 2,\n        ax = -50, ay = -50\n      ),\n      list(\n        x = 0.5, y = 0.6, \n        text = \"Probabilité Medium\", \n        showarrow = TRUE, \n        arrowhead = 2,\n        ax = -50, ay = -50\n      ),\n      list(\n        x = 0.5, y = 0.4, \n        text = \"Probabilité Low\", \n        showarrow = TRUE, \n        arrowhead = 2,\n        ax = -50, ay = -50\n      )\n    )\n  )\n\n# Afficher le graphique interactif\np_interactive\n\n\n\n\n\n\n\n\ncode R\n# 1. Charger les librairies nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# 2. Convertir la colonne de réponses A15 en une variable Santé catégorique (3 niveaux)\n# Supposons que ta variable santé est dans la colonne 'A15' de 'my_data_frame'\n\n# Remplacer les valeurs de A15 par les niveaux correspondants pour Santé\nmy_data_frame$Santé &lt;- factor(my_data_frame$A15,\n                              levels = c(1, 2, 3, 4, 5),\n                              labels = c(\"Very Good\", \"Good\", \"Fair\", \"Poor\", \"Very Poor\"))\n\n# Convertir en 3 niveaux: \"Good\", \"Fair\", \"Poor\"\nmy_data_frame$Santé &lt;- factor(my_data_frame$Santé,\n                              levels = c(\"Very Good\", \"Good\", \"Fair\", \"Poor\", \"Very Poor\"),\n                              labels = c(\"Good\", \"Good\", \"Fair\", \"Poor\", \"Poor\"))\n\n# Exclure les réponses \"Ne sait pas\" (6) et \"Refus\" (7)\nmy_data_frame_clean &lt;- my_data_frame[!(my_data_frame$A15 %in% c(6, 7)), ]\n\n# 3. Vérifier que la variable Santé est correctement créée\ntable(my_data_frame_clean$Santé)\n\n\n\nGood Fair Poor \n6410 1998  783 \n\n\ncode R\n# 4. Convertir 'Sex' en facteur\nmy_data_frame_clean$Sex &lt;- factor(my_data_frame_clean$Sex, levels = c(\"Men\", \"Women\"))\n\n# 5. Ajuster le modèle de régression logistique ordinale avec interaction entre Sex et distance_abs_2\nmodel_clean_sex_health &lt;- polr(Santé ~ distance_abs_2 * Sex, data = my_data_frame_clean, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_clean_sex_health)\n\n\nCall:\npolr(formula = Santé ~ distance_abs_2 * Sex, data = my_data_frame_clean, \n    method = \"logistic\")\n\nCoefficients:\n                           Value Std. Error t value\ndistance_abs_2          -0.19064    0.05772 -3.3026\nSexWomen                 0.02624    0.07578  0.3463\ndistance_abs_2:SexWomen  0.21223    0.07738  2.7426\n\nIntercepts:\n          Value   Std. Error t value\nGood|Fair  0.7948  0.0554    14.3528\nFair|Poor  2.3365  0.0628    37.2049\n\nResidual Deviance: 14545.71 \nAIC: 14555.71 \n\n\ncode R\n# 6. Calculer les probabilités pour chaque niveau de Santé par sexe\npred_prob_clean_sex_health &lt;- predict(model_clean_sex_health, type = \"probs\")\n\n# Ajouter les probabilités au dataframe nettoyé\nmy_data_frame_clean$prob_poor &lt;- pred_prob_clean_sex_health[, \"Poor\"]\nmy_data_frame_clean$prob_fair &lt;- pred_prob_clean_sex_health[, \"Fair\"]\nmy_data_frame_clean$prob_good &lt;- pred_prob_clean_sex_health[, \"Good\"]\n\n# 7. Visualisation avec ggplot et ajout de commentaires pour les courbes\np_health &lt;- ggplot(my_data_frame_clean, aes(x = distance_abs_2)) +\n  geom_line(aes(y = prob_poor, color = \"Poor\"), size = 1) +\n  geom_line(aes(y = prob_fair, color = \"Fair\"), size = 1) +\n  geom_line(aes(y = prob_good, color = \"Good\"), size = 1) +\n  labs(title = \"Probabilité d'être en bonne santé selon l'écart aux normes et par sexe\",\n       x = \"Distance aux Normes (Z-score)\",\n       y = \"Probabilité\") +\n  scale_color_manual(values = c(\"Poor\" = \"red\", \n                                \"Fair\" = \"orange\", \n                                \"Good\" = \"green\")) +\n  theme_minimal() +\n  facet_wrap(~ Sex) +  # Facette par Sexe\n  theme(legend.title = element_blank())  # Enlever le titre de la légende\n\n# 8. Rendre le graphique interactif avec plotly et ajouter des annotations\np_interactive_health &lt;- ggplotly(p_health)\n\n# Ajouter des annotations pour chaque courbe\np_interactive_health &lt;- p_interactive_health %&gt;%\n  layout(\n    annotations = list(\n      list(\n        x = 0.5, y = 0.8, \n        text = \"Probabilité Poor\", \n        showarrow = TRUE, \n        arrowhead = 2,\n        ax = -50, ay = -50\n      ),\n      list(\n        x = 0.5, y = 0.6, \n        text = \"Probabilité Fair\", \n        showarrow = TRUE, \n        arrowhead = 2,\n        ax = -50, ay = -50\n      ),\n      list(\n        x = 0.5, y = 0.4, \n        text = \"Probabilité Good\", \n        showarrow = TRUE, \n        arrowhead = 2,\n        ax = -50, ay = -50\n      )\n    )\n  )\n\n# Afficher le graphique interactif\np_interactive_health\n\n\n\n\n\n\n\n\ncode R\n# Créer la variable revenu en fonction de CRITREVENU\nmy_data_frame$revenu &lt;- NA  # Initialisation de la variable\n\n# Assignation des tranches de revenu\nmy_data_frame$revenu[my_data_frame$CRITREVENU %in% c(1, 2)] &lt;- \"Moins de 1000 euros\"\nmy_data_frame$revenu[my_data_frame$CRITREVENU %in% c(3, 4)] &lt;- \"1000 à 1499 euros\"\nmy_data_frame$revenu[my_data_frame$CRITREVENU %in% c(5, 6)] &lt;- \"1500 à 2499 euros\"\nmy_data_frame$revenu[my_data_frame$CRITREVENU %in% c(7, 8, 9, 10)] &lt;- \"2500 euros et plus\"\n\n# Convertir la variable revenu en facteur\nmy_data_frame$revenu &lt;- factor(my_data_frame$revenu, \n                               levels = c(\"Moins de 1000 euros\", \"1000 à 1499 euros\", \"1500 à 2499 euros\", \"2500 euros et plus\"))\n\n# Vérifier les niveaux de la nouvelle variable revenu\nsummary(my_data_frame$revenu)\n\n\nMoins de 1000 euros   1000 à 1499 euros   1500 à 2499 euros  2500 euros et plus \n                766                1280                2241                3775 \n               NA's \n               1172 \n\n\n\n\ncode R\n# Charger les librairies nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# 2. Vérifier les valeurs manquantes dans le dataframe\n#summary(my_data_frame)\n\n# 3. Supprimer les lignes contenant des valeurs manquantes dans les colonnes pertinentes\nmy_data_frame_clean &lt;- my_data_frame[complete.cases(my_data_frame[c(\"satisfaction\", \"Sex\", \"distance_abs_2\", \"revenu\")]), ]\n\n# Vérification de la taille du dataframe nettoyé\nnrow(my_data_frame_clean)  # Assure-toi que la taille est correcte\n\n\n[1] 8057\n\n\ncode R\n# 4. Convertir les variables catégoriques en facteurs avec les niveaux appropriés\nmy_data_frame_clean$satisfaction &lt;- factor(my_data_frame_clean$satisfaction, levels = c(\"Low\", \"Medium\", \"High\"))\nmy_data_frame_clean$Sex &lt;- factor(my_data_frame_clean$Sex, levels = c(\"Men\", \"Women\"))\n\n\nmy_data_frame_clean$revenu &lt;- factor(my_data_frame_clean$revenu, \n                                     levels = c(\"Moins de 1000 euros\", \"1000 à 1499 euros\", \n                                                \"1500 à 2499 euros\", \"2500 euros et plus\"),\n                                     labels = c(\"&lt;1000\", \"[1000-1499]\", \"[1500-2499]\", \"≥2500\"))\n\n# 5. Ajuster le modèle de régression logistique ordinale avec interaction entre Sexe, revenu et distance_abs_2\nmodel_clean_sex_revenu &lt;- polr(as.factor(satisfaction) ~ distance_abs_2 * Sex * revenu, \n                               data = my_data_frame_clean, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_clean_sex_revenu)\n\n\nCall:\npolr(formula = as.factor(satisfaction) ~ distance_abs_2 * Sex * \n    revenu, data = my_data_frame_clean, method = \"logistic\")\n\nCoefficients:\n                                             Value Std. Error t value\ndistance_abs_2                            -0.15950     0.1647 -0.9683\nSexWomen                                  -0.32601     0.2353 -1.3856\nrevenu[1000-1499]                         -0.06179     0.2271 -0.2721\nrevenu[1500-2499]                         -0.42024     0.1997 -2.1042\nrevenu≥2500                               -1.08504     0.1889 -5.7434\ndistance_abs_2:SexWomen                    0.22862     0.2295  0.9961\ndistance_abs_2:revenu[1000-1499]          -0.02571     0.2198 -0.1170\ndistance_abs_2:revenu[1500-2499]          -0.11661     0.1912 -0.6099\ndistance_abs_2:revenu≥2500                 0.14320     0.1780  0.8046\nSexWomen:revenu[1000-1499]                 0.04886     0.2999  0.1629\nSexWomen:revenu[1500-2499]                -0.06160     0.2701 -0.2280\nSexWomen:revenu≥2500                       0.07601     0.2558  0.2971\ndistance_abs_2:SexWomen:revenu[1000-1499] -0.09139     0.2959 -0.3089\ndistance_abs_2:SexWomen:revenu[1500-2499]  0.03572     0.2659  0.1343\ndistance_abs_2:SexWomen:revenu≥2500       -0.32040     0.2501 -1.2813\n\nIntercepts:\n            Value   Std. Error t value\nLow|Medium  -1.3544  0.1766    -7.6705\nMedium|High -0.1353  0.1759    -0.7691\n\nResidual Deviance: 17140.82 \nAIC: 17174.82 \n\n\ncode R\n# 6. Calculer les probabilités pour chaque niveau de satisfaction par sexe et revenu\npred_prob_clean_sex_revenu &lt;- predict(model_clean_sex_revenu, type = \"probs\")\n\n# Ajouter les probabilités au dataframe nettoyé\nmy_data_frame_clean$prob_high &lt;- pred_prob_clean_sex_revenu[, \"High\"]\nmy_data_frame_clean$prob_medium &lt;- pred_prob_clean_sex_revenu[, \"Medium\"]\nmy_data_frame_clean$prob_low &lt;- pred_prob_clean_sex_revenu[, \"Low\"]\n\np &lt;- ggplot(my_data_frame_clean, aes(x = distance_abs_2)) +\n  geom_line(aes(y = prob_high, color = \"High\"), size = 1) +\n  geom_line(aes(y = prob_medium, color = \"Medium\"), size = 1) +\n  geom_line(aes(y = prob_low, color = \"Low\"), size = 1) +\n  labs(title = \"Probabilité d'être satisfait selon l'écart aux normes, par Sexe et Revenu\",\n       x = \"Distance aux Normes (Z-score)\",\n       y = \"Probabilité\") +\n  scale_color_manual(values = c(\"High\" = \"blue\", \"Medium\" = \"orange\", \"Low\" = \"red\")) +\n  theme_minimal() +\n  facet_grid(revenu ~ Sex) +  # Facet verticalement par revenu et horizontalement par sexe\n  theme(\n    legend.title = element_blank(),\n    strip.text.y = element_text(size = 10),  # Réduire la taille des labels des facettes\n    panel.spacing = unit(2, \"lines\")  # Augmenter l'espacement vertical entre facettes\n  )\n\n# Rendre interactif\np_interactive &lt;- ggplotly(p)\n\n# Afficher le graphique\np_interactive\n\n\n\n\n\n\n\n\ncode R\n# Charger les librairies nécessaires\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(plotly)\n\n\n\n# Supprimer les lignes contenant des valeurs manquantes dans les colonnes pertinentes\nmy_data_frame_clean &lt;- my_data_frame[complete.cases(my_data_frame[c(\"Santé\", \"Sex\", \"distance_abs_2\", \"revenu\")]), ]\n\n# Convertir les variables catégoriques en facteurs avec les niveaux appropriés\nmy_data_frame_clean$Sex &lt;- factor(my_data_frame_clean$Sex, levels = c(\"Men\", \"Women\"))\n\nmy_data_frame_clean$revenu &lt;- factor(my_data_frame_clean$revenu, \n                                     levels = c(\"Moins de 1000 euros\", \"1000 à 1499 euros\", \n                                                \"1500 à 2499 euros\", \"2500 euros et plus\"),\n                                     labels = c(\"&lt;1000\", \"[1000-1499]\", \"[1500-2499]\", \"≥2500\"))\n\n# Ajuster le modèle de régression logistique ordinale avec interaction entre Sexe, revenu et distance_abs_2\nmodel_clean_sex_revenu &lt;- polr(Santé ~ distance_abs_2 * Sex * revenu, \n                               data = my_data_frame_clean, method = \"logistic\")\n\n# Résumé du modèle\nsummary(model_clean_sex_revenu)\n\n\nCall:\npolr(formula = Santé ~ distance_abs_2 * Sex * revenu, data = my_data_frame_clean, \n    method = \"logistic\")\n\nCoefficients:\n                                             Value Std. Error t value\ndistance_abs_2                            -0.07229     0.1772 -0.4079\nSexWomen                                   0.02646     0.2401  0.1102\nrevenu[1000-1499]                         -0.17956     0.2341 -0.7672\nrevenu[1500-2499]                         -0.61613     0.2096 -2.9391\nrevenu≥2500                               -1.35968     0.2034 -6.6848\ndistance_abs_2:SexWomen                    0.09937     0.2390  0.4157\ndistance_abs_2:revenu[1000-1499]          -0.08366     0.2352 -0.3558\ndistance_abs_2:revenu[1500-2499]          -0.20282     0.2118 -0.9578\ndistance_abs_2:revenu≥2500                -0.11564     0.2024 -0.5713\nSexWomen:revenu[1000-1499]                 0.09874     0.3086  0.3199\nSexWomen:revenu[1500-2499]                -0.29406     0.2841 -1.0349\nSexWomen:revenu≥2500                      -0.07925     0.2746 -0.2886\ndistance_abs_2:SexWomen:revenu[1000-1499] -0.11806     0.3100 -0.3809\ndistance_abs_2:SexWomen:revenu[1500-2499]  0.26781     0.2862  0.9357\ndistance_abs_2:SexWomen:revenu≥2500        0.15741     0.2737  0.5750\n\nIntercepts:\n          Value   Std. Error t value\nGood|Fair -0.0474  0.1802    -0.2629\nFair|Poor  1.5620  0.1821     8.5795\n\nResidual Deviance: 12216.75 \nAIC: 12250.75 \n\n\ncode R\n# Calculer les probabilités pour chaque niveau de santé par sexe et revenu\npred_prob_clean_sex_revenu &lt;- predict(model_clean_sex_revenu, type = \"probs\")\n\n# Ajouter les probabilités au dataframe nettoyé\nmy_data_frame_clean$prob_high &lt;- pred_prob_clean_sex_revenu[, \"Good\"]\nmy_data_frame_clean$prob_medium &lt;- pred_prob_clean_sex_revenu[, \"Fair\"]\nmy_data_frame_clean$prob_low &lt;- pred_prob_clean_sex_revenu[, \"Poor\"]\n\n# Visualisation avec ggplot\np &lt;- ggplot(my_data_frame_clean, aes(x = distance_abs_2)) +\n  geom_line(aes(y = prob_high, color = \"High\"), size = 1) +\n  geom_line(aes(y = prob_medium, color = \"Medium\"), size = 1) +\n  geom_line(aes(y = prob_low, color = \"Low\"), size = 1) +\n  labs(title = \"Probabilité d'avoir un bon état de santé selon l'écart aux normes, par Sexe et Revenu\",\n       x = \"Distance aux Normes (Z-score)\",\n       y = \"Probabilité\") +\n  scale_color_manual(values = c(\"High\" = \"blue\", \"Medium\" = \"orange\", \"Low\" = \"red\")) +\n  theme_minimal() +\n  facet_grid(revenu ~ Sex) +  # Facet verticalement par revenu et horizontalement par sexe\n  theme(\n    legend.title = element_blank(),\n    strip.text.y = element_text(size = 10),  # Réduire la taille des labels des facettes\n    panel.spacing = unit(2, \"lines\")  # Augmenter l'espacement vertical entre facettes\n  )\n\n# Rendre interactif\np_interactive &lt;- ggplotly(p)\n\n# Afficher le graphique\np_interactive\n\n\n\n\n\n\n\n\ncode R\nmy_data_frame$distance_abs_2_bins&lt;-as.factor(my_data_frame$distance_abs_2_bins)\nmy_data_frame$satisfaction&lt;-as.factor(my_data_frame$satisfaction)\nrego &lt;- MASS::polr(\n  satisfaction ~ Sex + revenu + age_group + distance_abs_2_bins,\n  data = my_data_frame\n)\n\ntheme_gtsummary_language(\"en\", decimal.mark = \",\")\nrego |&gt; \n  tbl_regression(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  ) |&gt; \n  bold_labels() |&gt; \n  add_global_p(keep = TRUE) |&gt; \n  as_kable_extra(format = \"latex\", booktabs = TRUE) |&gt; \n  kable_styling(latex_options = c(\"hold_position\", \"scale_down\"), full_width = FALSE)\n\n\n\n\n\ncode R\nrego |&gt; \n  ggstats::ggcoef_table(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  )\n\n\n\n\n\n\n\n\n\ncode R\nrego |&gt; \n  broom.helpers::plot_marginal_predictions() |&gt; \n  patchwork::wrap_plots(ncol = 1) &\n  scale_y_continuous(labels = scales::percent) &\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\ncode R\nlibrary(dplyr)\n\n# Vérifier et nettoyer la colonne Sex\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(\n    Sex = trimws(as.character(Sex)),  # Supprime les espaces autour des valeurs\n    Sex = case_when(\n      tolower(Sex) == \"men\" ~ \"Men\",   # Uniformise \"men\" en \"Men\"\n      tolower(Sex) == \"women\" ~ \"Women\",  # Uniformise \"women\" en \"Women\"\n      TRUE ~ NA_character_  # Remplace toutes les autres valeurs par NA\n    )\n  ) %&gt;%\n  drop_na(Sex)  # Supprime les lignes où Sex est NA\n\n# Séparer les données\ndf_men &lt;- my_data_frame %&gt;% filter(Sex == \"Men\")\ndf_women &lt;- my_data_frame %&gt;% filter(Sex == \"Women\")\n\n# Vérifier la séparation\nprint(dim(df_men))   # Nombre de lignes et colonnes pour les hommes\n\n\n[1] 4162 1593\n\n\ncode R\nprint(dim(df_women)) # Nombre de lignes et colonnes pour les femmes\n\n\n[1] 5072 1593\n\n\ncode R\n# Modèles de régression\nrego_men &lt;- polr(\n  satisfaction ~ revenu + age_group + score_scale,\n  data = df_men\n)\n\n\n\n# Fonction pour générer le tableau\ngenerate_table &lt;- function(rego_model) {\n  rego_model |&gt; \n    tbl_regression(\n      exponentiate = TRUE,\n      tidy_fun = broom.helpers::tidy_parameters\n    ) |&gt; \n    bold_labels() |&gt; \n    add_global_p(keep = TRUE) |&gt; \n    as_kable_extra(format = \"latex\", booktabs = TRUE) |&gt; \n    kable_styling(latex_options = c(\"hold_position\", \"scale_down\"), full_width = FALSE)\n}\n\np1&lt;- rego_men |&gt; \n  ggstats::ggcoef_table(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  )\n\np1\n\n\n\n\n\n\n\n\n\ncode R\np2&lt;-rego_men |&gt; \n  broom.helpers::plot_marginal_predictions() |&gt; \n  patchwork::wrap_plots(ncol = 1) &\n  scale_y_continuous(labels = scales::percent) &\n  coord_flip()\np2\n\n\n\n\n\n\n\n\n\ncode R\ndf_women &lt;- df_women %&gt;%\n  mutate(across(where(is.factor), droplevels))\nrego_women &lt;- polr(\n  satisfaction ~ revenu + age_group + score_scale,\n  data = df_women\n)\n\nsummary(rego_women)\n\n\nCall:\npolr(formula = satisfaction ~ revenu + age_group + score_scale, \n    data = df_women)\n\nCoefficients:\n                           Value Std. Error  t value\nrevenu1000 à 1499 euros   0.2604    0.11542   2.2566\nrevenu1500 à 2499 euros   0.4406    0.10790   4.0832\nrevenu2500 euros et plus  0.5379    0.10226   5.2603\nage_group[38-54[         -0.2421    0.07518  -3.2199\nage_group[54-67[         -0.8566    0.07840 -10.9250\nage_group[67-97[         -1.8190    0.11709 -15.5350\nscore_scale2             -0.2358    0.47205  -0.4995\nscore_scale3             -0.2969    0.46379  -0.6402\nscore_scale4             -0.1785    0.46406  -0.3847\nscore_scale5             -0.2060    0.46711  -0.4410\nscore_scaleVery Feminine -0.1623    0.49138  -0.3302\n\nIntercepts:\n           Value    Std. Error t value \nHigh|Low    -1.1607   0.4724    -2.4567\nLow|Medium   0.6977   0.4721     1.4778\n\nResidual Deviance: 9113.95 \nAIC: 9139.95 \n(682 observations effacées parce que manquantes)\n\n\ncode R\np3&lt;-rego_women |&gt; \n  ggstats::ggcoef_table(\n    exponentiate = TRUE,\n    tidy_fun = broom.helpers::tidy_parameters\n  )\np3\n\n\n\n\n\n\n\n\n\ncode R\np4&lt;-rego_women |&gt; \n  broom.helpers::plot_marginal_predictions() |&gt; \n  patchwork::wrap_plots(ncol = 1) &\n  scale_y_continuous(labels = scales::percent) &\n  coord_flip()\n\np4\n\n\n\n\n\n\n\n\n\n\n\ncode R\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# Créer un tableau de proportions\ndf_proportions &lt;- my_data_frame %&gt;%\n  group_by(revenu, score_scale) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  group_by(revenu) %&gt;%\n  mutate(proportion = count / sum(count))  # Calcul de la proportion\n\n# Graphique interactif avec Plotly (barres empilées)\nfig &lt;- plot_ly(df_proportions, \n               x = ~revenu, \n               y = ~proportion, \n               color = ~score_scale, \n               type = \"bar\",\n               text = ~paste0(round(proportion*100, 1), \"%\"), \n               textposition = \"inside\") %&gt;%\n  layout(title = \"Proportion de score_scale par tranche de revenu\",\n         xaxis = list(title = \"Tranche de revenu\"),\n         yaxis = list(title = \"Proportion\", tickformat = \"%\"),\n         barmode = \"stack\")  # Empilement des barres\n\nfig  # Affichage du graphique interactif\n\n\n\n\n\n\n\n\ncode R\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# Créer un tableau de proportions\ndf_proportions &lt;- my_data_frame %&gt;%\n  group_by(CLASSIF, score_scale) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  group_by(CLASSIF) %&gt;%\n  mutate(proportion = count / sum(count))  # Calcul de la proportion\n\n# Graphique interactif avec Plotly (barres empilées)\nfig &lt;- plot_ly(df_proportions, \n               x = ~CLASSIF, \n               y = ~proportion, \n               color = ~score_scale, \n               type = \"bar\",\n               text = ~paste0(round(proportion*100, 1), \"%\"), \n               textposition = \"inside\") %&gt;%\n  layout(title = \"Proportion de score_scale par profession\",\n         xaxis = list(title = \"Profession\"),\n         yaxis = list(title = \"Proportion\", tickformat = \"%\"),\n         barmode = \"stack\")  # Empilement des barres\n\nfig  # Affichage du graphique interactif\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nManoeuvre ou ouvrier spécialisé\n\n\n2\nOuvrier qualifié ou hautement qualifié/ technicien(ne) d’atelier\n\n\n3\nTechnicien(ne)\n\n\n4\nAgent de maîtrise, maîtrise administrative ou commerciale, VRP (non cadre)\n\n\n5\nIngénieur, Cadre\n\n\n6\nEmployé(e) de bureau, Employé(e) de commerce, Personnel de services\n\n\n7\nDirecteur général, Adjoint direct\n\n\n8\nNSP\n\n\n9\nREF\n\n\n\n\n\ncode R\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# Créer un tableau de proportions\ndf_proportions &lt;- my_data_frame %&gt;%\n  group_by(satisfaction, score_scale) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  group_by(satisfaction) %&gt;%\n  mutate(proportion = count / sum(count))  # Calcul de la proportion\n\n# Graphique interactif avec Plotly (barres empilées)\nfig &lt;- plot_ly(df_proportions, \n               x = ~satisfaction, \n               y = ~proportion, \n               color = ~score_scale, \n               type = \"bar\",\n               text = ~paste0(round(proportion*100, 1), \"%\"), \n               textposition = \"inside\") %&gt;%\n  layout(title = \"Proportion de score_scale par degré de satisfaction\",\n         xaxis = list(title = \"Satisfaction\"),\n         yaxis = list(title = \"Proportion\", tickformat = \"%\"),\n         barmode = \"stack\")  # Empilement des barres\n\nfig  # Affichage du graphique interactif\n\n\n\n\n\n\n\n\ncode R\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# Convertir DIPLOM en facteur\nmy_data_frame$DIPLOM &lt;- as.factor(my_data_frame$DIPLOM)\n\n# Créer un tableau de proportions\ndf_proportions &lt;- my_data_frame %&gt;%\n  group_by(DIPLOM, score_scale) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  group_by(DIPLOM) %&gt;%\n  mutate(proportion = count / sum(count))  # Calcul de la proportion\n\n# Ajouter une colonne avec les descriptions des diplômes\ndiplome_labels &lt;- c(\n  \"Vous n'avez jamais été à l'école ou vous l'avez quittée avant la fin du primaire\",\n  \"Aucun diplôme et scolarité interrompue à la fin du primaire ou avant la fin du collège\",\n  \"Aucun diplôme et scolarité jusqu'à la fin du collège et au-delà\",\n  \"CEP\",\n  \"BEPC, brevet élémentaire, brevet des collèges, DNB\",\n  \"CAP, BEP ou diplôme équivalent\",\n  \"Baccalauréat général ou technologique, brevet supérieur\",\n  \"Capacité en droit, DAEU, ESEU\",\n  \"Baccalauréat professionnel, brevet professionnel, de technicien ou d'enseignement, diplôme équivalent\",\n  \"BTS, DUT, DEUST, diplôme de la santé ou social de niveau Bac+2 ou diplôme équivalent\",\n  \"Licence, licence pro, maîtrise ou autre diplôme de niveau Bac+3 ou 4 ou diplôme équivalent\",\n  \"Master, DEA, DESS, diplôme grande école de niveau Bac+5, doctorat de santé\",\n  \"Doctorat de recherche (hors santé)\",\n  \"NSP\",\n  \"REF\"\n)\n\n# Ajouter les libellés des diplômes à df_proportions\ndf_proportions &lt;- df_proportions %&gt;%\n  mutate(DIPLOM_label = diplome_labels[as.numeric(DIPLOM)])\n\n# Graphique interactif avec Plotly (barres empilées)\nfig &lt;- plot_ly(df_proportions, \n               x = ~DIPLOM, \n               y = ~proportion, \n               color = ~score_scale, \n               type = \"bar\",\n               text = ~paste(DIPLOM_label, \"&lt;br&gt;\", round(proportion*100, 1), \"%\"),  # Affichage du libellé et proportion\n               textposition = \"inside\") %&gt;%\n  layout(title = \"Proportion de score_scale par niveau de diplôme\",\n         xaxis = list(title = \"Niveau de diplôme\"),\n         yaxis = list(title = \"Proportion\", tickformat = \"%\"),\n         barmode = \"stack\",  # Empilement des barres\n         hovermode = \"closest\")  # Afficher les informations les plus proches du survol\n\nfig\n\n\n\n\n\n\n\n\ncode R\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# Convertir DIPLOM en facteur\nmy_data_frame$DIPLOM &lt;- as.factor(my_data_frame$DIPLOM)\n# Création des quartiles de distance_abs_2\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(quartile_distance = cut(distance_abs_2, \n                                 breaks = quantile(distance_abs_2, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE), \n                                 include.lowest = TRUE, \n                                 labels = c(\"Q1\", \"Q2\", \"Q3\", \"Q4\")))  # Étiquettes des quartiles\n\n# Créer un tableau de proportions\ndf_proportions &lt;- my_data_frame %&gt;%\n  group_by(DIPLOM, quartile_distance) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  group_by(DIPLOM) %&gt;%\n  mutate(proportion = count / sum(count))  # Calcul de la proportion\n\n# Ajouter une colonne avec les descriptions des diplômes\ndiplome_labels &lt;- c(\n  \"Vous n'avez jamais été à l'école ou vous l'avez quittée avant la fin du primaire\",\n  \"Aucun diplôme et scolarité interrompue à la fin du primaire ou avant la fin du collège\",\n  \"Aucun diplôme et scolarité jusqu'à la fin du collège et au-delà\",\n  \"CEP\",\n  \"BEPC, brevet élémentaire, brevet des collèges, DNB\",\n  \"CAP, BEP ou diplôme équivalent\",\n  \"Baccalauréat général ou technologique, brevet supérieur\",\n  \"Capacité en droit, DAEU, ESEU\",\n  \"Baccalauréat professionnel, brevet professionnel, de technicien ou d'enseignement, diplôme équivalent\",\n  \"BTS, DUT, DEUST, diplôme de la santé ou social de niveau Bac+2 ou diplôme équivalent\",\n  \"Licence, licence pro, maîtrise ou autre diplôme de niveau Bac+3 ou 4 ou diplôme équivalent\",\n  \"Master, DEA, DESS, diplôme grande école de niveau Bac+5, doctorat de santé\",\n  \"Doctorat de recherche (hors santé)\",\n  \"NSP\",\n  \"REF\"\n)\n\n# Ajouter les libellés des diplômes à df_proportions\ndf_proportions &lt;- df_proportions %&gt;%\n  mutate(DIPLOM_label = diplome_labels[as.numeric(DIPLOM)])\n\n# Graphique interactif avec Plotly (barres empilées)\nfig &lt;- plot_ly(df_proportions, \n               x = ~DIPLOM, \n               y = ~proportion, \n               color = ~quartile_distance, \n               type = \"bar\",\n               text = ~paste(DIPLOM_label, \"&lt;br&gt;\", round(proportion*100, 1), \"%\"),  # Affichage du libellé et proportion\n               textposition = \"inside\") %&gt;%\n  layout(title = \"Quartile Distance par niveau de diplôme\",\n         xaxis = list(title = \"Niveau de diplôme\"),\n         yaxis = list(title = \"Proportion\", tickformat = \"%\"),\n         barmode = \"stack\",  # Empilement des barres\n         hovermode = \"closest\")  # Afficher les informations les plus proches du survol\n\nfig\n\n\n\n\n\n\n\n\ncode R\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# Création des quartiles de distance_abs_2\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(quartile_distance = cut(distance_abs_2, \n                                 breaks = quantile(distance_abs_2, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE), \n                                 include.lowest = TRUE, \n                                 labels = c(\"Q1\", \"Q2\", \"Q3\", \"Q4\")))  # Étiquettes des quartiles\n\ntable(my_data_frame$quartile_distance)  # Vérification\n\n\n\n  Q1   Q2   Q3   Q4 \n2309 2308 2308 2309 \n\n\ncode R\n# Calcul des proportions correctes par satisfaction (A2)\ndf_proportions &lt;- my_data_frame %&gt;%\n  group_by(satisfaction, quartile_distance) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  group_by(satisfaction) %&gt;%  # Normalisation par A2 et non par quartile_distance\n  mutate(proportion = count / sum(count))  \n\n# Graphique interactif avec Plotly (barres empilées)\nfig &lt;- plot_ly(df_proportions, \n               x = ~satisfaction, \n               y = ~proportion, \n               color = ~quartile_distance, \n               type = \"bar\",\n               text = ~paste0(round(proportion * 100, 1), \"%\"), \n               textposition = \"inside\") %&gt;%\n  layout(title = \"Proportion de distance aux normes par degré de satisfaction\",\n         xaxis = list(title = \"Satisfaction\"),\n         yaxis = list(title = \"Proportion\", tickformat = \"%\"),\n         barmode = \"stack\")  # Empilement des barres pour que chaque A2 fasse 100%\n\nfig\n\n\n\n\n\n\ncode R\n# Créer un tableau de contingence\ncontingency_table &lt;- table(my_data_frame$satisfaction, my_data_frame$quartile_distance)\n\n# Test du chi-deux\nchi2_test &lt;- chisq.test(contingency_table)\n\n# Résultats\nchi2_test\n\n\n\n    Pearson's Chi-squared test\n\ndata:  contingency_table\nX-squared = 11.811, df = 6, p-value = 0.06633\n\n\n\n\ncode R\ncontingency_table &lt;- table(my_data_frame$satisfaction, my_data_frame$quartile_distance)\nprint(contingency_table)\n\n\n        \n          Q1  Q2  Q3  Q4\n  High   785 779 823 730\n  Low    848 869 861 925\n  Medium 674 657 621 653\n\n\ncode R\nlibrary(nnet)\n\nmy_data_frame$satisfaction &lt;- as.factor(my_data_frame$satisfaction)  # S'assurer que A2 est factorielle\nmy_data_frame$quartile_distance &lt;- as.factor(my_data_frame$quartile_distance)  # Idem\n\nmodel &lt;- multinom(satisfaction ~ quartile_distance, data = my_data_frame)\n\n\n# weights:  15 (8 variable)\ninitial  value 10134.698363 \niter  10 value 10062.232209\nfinal  value 10062.112229 \nconverged\n\n\ncode R\nsummary(model)\n\n\nCall:\nmultinom(formula = satisfaction ~ quartile_distance, data = my_data_frame)\n\nCoefficients:\n       (Intercept) quartile_distanceQ2 quartile_distanceQ3 quartile_distanceQ4\nLow     0.07719688          0.03213488         -0.03205884          0.15955098\nMedium -0.15245629         -0.01787090         -0.12916843          0.04098897\n\nStd. Errors:\n       (Intercept) quartile_distanceQ2 quartile_distanceQ3 quartile_distanceQ4\nLow     0.04952907          0.06991118          0.06949558          0.07002909\nMedium  0.05251254          0.07458776          0.07471907          0.07522514\n\nResidual Deviance: 20124.22 \nAIC: 20140.22 \n\n\ncode R\nlibrary(ggeffects)\npred &lt;- ggeffect(model, terms = \"quartile_distance\")\nplot(pred)  # Visualisation des probabilités",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notre Mesure: Le Cultural Gender Normativity Index (CGNI)</span>"
    ]
  },
  {
    "objectID": "construction_indice.html#diplomes-et-distance-aux-normes-de-genre",
    "href": "construction_indice.html#diplomes-et-distance-aux-normes-de-genre",
    "title": "1  Notre Mesure: Le Cultural Gender Normativity Index (CGNI)",
    "section": "1.4 Diplomes et distance aux normes de genre",
    "text": "1.4 Diplomes et distance aux normes de genre\n\n\ncode R\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# Convertir DIPLOM et Sex en facteurs\nmy_data_frame$DIPLOM &lt;- as.factor(my_data_frame$DIPLOM)\nmy_data_frame$Sex &lt;- as.factor(my_data_frame$Sex)\n\n# Création des quartiles de distance_abs_2\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(quartile_distance = cut(distance_abs_2, \n                                 breaks = quantile(distance_abs_2, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE), \n                                 include.lowest = TRUE, \n                                 labels = c(\"Q1\", \"Q2\", \"Q3\", \"Q4\")))  # Étiquettes des quartiles\n\n# Créer un tableau de proportions\ndf_proportions &lt;- my_data_frame %&gt;%\n  group_by(Sex, DIPLOM, quartile_distance) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  group_by(Sex, DIPLOM) %&gt;%\n  mutate(proportion = count / sum(count))  # Calcul de la proportion\n\n# Ajouter une colonne avec les descriptions des diplômes\ndiplome_labels &lt;- c(\n  \"Vous n'avez jamais été à l'école ou vous l'avez quittée avant la fin du primaire\",\n  \"Aucun diplôme et scolarité interrompue à la fin du primaire ou avant la fin du collège\",\n  \"Aucun diplôme et scolarité jusqu'à la fin du collège et au-delà\",\n  \"CEP\",\n  \"BEPC, brevet élémentaire, brevet des collèges, DNB\",\n  \"CAP, BEP ou diplôme équivalent\",\n  \"Baccalauréat général ou technologique, brevet supérieur\",\n  \"Capacité en droit, DAEU, ESEU\",\n  \"Baccalauréat professionnel, brevet professionnel, de technicien ou d'enseignement, diplôme équivalent\",\n  \"BTS, DUT, DEUST, diplôme de la santé ou social de niveau Bac+2 ou diplôme équivalent\",\n  \"Licence, licence pro, maîtrise ou autre diplôme de niveau Bac+3 ou 4 ou diplôme équivalent\",\n  \"Master, DEA, DESS, diplôme grande école de niveau Bac+5, doctorat de santé\",\n  \"Doctorat de recherche (hors santé)\",\n  \"NSP\",\n  \"REF\"\n)\n\n# Ajouter les libellés des diplômes à df_proportions\ndf_proportions &lt;- df_proportions %&gt;%\n  mutate(DIPLOM_label = diplome_labels[as.numeric(DIPLOM)])\n\n# Séparer les données en deux sous-ensembles (Hommes et Femmes)\ndf_men &lt;- df_proportions %&gt;% filter(Sex == \"Men\")\ndf_women &lt;- df_proportions %&gt;% filter(Sex == \"Women\")\n\n# Graphique pour les hommes\nfig_men &lt;- plot_ly(df_men, \n                   x = ~DIPLOM, \n                   y = ~proportion, \n                   color = ~quartile_distance, \n                   type = \"bar\",\n                   text = ~paste(DIPLOM_label, \"&lt;br&gt;\", round(proportion*100, 1), \"%\"),  # Affichage du libellé et proportion\n                   textposition = \"inside\") %&gt;%\n  layout(title = \"Proportion de score_scale par niveau de diplôme (Hommes)\",\n         xaxis = list(title = \"Niveau de diplôme\"),\n         yaxis = list(title = \"Proportion\", tickformat = \"%\"),\n         barmode = \"stack\",  # Empilement des barres\n         hovermode = \"closest\")  # Afficher les informations les plus proches du survol\n\n# Graphique pour les femmes\nfig_women &lt;- plot_ly(df_women, \n                     x = ~DIPLOM, \n                     y = ~proportion, \n                     color = ~quartile_distance, \n                     type = \"bar\",\n                     text = ~paste(DIPLOM_label, \"&lt;br&gt;\", round(proportion*100, 1), \"%\"),  # Affichage du libellé et proportion\n                     textposition = \"inside\") %&gt;%\n  layout(title = \"Proportion de score_scale par niveau de diplôme (Femmes)\",\n         xaxis = list(title = \"Niveau de diplôme\"),\n         yaxis = list(title = \"Proportion\", tickformat = \"%\"),\n         barmode = \"stack\",  # Empilement des barres\n         hovermode = \"closest\")  # Afficher les informations les plus proches du survol\n\n# Afficher les deux graphiques séparés\nfig_men\n\n\n\n\n\n\ncode R\nfig_women\n\n\n\n\n\n\n\n\ncode R\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# Création des quartiles de distance_abs_2\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(quartile_distance = cut(distance_abs_2, \n                                 breaks = quantile(distance_abs_2, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE), \n                                 include.lowest = TRUE, \n                                 labels = c(\"Q1\", \"Q2\", \"Q3\", \"Q4\")))  # Étiquettes des quartiles\n\ntable(my_data_frame$quartile_distance)  # Vérification\n\n\n\n  Q1   Q2   Q3   Q4 \n2309 2308 2308 2309 \n\n\ncode R\n# Calcul des proportions correctes par satisfaction (A2)\ndf_proportions &lt;- my_data_frame %&gt;%\n  group_by(Santé, quartile_distance) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  group_by(Santé) %&gt;%  # Normalisation par A2 et non par quartile_distance\n  mutate(proportion = count / sum(count))  \n\n# Graphique interactif avec Plotly (barres empilées)\nfig &lt;- plot_ly(df_proportions, \n               x = ~Santé, \n               y = ~proportion, \n               color = ~quartile_distance, \n               type = \"bar\",\n               text = ~paste0(round(proportion * 100, 1), \"%\"), \n               textposition = \"inside\") %&gt;%\n  layout(title = \"Proportion de distance aux normes par état de Santé\",\n         xaxis = list(title = \"Santé\"),\n         yaxis = list(title = \"Proportion\", tickformat = \"%\"),\n         barmode = \"stack\")  # Empilement des barres pour que chaque A2 fasse 100%\n\nfig\n\n\n\n\n\n\ncode R\n# Créer un tableau de contingence\ncontingency_table &lt;- table(my_data_frame$Santé, my_data_frame$quartile_distance)\n\n# Test du chi-deux\nchi2_test &lt;- chisq.test(contingency_table)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notre Mesure: Le Cultural Gender Normativity Index (CGNI)</span>"
    ]
  },
  {
    "objectID": "construction_indice.html#comparaison-des-modèles-suite",
    "href": "construction_indice.html#comparaison-des-modèles-suite",
    "title": "1  Notre Mesure: Le Cultural Gender Normativity Index (CGNI)",
    "section": "1.5 Comparaison des modèles (Suite)",
    "text": "1.5 Comparaison des modèles (Suite)\n\n\ncode R\nmy_data_frame$Sex &lt;- as.factor(my_data_frame$Sex)\n\n# Modèle avec 'identity'\nmodel_identity &lt;- glm(Sex ~ identity, data = my_data_frame, family = binomial)\n\n# Modèle avec 'score'\nmodel_score &lt;- glm(Sex ~ score, data = my_data_frame, family = binomial)\n\n# Comparer les modèles via les critères AIC (Akaike Information Criterion)\naic_identity &lt;- AIC(model_identity)\naic_score &lt;- AIC(model_score)\n\n# Comparer les modèles via la deviance\ndeviance_identity &lt;- deviance(model_identity)\ndeviance_score &lt;- deviance(model_score)\n\n# Résumé des modèles\nsummary(model_identity)\n\n\n\nCall:\nglm(formula = Sex ~ identity, family = binomial, data = my_data_frame)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  3.00930    0.08534   35.26   &lt;2e-16 ***\nidentity    -7.59704    0.22373  -33.96   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 12711  on 9233  degrees of freedom\nResidual deviance: 11162  on 9232  degrees of freedom\nAIC: 11166\n\nNumber of Fisher Scoring iterations: 4\n\n\ncode R\nsummary(model_score)\n\n\n\nCall:\nglm(formula = Sex ~ score, family = binomial, data = my_data_frame)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.58503    0.03010  -19.43   &lt;2e-16 ***\nscore        1.04195    0.02254   46.22   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 12711.2  on 9233  degrees of freedom\nResidual deviance:  8323.5  on 9232  degrees of freedom\nAIC: 8327.5\n\nNumber of Fisher Scoring iterations: 5\n\n\ncode R\n# Affichage des AIC et deviance\ncat(\"AIC for model with 'identity':\", aic_identity, \"\\n\")\n\n\nAIC for model with 'identity': 11166.46 \n\n\ncode R\ncat(\"AIC for model with 'score':\", aic_score, \"\\n\")\n\n\nAIC for model with 'score': 8327.457 \n\n\ncode R\ncat(\"Deviance for model with 'identity':\", deviance_identity, \"\\n\")\n\n\nDeviance for model with 'identity': 11162.46 \n\n\ncode R\ncat(\"Deviance for model with 'score':\", deviance_score, \"\\n\")\n\n\nDeviance for model with 'score': 8323.457 \n\n\n\n\ncode R\nlibrary(pROC)\n\n# Calculer la probabilité prédite pour chaque modèle\nprob_identity &lt;- predict(model_identity, type = \"response\")\nprob_score &lt;- predict(model_score, type = \"response\")\n\n# Calculer la courbe ROC et AUC pour chaque modèle\nroc_identity &lt;- roc(my_data_frame$Sex, prob_identity)\nroc_score &lt;- roc(my_data_frame$Sex, prob_score)\n\n# Afficher les résultats AUC\ncat(\"AUC for model with 'identity':\", auc(roc_identity), \"\\n\")\n\n\nAUC for model with 'identity': 0.7242187 \n\n\ncode R\ncat(\"AUC for model with 'score':\", auc(roc_score), \"\\n\")\n\n\nAUC for model with 'score': 0.8676684 \n\n\ncode R\n# Tracer les courbes ROC\nplot(roc_identity, col = \"blue\", main = \"Courbes ROC pour 'identity' et 'score'\")\nplot(roc_score, col = \"red\", add = TRUE)\nlegend(\"bottomright\", legend = c(\"identity\", \"score\"), col = c(\"blue\", \"red\"), lwd = 2)\n\n\n\n\n\n\n\n\n\n\n\ncode R\n# Convertir satisfaction en numérique\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(satisfaction_numeric = case_when(\n    satisfaction == \"Low\" ~ 1,\n    satisfaction == \"Medium\" ~ 2,\n    satisfaction == \"High\" ~ 3,\n    TRUE ~ NA_real_  # Gérer les valeurs manquantes si nécessaire\n  ))\n\n# Vérifier la conversion\ntable(my_data_frame$satisfaction_numeric)\n\n\n\n   1    2    3 \n3503 2605 3117 \n\n\ncode R\n# Test de corrélation de Spearman entre satisfaction (ordinale) et distance_quartile (continue)\ncor.test(my_data_frame$satisfaction_numeric, my_data_frame$distance_abs_2, method = \"spearman\")\n\n\n\n    Spearman's rank correlation rho\n\ndata:  my_data_frame$satisfaction_numeric and my_data_frame$distance_abs_2\nS = 1.3324e+11, p-value = 0.07856\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n        rho \n-0.01831584 \n\n\ncode R\n# Convertir 'santé' en numérique (Good = 1, Fair = 2, Poor = 3)\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(santé_numeric = case_when(\n    Santé == \"Good\" ~ 1,\n    Santé == \"Fair\" ~ 2,\n    Santé == \"Poor\" ~ 3,\n    TRUE ~ NA_real_\n  ))\n\n# Test de corrélation de Spearman entre santé (ordinale) et distance_abs_2\ncor.test(my_data_frame$santé_numeric, my_data_frame$distance_abs_2, method = \"spearman\")\n\n\n\n    Spearman's rank correlation rho\n\ndata:  my_data_frame$santé_numeric and my_data_frame$distance_abs_2\nS = 1.2994e+11, p-value = 0.6901\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n         rho \n-0.004159822 \n\n\n\n\ncode R\n# Régression logistique ordinale\nlibrary(MASS)\nrego_ordinal &lt;- polr(satisfaction ~ distance_abs_2, data = my_data_frame, method = \"logistic\")\nsummary(rego_ordinal)\n\n\nCall:\npolr(formula = satisfaction ~ distance_abs_2, data = my_data_frame, \n    method = \"logistic\")\n\nCoefficients:\n                 Value Std. Error t value\ndistance_abs_2 0.02273    0.03199  0.7105\n\nIntercepts:\n           Value    Std. Error t value \nHigh|Low    -0.6543   0.0340   -19.2524\nLow|Medium   0.9511   0.0348    27.3139\n\nResidual Deviance: 20135.53 \nAIC: 20141.53 \n(9 observations effacées parce que manquantes)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notre Mesure: Le Cultural Gender Normativity Index (CGNI)</span>"
    ]
  },
  {
    "objectID": "construction_indice.html#sexe-ou-genre-pour-prédire-la-satisfaction",
    "href": "construction_indice.html#sexe-ou-genre-pour-prédire-la-satisfaction",
    "title": "1  Notre Mesure: Le Cultural Gender Normativity Index (CGNI)",
    "section": "1.6 Sexe ou Genre pour prédire la Satisfaction ?",
    "text": "1.6 Sexe ou Genre pour prédire la Satisfaction ?\n\n\ncode R\n# Convertir les variables en facteurs si nécessaire\nmy_data_frame$DIPLOM &lt;- as.factor(my_data_frame$DIPLOM)\nmy_data_frame$Sex &lt;- as.factor(my_data_frame$Sex)\nmy_data_frame$CLASSIF &lt;- as.factor(my_data_frame$CLASSIF)\nmy_data_frame$revenu &lt;- as.factor(my_data_frame$revenu)\nmy_data_frame$Santé &lt;- as.factor(my_data_frame$Santé)\nmy_data_frame$satisfaction &lt;- as.factor(my_data_frame$satisfaction)\nmy_data_frame$SITUA &lt;- as.factor(my_data_frame$SITUA)\nmy_data_frame$CS2D &lt;- as.factor(my_data_frame$CS2D)\n\n# Créer une fonction pour comparer les modèles avec 'score' et 'Sex' comme prédicteurs\ncompare_models &lt;- function(variable) {\n  # Affichage de la variable actuellement traitée\n  cat(\"Traitement de la variable :\", variable, \"\\n\")\n  \n  # Modèle avec score comme prédicteur\n  model_score &lt;- polr(as.formula(paste(variable, \"~ score_normalise_2\")), data = my_data_frame, method = \"logistic\")\n  \n  # Modèle avec sexe comme prédicteur\n  model_sex &lt;- polr(as.formula(paste(variable, \"~ Sex\")), data = my_data_frame, method = \"logistic\")\n  \n  # Comparer l'AIC des deux modèles\n  aic_score &lt;- AIC(model_score)\n  aic_sex &lt;- AIC(model_sex)\n  \n  # Comparer et retourner le meilleur modèle\n  if (aic_score &lt; aic_sex) {\n    return(data.frame(variable = variable, best_predictor = \"Score\", AIC_score = aic_score, AIC_sex = aic_sex))\n  } else {\n    return(data.frame(variable = variable, best_predictor = \"Sex\", AIC_score = aic_score, AIC_sex = aic_sex))\n  }\n}\n\n# Liste des variables d'intérêt à analyser\nvariables &lt;- c(\"DIPLOM\", \"CLASSIF\", \"SITUA\", \"satisfaction\", \"Santé\", \"revenu\", \"CS2D\")\n\n# Appliquer la fonction pour chaque variable d'intérêt et combiner les résultats\nresults &lt;- do.call(rbind, lapply(variables, compare_models))\n\n\nTraitement de la variable : DIPLOM \nTraitement de la variable : CLASSIF \nTraitement de la variable : SITUA \nTraitement de la variable : satisfaction \nTraitement de la variable : Santé \nTraitement de la variable : revenu \nTraitement de la variable : CS2D \n\n\ncode R\n# Afficher les résultats sous forme de tableau\nprint(results)\n\n\n      variable best_predictor AIC_score   AIC_sex\n1       DIPLOM          Score 41875.234 41877.259\n2      CLASSIF            Sex  9541.198  9303.852\n3        SITUA            Sex 24323.188 24316.900\n4 satisfaction            Sex 20141.821 20141.519\n5        Santé            Sex 14570.078 14563.140\n6       revenu            Sex 19741.506 19729.137\n7         CS2D          Score 29090.088 29114.292",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notre Mesure: Le Cultural Gender Normativity Index (CGNI)</span>"
    ]
  },
  {
    "objectID": "construction_indice.html#genre-et-professions",
    "href": "construction_indice.html#genre-et-professions",
    "title": "1  Notre Mesure: Le Cultural Gender Normativity Index (CGNI)",
    "section": "1.7 Genre et Professions",
    "text": "1.7 Genre et Professions\n\n\ncode R\nlibrary(readxl)\nmy_data_frame$CS2D&lt;-as.numeric(my_data_frame$CS2D)\nListes_professions &lt;- read_excel(\"professions.xls\")\n\nmapping_codes_libelles &lt;- Listes_professions[, c(\"Code\", \"Libelle\")]\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  left_join(mapping_codes_libelles, by = c(\"CS2D\" = \"Code\")) %&gt;%\n  mutate(CS2D = Libelle)\n# Charger la bibliothèque dplyr pour manipuler les données\nlibrary(dplyr)\n\n\nhead(my_data_frame$CS2D)\n\n\n[1] \"Chefs d'entreprise de 10 salariés ou plus\"\n[2] NA                                         \n[3] \"Agriculteurs sur petite exploitation\"     \n[4] NA                                         \n[5] NA                                         \n[6] NA                                         \n\n\ncode R\nsummary(my_data_frame$CS2D)\n\n\n   Length     Class      Mode \n     9234 character character \n\n\ncode R\n# Compter les occurrences des professions\nprofession_counts &lt;- table(my_data_frame$CS2D)\n\n# Trier les professions par fréquence, du plus grand au plus petit\nprofession_counts_sorted &lt;- sort(profession_counts, decreasing = TRUE)\n\n# Sélectionner les 10 professions les plus représentées\ntop_10_professions &lt;- head(profession_counts_sorted, 10)\n\n# Afficher les 10 professions les plus représentées\ntop_10_professions\n\n\n\n                                                Artisans \n                                                     332 \n                                   Professions libérales \n                                                     228 \n                                Commerçants et assimilés \n                                                     219 \n                   Agriculteurs sur moyenne exploitation \n                                                     144 \n               Chefs d'entreprise de 10 salariés ou plus \n                                                     111 \n                    Agriculteurs sur petite exploitation \n                                                     105 \n                  Professeurs, professions scientifiques \n                                                      90 \nProfessions de l'information, des arts et des spectacles \n                                                      88 \n                    Agriculteurs sur grande exploitation \n                                                      79 \n                          Cadres de la fonction publique \n                                                      74 \n\n\ncode R\n# Filtrer les données pour ne garder que les 10 professions les plus représentées\ntop_10_data &lt;- my_data_frame[my_data_frame$CS2D %in% names(top_10_professions), ]\n\n# Créer un tableau de proportions\ntop_10_data &lt;- my_data_frame %&gt;%\n  group_by(Sex, CS2D, quartile_distance, score_normalise_2, distance_abs_2, score_scale) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  group_by(Sex, CS2D) %&gt;%\n  mutate(proportion = count / sum(count))  # Calcul de la proportion\n\n\n# Séparer les données en deux sous-ensembles (Hommes et Femmes)\ndf_men &lt;- top_10_data %&gt;% filter(Sex == \"Men\")\ndf_women &lt;- top_10_data %&gt;% filter(Sex == \"Women\")\n\n# Graphique pour les hommes\nfig_men &lt;- plot_ly(df_men, \n                   x = ~CS2D, \n                   y = ~proportion, \n                   color = ~quartile_distance, \n                   type = \"bar\",\n                     # Affichage du libellé et proportion\n                   textposition = \"inside\") %&gt;%\n  layout(title = \"Proportion de score_scale par niveau de diplôme (Hommes)\",\n         xaxis = list(title = \"profession\"),\n         yaxis = list(title = \"Proportion\", tickformat = \"%\"),\n         barmode = \"stack\",  # Empilement des barres\n         hovermode = \"closest\")  # Afficher les informations les plus proches du survol\n\n# Graphique pour les femmes\nfig_women &lt;- plot_ly(df_women, \n                     x = ~CS2D, \n                     y = ~proportion, \n                     color = ~quartile_distance, \n                     type = \"bar\",\n                       \n                     textposition = \"inside\") %&gt;%\n  layout(title = \"Proportion de score_scale par profession (Femmes)\",\n         xaxis = list(title = \"Profession\"),\n         yaxis = list(title = \"Proportion\", tickformat = \"%\"),\n         barmode = \"stack\",  # Empilement des barres\n         hovermode = \"closest\")  # Afficher les informations les plus proches du survol\n\n# Afficher les deux graphiques séparés\nfig_men\n\n\n\n\n\n\ncode R\nfig_women\n\n\n\n\n\n\n\n\ncode R\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Vérifier que CS2D et Sex sont bien des facteurs\ntop_10_data$CS2D &lt;- as.factor(top_10_data$CS2D)\ntop_10_data$Sex &lt;- as.factor(top_10_data$Sex)\n\n# Calcul du score moyen par profession\nscore_summary &lt;- top_10_data %&gt;%\n  group_by(CS2D) %&gt;%\n  summarise(score_moyen = mean(score_normalise_2, na.rm = TRUE))\n\n# Calcul des proportions Homme/Femme par profession\nsex_distribution &lt;- top_10_data %&gt;%\n  group_by(CS2D, Sex) %&gt;%\n  summarise(n = n(), .groups = \"drop\") %&gt;%\n  group_by(CS2D) %&gt;%\n  mutate(proportion = n / sum(n))\n\n# Fusionner les deux datasets\nsummary_data &lt;- left_join(score_summary, sex_distribution, by = \"CS2D\")\n\n# Visualisation combinée\nggplot(summary_data, aes(x = reorder(CS2D, score_moyen))) +\n  geom_col(aes(y = score_moyen), fill = \"blue\", alpha = 0.6) +\n  geom_point(aes(y = proportion * max(score_moyen), color = Sex), size = 4) +\n  scale_y_continuous(\n    sec.axis = sec_axis(~./max(score_summary$score_moyen), name = \"Proportion H/F\")\n  ) +\n  labs(title = \"Score moyen et proportion H/F par profession\",\n       x = \"Profession (CS2D)\", y = \"Score normalisé moyen\") +\n  coord_flip() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\ncode R\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Vérifier que CS2D et Sex sont bien des facteurs\ntop_10_data$CS2D &lt;- as.factor(top_10_data$CS2D)\ntop_10_data$Sex &lt;- as.factor(top_10_data$Sex)\n\n# Calcul du score moyen par profession\ndistance_summary &lt;- top_10_data %&gt;%\n  group_by(CS2D) %&gt;%\n  summarise(distance_moyenne = mean(distance_abs_2, na.rm = TRUE))\n\n# Calcul des proportions Homme/Femme par profession\nsex_distribution &lt;- top_10_data %&gt;%\n  group_by(CS2D, Sex) %&gt;%\n  summarise(n = n(), .groups = \"drop\") %&gt;%\n  group_by(CS2D) %&gt;%\n  mutate(proportion = n / sum(n))\n\n# Fusionner les deux datasets\nsummary_data &lt;- left_join(distance_summary, sex_distribution, by = \"CS2D\")\n\n# Visualisation combinée\nggplot(summary_data, aes(x = reorder(CS2D, distance_moyenne))) +\n  geom_col(aes(y = distance_moyenne), fill = \"blue\", alpha = 0.6) +\n  geom_point(aes(y = proportion * max(distance_moyenne), color = Sex), size = 4) +\n  scale_y_continuous(\n    sec.axis = sec_axis(~./max(distance_summary$distance_moyenne), name = \"Proportion H/F\")\n  ) +\n  labs(title = \"Distance moyenne et proportion H/F par profession\",\n       x = \"Profession (CS2D)\", y = \"Distance moyenne\") +\n  coord_flip() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\ncode R\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Vérifier que CS2D et Sex sont bien des facteurs\ntop_10_data$CS2D &lt;- as.factor(top_10_data$CS2D)\ntop_10_data$Sex &lt;- as.factor(top_10_data$Sex)\n\n# Calcul de la distance moyenne par profession et par sexe\ndistance_summary &lt;- top_10_data %&gt;%\n  group_by(CS2D, Sex) %&gt;%\n  summarise(distance_moyenne = mean(distance_abs_2, na.rm = TRUE), .groups = \"drop\")\n\n# Visualisation\np&lt;-ggplot(distance_summary, aes(x = reorder(CS2D, distance_moyenne), y = distance_moyenne, fill = Sex)) +\n  geom_col(position = \"dodge\") +\n  labs(title = \"Distance moyenne (score_distance) par profession et par sexe\",\n       x = \"Profession (CS2D)\", y = \"Distance moyenne (score_distance)\") +\n  coord_flip() +\n  theme_minimal()\n\np_plotly&lt;-ggplotly(p)\np_plotly\n\n\n\n\n\n\n\n\ncode R\n# Créer un tableau de proportions\ntop_10_data &lt;- my_data_frame %&gt;%\n  group_by(Sex, CS2D, quartile_distance, score_normalise_2, distance_abs_2, score_scale) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  group_by(Sex, CS2D) %&gt;%\n  mutate(proportion = count / sum(count))  # Calcul de la proportion\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\n\n# Vérifier que CS2D, Sex et score_scale sont bien des facteurs\ntop_10_data$CS2D &lt;- as.factor(top_10_data$CS2D)\ntop_10_data$Sex &lt;- as.factor(top_10_data$Sex)\ntop_10_data$score_scale &lt;- as.factor(top_10_data$score_scale)\n\n# Calcul des proportions de score_scale par profession et sexe\nscore_scale_distribution &lt;- top_10_data %&gt;%\n  group_by(CS2D, Sex, score_scale) %&gt;%\n  summarise(n = n(), .groups = \"drop\") %&gt;%\n  group_by(CS2D, Sex) %&gt;%\n  mutate(proportion = n / sum(n))\n\n# Visualisation\nggplot(score_scale_distribution, aes(x = score_scale, y = proportion, fill = Sex)) +\n  geom_col(position = \"dodge\") +\n  facet_wrap(~ CS2D) +\n  labs(title = \"Répartition de score_scale par profession et sexe\",\n       x = \"Score Scale\", y = \"Proportion\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\ncode R\ntop_10_data$CS2D &lt;- as.factor(top_10_data$CS2D)\ntop_10_data$Sex &lt;- as.factor(top_10_data$Sex)\ntop_10_data$score_scale &lt;- as.factor(top_10_data$score_scale)\n\n# Créer une version numérotée (1-10 + NA) pour affichage dans le graphique\ntop_10_data$CS2D_numeric &lt;- as.numeric(top_10_data$CS2D)\n\n# Calcul des proportions de score_scale par profession et sexe\nscore_scale_distribution &lt;- top_10_data %&gt;%\n  group_by(CS2D_numeric, CS2D, Sex, score_scale) %&gt;%\n  summarise(n = n(), .groups = \"drop\") %&gt;%\n  group_by(CS2D_numeric, CS2D, Sex) %&gt;%\n  mutate(proportion = n / sum(n))\n\n# Graphique ggplot\np &lt;- ggplot(score_scale_distribution, aes(x = score_scale, y = proportion, fill = Sex, \n                                          text = paste(\"Profession :\", CS2D))) +\n  geom_col(position = \"dodge\") +\n  facet_wrap(~ CS2D_numeric) +  # Garde les professions sous forme de codes\n  labs(title = \"Répartition de score_scale par profession et sexe\",\n       x = \"Score Scale\", y = \"Proportion\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Convertir en ggplotly avec tooltip interactif\nggplotly(p, tooltip = \"text\")\n\n\n\n\n\n\n\n\ncode R\n# Créer une version numérotée (1-10 + NA) pour affichage dans le graphique\ntop_10_data$CS2D_numeric &lt;- as.numeric(top_10_data$CS2D)\n\n# Calcul des proportions de score_scale par profession et sexe\nscore_scale_distribution &lt;- top_10_data %&gt;%\n  group_by(CS2D_numeric, CS2D, Sex, score_scale) %&gt;%\n  summarise(n = n(), .groups = \"drop\") %&gt;%\n  group_by(CS2D_numeric, CS2D, Sex) %&gt;%\n  mutate(proportion = n / sum(n) * 100)  # Conversion en pourcentage\n\n# Graphique ggplot\np &lt;- ggplot(score_scale_distribution, aes(x = score_scale, y = proportion, fill = Sex, \n                                          text = paste(\"Profession :\", CS2D, \"&lt;br&gt;\",\n                                                       \"Sexe :\", Sex, \"&lt;br&gt;\",\n                                                       \"Proportion :\", round(proportion, 1), \"%\"))) +\n  geom_col(position = \"dodge\") +\n  facet_wrap(~ CS2D_numeric) +  # Garde les professions sous forme de codes\n  labs(title = \"Répartition de score_scale par profession et sexe\",\n       x = \"Score Scale\", y = \"Proportion (%)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Convertir en ggplotly avec tooltip interactif\nggplotly(p, tooltip = \"text\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notre Mesure: Le Cultural Gender Normativity Index (CGNI)</span>"
    ]
  },
  {
    "objectID": "en_cours.html",
    "href": "en_cours.html",
    "title": "3  Mesures Continues du Genre",
    "section": "",
    "text": "3.1 Présentation des données\nLa base de données utilisée porte sur les pratiques culturelles des français, 2018, elle comprend un total de 1572 variables, réparties en plusieurs modules thématiques .\nLa structure thématique des variables se présente comme suit :\nVariables socio démographiques : 190 variables. Loisirs et vacances : 41 variables. Pratiques en amateur : 201 variables. Jeux-vidéo : 29 variables. Films, séries, émissions : 287 variables. Information : 41 variables. Écoute de musique et d’émissions : 109 variables. Bibliothèque et livres : 121 variables. Concerts, cinéma, théâtre, danse et festivals : 233 variables. Musées, expositions et patrimoine : 94 variables. Équipements et internet : 29 variables. Situation principale vis-à-vis du travail et activité professionnelle : 48 variables. Ressources culturelles : 40 variables. Situation dans l’enfance : 103 variables. Logement : 6 variables.\nCette répartition met en évidence la quantité considérable de données relatives aux pratiques culturelles et de loisirs (plus de 1000 variables au total dans ces modules) , qui constitue la base de l’analyse pour la construction des indices de genre continus.\nLe nombre total d’individus dans l’échantillon est de 9 234 .\nL’échantillon est composé de 4 162 hommes et 5 072 femmes .\nOn présente une répartition par âge, revenu, satisfaction, niveau de diplôme, situation d’emploi, état de santé et situation de couple. Pour la majorité de ces caractéristiques (âge, revenu, satisfaction, diplôme, situation emploi, santé, couple), des différences statistiquement signifficatives entre hommes et femmes sont notées (p &lt; 0.001 dans la plupart des cas) .\nOn détaille ensuite la fréquence de participation à diverses pratiques culturelles et en amateur, ventilée par sexe. Ce tableau illustre la différenciation marquée des pratiques selon le genre.\nPar exemple : Le tricot (“Knitting”) est pratiqué par 27% des femmes contre seulement 1.8% des hommes (p &lt; 0.001) . Le bricolage (“DIY”) est l’activité de 64% des hommes contre 45% des femmes (p &lt; 0.001) . La pêche/chasse (“Fishing hunting”) est pratiquée par 17% des hommes et 4.2% des femmes (p &lt; 0.001) . Tenir un journal intime (“Diary”) est l’habitude de 24% des femmes contre 6.8% des hommes (p &lt; 0.001) . La danse (“Dancing”) concerne 35% des femmes et 9.9% des hommes (p &lt; 0.001) . Les jeux vidéo (“Video games”) sont pratiqués par 42% des hommes et 36% des femmes (p &lt; 0.001) .\nCes données sur les pratiques culturelles différenciées sont ensuite utilisées pour construire les indices continus de genre, via l’Analyse des Correspondances Multiples (ACM) et la régression LASSO . Les coordonnées obtenues par l’ACM et les coeffcients de la régression LASSO pour différentes variables culturelles sont les poids utilisés pour calculer ces indices.\ncode R\nlibrary(foreign)\nlibrary(questionr) \nlibrary(ggplot2) \nlibrary(tidyverse) \nlibrary(ggmosaic)\nlibrary(GGally) \nlibrary(dataMaid)\nlibrary(dplyr) \nlibrary(GDAtools)\nlibrary(FactoMineR)\nlibrary(gtsummary) \nlibrary(factoextra)\nlibrary(gtsummary) \nlibrary(kableExtra)\nlibrary(RColorBrewer) \nlibrary(FactoMineR) \nlibrary(xtable) \nlibrary(explor)\nlibrary(MASS)\ncode R\ndata&lt;-read.csv2(\"pc18_quetelet_octobre2023.csv\")\ncode R\ndata$Sex &lt;- factor(data$SEXE, \n                            levels = c(1, 2), \n                            labels = c(\"Men\", \"Women\"))\nmy_data_frame &lt;- data |&gt; dplyr::rename( \n  Knitting = A1001 , \n  Cards_games = A1002,  \n  Gambling = A1003 , \n  Cooking = A1004 , \n  DIY = A1005  ,\n  Vegetable_garden = A1006 , \n  Ornamental_garden = A1007,  \n  Fishing_hunting = A1008 , \n  Collection = A1009  ,\n  Vehicle_custom = A1010 , \n  No_Amateur=A1011,\n  Making_music = A1901  ,\n  Diary = A1902  ,\n  Writing = A1903,  \n  Painting = A1904,  \n  Montage = A1905 , \n  Circus = A1906  ,\n  Pottery = A1907 , \n  Theater = A1908 , \n  Drawing = A1909 , \n  Dancing = A1910,  \n  Photography = A1911  ,\n  Genealogy = A1912 , \n  Science = A1913  ,\n  None = A1914  ,\n  Video_games = B1  ,\n  TV = C1  ,\n  Radio = E1  ,\n  Library = F1  ,\n  Museums = H112,  \n  Internet = I4 , \n  Concert = G2413 )\n\n\nmy_data_frame$Video_games &lt;- ifelse(my_data_frame$Video_games == 1, 1, 0)\nmy_data_frame$TV &lt;- ifelse(my_data_frame$TV == 5, 0, 1)\nmy_data_frame$Radio &lt;- ifelse(my_data_frame$Radio == 5, 0, 1)\nmy_data_frame$Library&lt;- ifelse(my_data_frame$Library == 1, 1, 0)\nmy_data_frame$Museums&lt;- ifelse(my_data_frame$Museums == 1, 0, 1)\nmy_data_frame$Internet&lt;- ifelse(my_data_frame$Internet == 5, 0, 1)\nmy_data_frame$Concert&lt;- ifelse(my_data_frame$Concert == 1, 0, 1)\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(\n    DIPLOMA = case_when(\n      DIPLOM %in% c(1, 2, 3) ~ \"Sans diplôme\",\n      DIPLOM %in% c(4, 5) ~ \"CEP / Brevet / DNB\",\n      DIPLOM == 6 ~ \"CAP / BEP\",\n      DIPLOM == 7 ~ \"Bac général / technologique\",\n      DIPLOM == 8 ~ \"Capacité / DAEU / ESEU\",\n      DIPLOM == 9 ~ \"Bac professionnel / équivalent\",\n      DIPLOM %in% c(10, 11, 12) ~ \"Bac+2 à Bac+5 (hors doctorat)\",\n      DIPLOM == 13 ~ \"Doctorat\",\n      DIPLOM %in% c(14, 15) ~ NA_character_,\n      TRUE ~ NA_character_\n    )\n  )\n\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(satisfaction = case_when(\n    A2 %in% 1 ~ \"Low\",      # 1 à 4 -&gt; Low\n    A2 %in% 2 ~ \"Medium\",   # 5 à 7 -&gt; Medium\n    A2 %in% 3 ~ \"High\",    # 8 à 10 -&gt; High\n    TRUE ~ NA_character_              \n  ))  \nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(Income = case_when(\n    CRITREVENU %in% 1:4 ~ \"Low\",      # 1 à 4 -&gt; Low\n    CRITREVENU %in% 5:7 ~ \"Medium\",   # 5 à 7 -&gt; Medium\n    CRITREVENU %in% 8:10 ~ \"High\",    # 8 à 10 -&gt; High\n    TRUE ~ NA_character_              \n  ))\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(Health = case_when(\n    A15 %in% 1:2 ~ \"Good\",      # 1 à 4 -&gt; Low\n    A15 %in% 3 ~ \"Medium\",   # 5 à 7 -&gt; Medium\n    A15 %in% 4:5 ~ \"Bad\",    # 8 à 10 -&gt; High\n    TRUE ~ NA_character_              \n  ))\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(\n    SITUA_lab = case_when(\n      SITUA == 1 ~ \"Occupe un emploi\",\n      SITUA == 2 ~ \"Apprenti sous contrat ou stagiaire rémunéré\",\n      SITUA == 3 ~ \"Etudiant, élève, en formation ou stagiaire non rémunéré\",\n      SITUA == 4 ~ \"Chômeur (inscrit ou non à Pôle Emploi)\",\n      SITUA == 5 ~ \"Retraité ou retiré des affaires ou en préretraite\",\n      SITUA == 6 ~ \"Femme ou homme au foyer\",\n      SITUA == 7 ~ \"Inactif ou inactive pour cause d'invalidité\",\n      SITUA == 8 ~ \"Autre situation d'inactivité\",\n      SITUA == 9 ~ \"NSP\",\n      SITUA == 10 ~ \"REF\",\n      TRUE ~ NA_character_\n    )\n  )\n\n\n\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(Couple = case_when(\n    VITENCOUPLE %in% 1:2 ~ \"Yes\",     \n    VITENCOUPLE %in% 3~ \"No\",  \n    \n    TRUE ~ NA_character_              \n  ))\n\nquartiles &lt;- quantile(data$AGE, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)\n\nmy_data_frame$age_group &lt;- cut(\n  my_data_frame$AGE,\n  breaks = 4,  # Automatically divide into 4 slices\n  labels = c(\"[15-38[\", \"[38-54[\", \"[54-67[\", \"[67-97[\"),  # Labels optionnels\n  include.lowest = TRUE \n)\ncode R\ntable &lt;- my_data_frame |&gt;\n  tbl_summary(\n    include = c( \"age_group\", \"Income\",\"Health\", \"satisfaction\",\"Couple\" ),\n    by = \"Sex\"\n  ) |&gt;\n  add_overall(last = TRUE) |&gt;\n  add_p()\n\ntable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\nOverall N = 9,2341\np-value2\n\n\n\n\nage_group\n\n\n\n\n\n\n&lt;0.001\n\n\n    [15-38[\n905 (22%)\n1,135 (22%)\n2,040 (22%)\n\n\n\n\n    [38-54[\n1,404 (34%)\n1,590 (31%)\n2,994 (32%)\n\n\n\n\n    [54-67[\n1,454 (35%)\n1,737 (34%)\n3,191 (35%)\n\n\n\n\n    [67-97[\n399 (9.6%)\n610 (12%)\n1,009 (11%)\n\n\n\n\nIncome\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n1,432 (39%)\n1,464 (33%)\n2,896 (36%)\n\n\n\n\n    Low\n762 (21%)\n1,284 (29%)\n2,046 (25%)\n\n\n\n\n    Medium\n1,476 (40%)\n1,644 (37%)\n3,120 (39%)\n\n\n\n\n    Unknown\n492\n680\n1,172\n\n\n\n\nHealth\n\n\n\n\n\n\n&lt;0.001\n\n\n    Bad\n322 (7.8%)\n461 (9.1%)\n783 (8.5%)\n\n\n\n\n    Good\n2,984 (72%)\n3,426 (68%)\n6,410 (70%)\n\n\n\n\n    Medium\n841 (20%)\n1,157 (23%)\n1,998 (22%)\n\n\n\n\n    Unknown\n15\n28\n43\n\n\n\n\nsatisfaction\n\n\n\n\n\n\n&lt;0.001\n\n\n    High\n1,461 (35%)\n1,656 (33%)\n3,117 (34%)\n\n\n\n\n    Low\n1,488 (36%)\n2,015 (40%)\n3,503 (38%)\n\n\n\n\n    Medium\n1,207 (29%)\n1,398 (28%)\n2,605 (28%)\n\n\n\n\n    Unknown\n6\n3\n9\n\n\n\n\nCouple\n2,444 (59%)\n2,567 (51%)\n5,011 (54%)\n&lt;0.001\n\n\n    Unknown\n4\n9\n13\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\ncode R\ntable &lt;- my_data_frame |&gt;\n  tbl_summary(\n    include = c(  \"Knitting\" , \n                  \"Cards_games\",  \n                  \"Gambling\" , \n                  \"Cooking\" , \n                  \"DIY\"  ,\n                  \"Vegetable_garden\" , \n                  \"Ornamental_garden\",  \n                  \"Fishing_hunting\" , \n                  \"Collection\"  ,\n                  \"Vehicle_custom\", \n                  \"Making_music\"   ,\n                  \"Diary\" ,\n                  \"Writing\" ,  \n                  \"Painting\",  \n                  \"Montage\"  , \n                  \"Circus\"   ,\n                  \"Pottery\" , \n                  \"Theater\" , \n                  \"Drawing\" , \n                  \"Dancing\",  \n                  \"Photography\"  ,\n                  \"Genealogy\" , \n                  \"Science\"  ,\n                  \"None\"  ,\n                  \"No_Amateur\",\n                  \"Video_games\"  ,\n                  \"TV\" ,\n                  \"Radio\"  ,\n                  \n                  \"Museums\",  \n                  \"Internet\", \n                  \"Concert\"),\n    by = \"Sex\"\n  ) |&gt;\n  add_overall(last = TRUE) |&gt;\n  add_p()\n\ntable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\nOverall N = 9,2341\np-value2\n\n\n\n\nKnitting\n73 (1.8%)\n1,370 (27%)\n1,443 (16%)\n&lt;0.001\n\n\nCards_games\n1,899 (46%)\n2,764 (54%)\n4,663 (50%)\n&lt;0.001\n\n\nGambling\n990 (24%)\n970 (19%)\n1,960 (21%)\n&lt;0.001\n\n\nCooking\n1,685 (40%)\n3,473 (68%)\n5,158 (56%)\n&lt;0.001\n\n\nDIY\n2,667 (64%)\n2,283 (45%)\n4,950 (54%)\n&lt;0.001\n\n\nVegetable_garden\n1,335 (32%)\n1,245 (25%)\n2,580 (28%)\n&lt;0.001\n\n\nOrnamental_garden\n1,793 (43%)\n2,198 (43%)\n3,991 (43%)\n0.8\n\n\nFishing_hunting\n722 (17%)\n212 (4.2%)\n934 (10%)\n&lt;0.001\n\n\nCollection\n395 (9.5%)\n281 (5.5%)\n676 (7.3%)\n&lt;0.001\n\n\nVehicle_custom\n264 (6.3%)\n60 (1.2%)\n324 (3.5%)\n&lt;0.001\n\n\nMaking_music\n1,312 (32%)\n1,830 (36%)\n3,142 (34%)\n&lt;0.001\n\n\nDiary\n285 (6.8%)\n1,206 (24%)\n1,491 (16%)\n&lt;0.001\n\n\nWriting\n410 (9.9%)\n746 (15%)\n1,156 (13%)\n&lt;0.001\n\n\nPainting\n667 (16%)\n1,303 (26%)\n1,970 (21%)\n&lt;0.001\n\n\nMontage\n843 (20%)\n586 (12%)\n1,429 (15%)\n&lt;0.001\n\n\nCircus\n116 (2.8%)\n179 (3.5%)\n295 (3.2%)\n0.044\n\n\nPottery\n264 (6.3%)\n705 (14%)\n969 (10%)\n&lt;0.001\n\n\nTheater\n483 (12%)\n800 (16%)\n1,283 (14%)\n&lt;0.001\n\n\nDrawing\n864 (21%)\n1,285 (25%)\n2,149 (23%)\n&lt;0.001\n\n\nDancing\n410 (9.9%)\n1,782 (35%)\n2,192 (24%)\n&lt;0.001\n\n\nPhotography\n1,175 (28%)\n1,176 (23%)\n2,351 (25%)\n&lt;0.001\n\n\nGenealogy\n513 (12%)\n575 (11%)\n1,088 (12%)\n0.14\n\n\nScience\n611 (15%)\n469 (9.2%)\n1,080 (12%)\n&lt;0.001\n\n\nNone\n1,394 (33%)\n1,261 (25%)\n2,655 (29%)\n&lt;0.001\n\n\nNo_Amateur\n276 (6.6%)\n359 (7.1%)\n635 (6.9%)\n0.4\n\n\nVideo_games\n1,760 (42%)\n1,827 (36%)\n3,587 (39%)\n&lt;0.001\n\n\nTV\n3,878 (93%)\n4,806 (95%)\n8,684 (94%)\n0.001\n\n\nRadio\n3,522 (85%)\n4,186 (83%)\n7,708 (83%)\n0.007\n\n\nMuseums\n4,101 (99%)\n5,009 (99%)\n9,110 (99%)\n0.4\n\n\nInternet\n3,459 (83%)\n4,185 (83%)\n7,644 (83%)\n0.4\n\n\nConcert\n3,344 (80%)\n4,234 (83%)\n7,578 (82%)\n&lt;0.001\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\nLecture: Parmi l’ensemble des individus interrogés, 16% pratiquent le tricot (Knitting); 27% des femmes le pratiquent contre 1,8% des hommes\ncode R\npratiques_cols_1 &lt;- c( \"Knitting\" , \n                     \"Cards_games\",  \n                     \"Gambling\" , \n                     \"Cooking\" , \n                     \"DIY\"  ,\n                     \"Vegetable_garden\" , \n                     \"Fishing_hunting\" , \n                     \"Collection\"  ,\n                     \"Vehicle_custom\",\n                     \"Making_music\"   ,\n                     \"Diary\" ,\n                     \"Writing\" ,  \n                     \"Painting\",  \n                     \"Montage\"  , \n                     \"Pottery\" , \n                     \"Theater\" , \n                     \"Drawing\" , \n                     \"Dancing\",  \n                     \"Photography\"  ,\n                     \"Genealogy\" , \n                     \"Science\"  ,\n                     \"None\" ,\n                     \"Video_games\"  ,\n                    \n                     \"Concert\"\n                            )\n\n\n#MCA\n\n# Add Sex Column to the selection\ncols_of_interest_1 &lt;- c(\"Sex\", \"AGE\", pratiques_cols_1)\n\n# Build a new dataframe with these columns\ndata_pratiques &lt;- my_data_frame[, cols_of_interest_1]\ndata_pratiques$AGE &lt;- cut(data_pratiques$AGE, \n                          breaks = quantile(data_pratiques$AGE, probs = seq(0, 1, 0.25), na.rm = TRUE), \n                          include.lowest = TRUE)\nra_data &lt;- na.omit(data_pratiques)\n\ncols_to_factor &lt;- c(  \"Knitting\" , \n                      \"Cards_games\",  \n                      \"Gambling\" , \n                      \"Cooking\" , \n                      \"DIY\"  ,\n                      \"Vegetable_garden\" , \n                      \"Fishing_hunting\" , \n                      \"Collection\"  ,\n                      \"Vehicle_custom\",\n                      \"Making_music\"   ,\n                      \"Diary\" ,\n                      \"Writing\" ,  \n                      \"Painting\",  \n                      \"Montage\"  , \n                      \"Pottery\" , \n                      \"Theater\" , \n                      \"Drawing\" , \n                      \"Dancing\",  \n                      \"Photography\"  ,\n                      \"Genealogy\" , \n                      \"Science\"  ,\n                      \"None\"  ,\n                      \"Video_games\"  ,\n                      \n                      \"Concert\")\n\n# apply as.factor to these columnns\nra_data[cols_to_factor] &lt;- lapply(ra_data[cols_to_factor], as.factor)\n\n# running MCA with FactoMiner\nacm2_fm &lt;- ra_data |&gt; \n  FactoMineR::MCA(\n    ncp = Inf,\n    graph = TRUE,\n    quali.sup = 1:2\n  )\ncode R\n# Extract modality names\nmodalites_names &lt;- rownames(acm2_fm$var$coord)\n\n# Check modality names\nhead(modalites_names)\n\n\n[1] \"Knitting_0\"    \"Knitting_1\"    \"Cards_games_0\" \"Cards_games_1\"\n[5] \"Gambling_0\"    \"Gambling_1\"   \n\n\ncode R\n# Extract coordinates for dimension 2\ncoord_dim2_modalites &lt;- acm2_fm$var$coord[, 2]\n\n# Create a table associating the modalities and their coordinates in dimension 2\nmodalites_coord &lt;- data.frame(Modalite = modalites_names, Coord_Dim2 = coord_dim2_modalites)\n\n\n\n# Keep only the two necessary columns\nmodalites_coord_selected &lt;- modalites_coord[, c(\"Modalite\", \"Coord_Dim2\")]\n\nprint(modalites_coord_selected)\n\n\n                             Modalite   Coord_Dim2\nKnitting_0                 Knitting_0  0.061083540\nKnitting_1                 Knitting_1 -0.329800319\nCards_games_0           Cards_games_0 -0.191733041\nCards_games_1           Cards_games_1  0.187950189\nGambling_0                 Gambling_0 -0.172468113\nGambling_1                 Gambling_1  0.640067884\nCooking_0                   Cooking_0 -0.003343761\nCooking_1                   Cooking_1  0.002642336\nDIY_0                           DIY_0 -0.560199305\nDIY_1                           DIY_1  0.484827035\nVegetable_garden_0 Vegetable_garden_0 -0.276379719\nVegetable_garden_1 Vegetable_garden_1  0.712802577\nFishing_hunting_0   Fishing_hunting_0 -0.175132414\nFishing_hunting_1   Fishing_hunting_1  1.556315888\nCollection_0             Collection_0 -0.065206794\nCollection_1             Collection_1  0.825502582\nVehicle_custom_0     Vehicle_custom_0 -0.060085983\nVehicle_custom_1     Vehicle_custom_1  1.652364534\nMaking_music_0         Making_music_0  0.097404491\nMaking_music_1         Making_music_1 -0.188856829\nDiary_0                       Diary_0  0.099861613\nDiary_1                       Diary_1 -0.518597229\nWriting_0                   Writing_0  0.057148968\nWriting_1                   Writing_1 -0.399350660\nPainting_0                 Painting_0  0.029400939\nPainting_1                 Painting_1 -0.108410366\nMontage_0                   Montage_0 -0.091139295\nMontage_1                   Montage_1  0.497790202\nPottery_0                   Pottery_0  0.008044356\nPottery_1                   Pottery_1 -0.068613627\nTheater_0                   Theater_0  0.066669573\nTheater_1                   Theater_1 -0.413164281\nDrawing_0                   Drawing_0  0.021651695\nDrawing_1                   Drawing_1 -0.071383089\nDancing_0                   Dancing_0  0.168522075\nDancing_1                   Dancing_1 -0.541392541\nPhotography_0           Photography_0 -0.083774581\nPhotography_1           Photography_1  0.245266032\nGenealogy_0               Genealogy_0 -0.026958429\nGenealogy_1               Genealogy_1  0.201841328\nScience_0                   Science_0 -0.061028864\nScience_1                   Science_1  0.460767922\nNone_0                         None_0 -0.072250527\nNone_1                         None_1  0.179034357\nVideo_games_0           Video_games_0 -0.251059915\nVideo_games_1           Video_games_1  0.395242637\nConcert_0                   Concert_0 -0.048232041\nConcert_1                   Concert_1  0.010540018\ncode R\n# Initialize a vector to store the index of each individual\ndata_pratiques$indice_culturel &lt;- 0\n\n# Browse each individual\nfor (i in 1:nrow(data_pratiques)) {\n  \n  # Initialize individual's index to 0\n  indice_individu &lt;- 0\n  \n  # Browse each practice column (columns 3 to 27)\n  for (pratique in 3:27) {\n    \n    # Retrieve the individual's response for this practice (0 or 1)\n    reponse &lt;- data_pratiques[i, pratique]\n    \n    # If the answer is 1, add the coordinate of the corresponding modality to the index.\n    if (reponse == 1) {\n      \n      # Create the modality name (e.g. “knitting_1” or “knitting_0”)\n      nom_modalite_1 &lt;- paste0(names(data_pratiques)[pratique], \"_1\")\n      nom_modalite_0 &lt;- paste0(names(data_pratiques)[pratique], \"_0\")\n      \n      # Find the coordinate associated with the corresponding modality\n      if (nom_modalite_1 %in% modalites_coord$Modalite) {\n        indice_individu &lt;- indice_individu + modalites_coord$Coord_Dim2[modalites_coord$Modalite == nom_modalite_1]\n      }\n      if (nom_modalite_0 %in% modalites_coord$Modalite) {\n        indice_individu &lt;- indice_individu + modalites_coord$Coord_Dim2[modalites_coord$Modalite == nom_modalite_0]\n      }\n    }\n  }\n  \n  # Assign the calculated index to the individual\n  data_pratiques$indice_culturel[i] &lt;- indice_individu\n}\n####Normalisation\n\n# Calculate minimum and maximum index values\nmin_indice &lt;- min(data_pratiques$indice_culturel, na.rm = TRUE)\nmax_indice &lt;- max(data_pratiques$indice_culturel, na.rm = TRUE)\n\n# Normalize index\ndata_pratiques$indice_culturel_normalise &lt;- (data_pratiques$indice_culturel - min_indice) / (max_indice - min_indice)\n\n# Check results\n\nhead(data_pratiques[, c(\"indice_culturel\", \"indice_culturel_normalise\")])\n\n\n  indice_culturel indice_culturel_normalise\n1       3.9263677                 0.8629797\n2       0.8918710                 0.4200471\n3       0.2275676                 0.3230815\n4       0.2360965                 0.3243264\n5       0.5743836                 0.3737048\n6       0.4256581                 0.3519960\nNotre indice est donc construit de la façon suivante:\n\\[I_{1j} = \\sum_{k=1}^{Z} w_{1k} \\cdot X_{k j}\\]\nDans cette expression, \\(I_{1j}\\) désigne l’indice de l’individu \\(j\\), tandis que \\(w_{1k}\\) représente le poids associé à chaque variable culturelle \\(X_{kj}\\). La somme englobe toutes les variables culturelles \\(Z\\), ce qui nous permet de saisir l’engagement culturel global de l’individu.\ncode R\nmy_data_frame$identity&lt;-data_pratiques$indice_culturel_normalise\nmy_data_frame$indice&lt;-ra_data$indice_culturel\nggplot(my_data_frame, aes(x = identity, fill = Sex)) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) + \n  labs(title = \"Density of The Normalized Cultural Index by Sexe\",\n       x = \"Normalized Cultural Index\",\n       y = \"Density\",\n       fill = \"Sexe\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ncode R\nstat_des_indice&lt;-my_data_frame%&gt;%\n  tbl_summary(include=c(\"identity\"),by = \"Sex\",\n              statistic = list(\n            all_continuous() ~ \"{min} - {max}\"\n        )) %&gt;%\n  add_overall(last = TRUE) %&gt;%\n  add_p()\nstat_des_indice\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\nOverall N = 9,2341\np-value2\n\n\n\n\nidentity\n0.01 - 1.00\n0.00 - 0.87\n0.00 - 1.00\n&lt;0.001\n\n\n\n1 Min - Max\n\n\n2 Wilcoxon rank sum test",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mesures Continues du Genre</span>"
    ]
  },
  {
    "objectID": "en_cours.html#comparaisons-avec-des-mesures-existantes",
    "href": "en_cours.html#comparaisons-avec-des-mesures-existantes",
    "title": "3  Mesures Continues du Genre",
    "section": "3.3 Comparaisons avec des mesures existantes",
    "text": "3.3 Comparaisons avec des mesures existantes\n\n\ncode R\nmy_data_frame$identity_scale &lt;- cut(\n  my_data_frame$identity,\n  breaks = 7,  # Automatically divide into 7 slices\n  labels = c(\"Very Feminine\", \"1\", \"2\", \"3\", \"4\", \"5\", \"Very Masculine\"), \n  include.lowest = TRUE  \n)\ntable1 &lt;-\n  my_data_frame |&gt; \n  tbl_summary(include = c(identity_scale),\n  by=Sex ,)|&gt; \n    add_p()\ntable1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\np-value2\n\n\n\n\nidentity_scale\n\n\n\n\n&lt;0.001\n\n\n    Very Feminine\n6 (0.1%)\n246 (4.9%)\n\n\n\n\n    1\n631 (15%)\n2,220 (44%)\n\n\n\n\n    2\n2,274 (55%)\n2,270 (45%)\n\n\n\n\n    3\n852 (20%)\n274 (5.4%)\n\n\n\n\n    4\n324 (7.8%)\n56 (1.1%)\n\n\n\n\n    5\n61 (1.5%)\n5 (&lt;0.1%)\n\n\n\n\n    Very Masculine\n14 (0.3%)\n1 (&lt;0.1%)\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mesures Continues du Genre</span>"
    ]
  },
  {
    "objectID": "en_cours.html#répartition-de-indice-acm-par-genre",
    "href": "en_cours.html#répartition-de-indice-acm-par-genre",
    "title": "3  Mesures Continues du Genre",
    "section": "3.4 Répartition de indice ACM par genre",
    "text": "3.4 Répartition de indice ACM par genre",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mesures Continues du Genre</span>"
    ]
  },
  {
    "objectID": "en_cours.html#répartition-de-lidentity-scale-acm-par-genre",
    "href": "en_cours.html#répartition-de-lidentity-scale-acm-par-genre",
    "title": "3  Mesures Continues du Genre",
    "section": "3.5 Répartition de l’identity scale (<ACM) par genre",
    "text": "3.5 Répartition de l’identity scale (&lt;ACM) par genre",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mesures Continues du Genre</span>"
    ]
  },
  {
    "objectID": "en_cours.html#indice-alternatif-méthode-de-lasso",
    "href": "en_cours.html#indice-alternatif-méthode-de-lasso",
    "title": "3  Mesures Continues du Genre",
    "section": "3.6 Indice alternatif: Méthode de LASSO",
    "text": "3.6 Indice alternatif: Méthode de LASSO\n\n\n\n\n\n\nNote\n\n\n\nConstruction d’un indice par régression LASSO\nLa régression LASSO (Least Absolute Shrinkage and Selection Operator) est une méthode de régression pénalisée qui sélectionne automatiquement les variables les plus pertinentes en contraignant la somme des valeurs absolues des coefficients. Dans notre analyse, nous avons utilisé la régression LASSO avec validation croisée sur un ensemble d’activités culturelles pour prédire le sexe des individus (homme ou femme).\nLes variables ayant des coeffcients non nuls après régularisation ont été retenues. Un score linéaire a ensuite été calculé pour chaque individu sous la forme : \\[\n\\text{IndiceLASSO} = \\sum_{j \\in S} \\beta_j \\, x_j\n\\] où S est l’ensemble des variables sélectionnées, βj leur coefficient estimé, et xj la valeur observée de la variable pour un individu donné. Cet indice est ensuite normalisé entre 0 et 1 pour faciliter l’interprétation. Il reflète le positionnement d’un individu sur une dimension latente déterminée automatiquement par les pratiques différenciatrices selon le sexe.\n\n\n\n\ncode R\n### 1️⃣ Préparation des données ----\nlibrary(glmnet)\nlibrary(ggplot2)\n\n# Liste des variables\nvars &lt;- c(\"SEXE\", \"Knitting\", \"Cards_games\", \"Gambling\", \"Cooking\", \"DIY\",\n          \"Vegetable_garden\", \"Ornamental_garden\", \"Fishing_hunting\", \"Collection\",\n          \"Vehicle_custom\", \"Making_music\", \"Diary\", \"Writing\", \"Painting\", \"Montage\",\n          \"Circus\", \"Pottery\", \"Theater\", \"Drawing\", \"Dancing\", \"Photography\",\n          \"Genealogy\", \"Science\", \"None\", \"No_Amateur\", \"Video_games\", \"TV\",\n          \"Radio\", \"Library\", \"Museums\", \"Internet\", \"Concert\")\n\n# Sous-ensemble des variables\ndf_subset &lt;- my_data_frame[, vars]\n\n# Remplacer NA par 0 dans les variables explicatives\ndf_subset[,-1] &lt;- lapply(df_subset[,-1], function(x) { x[is.na(x)] &lt;- 0; x })\n\n# Convertir SEXE en facteur binaire\ndf_subset$SEXE &lt;- as.factor(df_subset$SEXE)\n\n# Split train / test\nset.seed(123)\nn &lt;- nrow(df_subset)\ntrain_index &lt;- sample(seq_len(n), size = floor(2*n/3))\n\ntrain_data &lt;- df_subset[train_index, ]\ntest_data  &lt;- df_subset[-train_index, ]\n\n### 2️⃣ Matrices X et y ----\nx_train &lt;- model.matrix(SEXE ~ ., data = train_data)[, -1]\ny_train &lt;- train_data$SEXE\n\nx_test &lt;- model.matrix(SEXE ~ ., data = test_data)[, -1]\ny_test &lt;- test_data$SEXE\n\n### 3️⃣ LASSO avec CV ----\ncv_lasso &lt;- cv.glmnet(x_train, y_train, alpha = 1, family = \"binomial\")\nbest_lambda &lt;- cv_lasso$lambda.min\ncat(\"Meilleur lambda :\", best_lambda, \"\\n\")\n\n\nMeilleur lambda : 0.0007031016 \n\n\ncode R\n# Coefficients non nuls\ncoef_lasso &lt;- coef(cv_lasso, s = \"lambda.min\")\ncoeffs_df &lt;- data.frame(\n  Variable = rownames(as.matrix(coef_lasso)),\n  Coefficient = as.numeric(coef_lasso)\n)\ncoeffs_nz &lt;- subset(coeffs_df, Coefficient != 0 & Variable != \"(Intercept)\")\nprint(coeffs_nz)\n\n\n            Variable Coefficient\n2           Knitting  2.98242981\n3        Cards_games  0.26392201\n4           Gambling -0.35960101\n5            Cooking  1.21424483\n6                DIY -1.03128656\n7   Vegetable_garden -0.31484191\n8  Ornamental_garden  0.32275720\n9    Fishing_hunting -1.48259504\n10        Collection -0.82958419\n11    Vehicle_custom -1.55077014\n12      Making_music -0.12868620\n13             Diary  1.38419740\n14           Writing -0.19190960\n15          Painting  0.44889901\n16           Montage -1.10040003\n17            Circus -0.07251206\n18           Pottery  0.50947384\n19           Theater -0.11880824\n20           Drawing -0.06715409\n21           Dancing  1.56074804\n22       Photography -0.37176873\n23         Genealogy -0.49266909\n24           Science -0.80041792\n25              None -0.13557802\n26        No_Amateur  0.52796323\n27       Video_games -0.17248226\n28                TV  0.43000010\n29             Radio -0.27969494\n30           Library  0.66452149\n31           Museums -0.20554024\n32          Internet  0.07508547\n33           Concert  0.03839690\n\n\ncode R\n### 4️⃣ Calcul de l'indice composite ----\nvars_kept &lt;- intersect(coeffs_nz$Variable, colnames(x_test))\nx_test_reduced &lt;- x_test[, vars_kept, drop = FALSE]\ncoef_vector &lt;- coeffs_nz$Coefficient[match(vars_kept, coeffs_nz$Variable)]\n\n# Score brut\ntest_data$score_LASSO &lt;- as.numeric(x_test_reduced %*% coef_vector)\n\n# Normalisation\nmin_s &lt;- min(test_data$score_LASSO, na.rm = TRUE)\nmax_s &lt;- max(test_data$score_LASSO, na.rm = TRUE)\ntest_data$score_normalise_LASSO &lt;- if (max_s &gt; min_s) {\n  (test_data$score_LASSO - min_s) / (max_s - min_s)\n} else { 0 }\n\n### 5️⃣ Visualisation ----\nggplot(test_data, aes(x = score_normalise_LASSO, color = SEXE, fill = SEXE)) +\n  geom_density(alpha = 0.4) +\n  labs(title = \"Densité du Score Normalisé (LASSO)\",\n       x = \"Score Normalisé\",\n       y = \"Densité\") +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ncode R\n# ✅ 1. On garde uniquement les variables présentes à la fois dans les coeffs et dans my_data_frame\nvars_kept &lt;- intersect(coeffs_nz$Variable, colnames(my_data_frame))\n\n# ✅ 2. Sous‐ensemble de la matrice de données\nx_full_reduced &lt;- my_data_frame[, vars_kept, drop = FALSE]\n\n# ✅ 3. Vecteur des coefficients dans le même ordre que les variables conservées\ncoef_vector &lt;- coeffs_nz$Coefficient[match(vars_kept, coeffs_nz$Variable)]\n\n# ✅ 4. Calcul du score brut LASSO\nmy_data_frame$score_LASSO &lt;- as.numeric(as.matrix(x_full_reduced) %*% coef_vector)\n\n# ✅ 5. Normalisation du score\nmin_s &lt;- min(my_data_frame$score_LASSO, na.rm = TRUE)\nmax_s &lt;- max(my_data_frame$score_LASSO, na.rm = TRUE)\n\nmy_data_frame$score_normalise_LASSO &lt;- if (max_s &gt; min_s) {\n  (my_data_frame$score_LASSO - min_s) / (max_s - min_s)\n} else {\n  0\n}\n\n\n\n\ncode R\npredictor_var &lt;- my_data_frame$score_LASSO\n\n# List of cultural activities\ncultural_activities &lt;- c(\n   \"Knitting\" , \n                      \"Cards_games\",  \n                      \"Gambling\" , \n                      \"Cooking\" , \n                      \"DIY\"  ,\n                      \"Vegetable_garden\" , \n                      \"Fishing_hunting\" , \n                      \"Collection\"  ,\n                      \"Vehicle_custom\",\n                      \"Making_music\"   ,\n                      \"Diary\" ,\n                      \"Writing\" ,  \n                      \"Painting\",  \n                      \"Montage\"  , \n                      \"Pottery\" , \n                      \"Theater\" , \n                      \"Drawing\" , \n                      \"Dancing\",  \n                      \"Photography\"  ,\n                      \"Genealogy\" , \n                      \"Science\"  ,\n                      \"None\"  ,\n                      \"Video_games\"  ,\n                      \"Library\"  ,\n                      \"Concert\"\n)\n\n# Initialiser un tableau vide pour les résultats\nresult_table &lt;- data.frame(Activity = character(), Accuracy = numeric(), stringsAsFactors = FALSE)\n\n# Boucle sur chaque activité culturelle\nfor (activity in cultural_activities) {\n  \n  # Créer la formule du modèle\n  model_formula &lt;- as.formula(paste(activity, \"~ score_LASSO\"))\n  \n  # Estimer le modèle Probit\n  model &lt;- glm(model_formula, data = my_data_frame, family = binomial(link = \"probit\"))\n  \n  # Prédictions\n  predicted &lt;- ifelse(predict(model, type = \"response\") &gt;= 0.5, 1, 0)\n  \n  # Calcul de l'exactitude\n  correct_predictions &lt;- sum(predicted == my_data_frame[[activity]], na.rm = TRUE)\n  total_predictions &lt;- nrow(my_data_frame)\n  accuracy &lt;- (correct_predictions / total_predictions) * 100\n  \n  # Ajouter la ligne au tableau de résultats\n  result_table[nrow(result_table) + 1, ] &lt;- list(Activity = activity, Accuracy = accuracy)\n}\n\n# Afficher le tableau final\nprint(result_table)\n\n\n           Activity Accuracy\n1          Knitting 72.73121\n2       Cards_games 50.21659\n3          Gambling 78.77410\n4           Cooking 54.02859\n5               DIY 50.77973\n6  Vegetable_garden 72.05978\n7   Fishing_hunting 89.88521\n8        Collection 92.67923\n9    Vehicle_custom 96.49123\n10     Making_music 61.72840\n11            Diary 73.85748\n12          Writing 87.48105\n13         Painting 76.96556\n14          Montage 84.13472\n15          Pottery 89.50617\n16          Theater 86.10570\n17          Drawing 76.72731\n18          Dancing 64.71735\n19      Photography 74.53974\n20        Genealogy 88.21746\n21          Science 88.30409\n22             None 71.24756\n23      Video_games 56.08620\n24          Library 15.29131\n25          Concert 82.06628\n\n\n\n\ncode R\nmy_data_frame$score_scale &lt;- cut(\n  my_data_frame$score_normalise_LASSO,\n  breaks = 7,  # Automatically divide into 7 slices\n  labels = c(\"Very Masculine\", \"1\", \"2\", \"3\", \"4\", \"5\", \"Very Feminine\"), \n  include.lowest = TRUE  \n)\ntable1 &lt;-\n  my_data_frame |&gt; \n  tbl_summary(include = c(score_scale),\n  by=Sex ,)|&gt;\n  add_p()\n    \ntable1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nMen N = 4,1621\nWomen N = 5,0721\np-value2\n\n\n\n\nscore_scale\n\n\n\n\n&lt;0.001\n\n\n    Very Masculine\n25 (2.7%)\n1 (&lt;0.1%)\n\n\n\n\n    1\n186 (20%)\n19 (1.2%)\n\n\n\n\n    2\n441 (47%)\n223 (14%)\n\n\n\n\n    3\n251 (27%)\n594 (36%)\n\n\n\n\n    4\n32 (3.4%)\n514 (31%)\n\n\n\n\n    5\n3 (0.3%)\n224 (14%)\n\n\n\n\n    Very Feminine\n1 (0.1%)\n60 (3.7%)\n\n\n\n\n    Unknown\n3,223\n3,437\n\n\n\n\n\n1 n (%)\n\n\n2 Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\ncode R\n# Proportions de 'score_scale' par genre\ntable_score_gender &lt;- table(my_data_frame$score_scale, my_data_frame$Sex)\ntable_score_gender_percent &lt;- prop.table(table_score_gender, 2) * 100  # Calcul par genre\ntable_score_gender_percent\n\n\n                \n                         Men       Women\n  Very Masculine  2.66240682  0.06116208\n  1              19.80830671  1.16207951\n  2              46.96485623 13.63914373\n  3              26.73056443 36.33027523\n  4               3.40788072 31.43730887\n  5               0.31948882 13.70030581\n  Very Feminine   0.10649627  3.66972477\n\n\ncode R\n# Proportions de 'satisfaction' par genre\ntable_satisfaction_gender &lt;- table(my_data_frame$satisfaction, my_data_frame$Sex)\ntable_satisfaction_gender_percent &lt;- prop.table(table_satisfaction_gender, 2) * 100  # Calcul par genre\ntable_satisfaction_gender_percent\n\n\n        \n              Men    Women\n  High   35.15399 32.66917\n  Low    35.80366 39.75143\n  Medium 29.04235 27.57940\n\n\n\n\ncode R\n# Visualiser la relation entre indice_normalise et score_normalise\nlibrary(ggplot2)\nggplot(my_data_frame, aes(x = identity, y = score_normalise_LASSO)) +\n  geom_point(alpha = 0.5) +\n  labs(title = \"Relation entre indice_normalise et score_normalise\", \n       x = \"Indice Normalisé\", \n       y = \"Score Normalisé\") +\n  theme_minimal() +\n  geom_smooth(method = \"lm\", col = \"red\", se = FALSE)  # Ajouter une droite de régression linéaire\n\n\n\n\n\n\n\n\n\n\n\ncode R\n# Convertir les variables en facteurs si nécessaire\nmy_data_frame$DIPLOM &lt;- as.factor(my_data_frame$DIPLOM)\nmy_data_frame$SEXE &lt;- as.factor(my_data_frame$SEXE)\nmy_data_frame$CLASSIF &lt;- as.factor(my_data_frame$CLASSIF)\nmy_data_frame$Income &lt;- as.factor(my_data_frame$Income)\nmy_data_frame$Health &lt;- as.factor(my_data_frame$Health)\nmy_data_frame$satisfaction &lt;- as.factor(my_data_frame$satisfaction)\nmy_data_frame$SITUA &lt;- as.factor(my_data_frame$SITUA)\nmy_data_frame$CS2D &lt;- as.factor(my_data_frame$CS2D)\n\n# Créer une fonction pour comparer les modèles avec 'score' et 'Sex' comme prédicteurs\ncompare_models &lt;- function(variable) {\n  # Affichage de la variable actuellement traitée\n  cat(\"Traitement de la variable :\", variable, \"\\n\")\n  \n  # Modèle avec score comme prédicteur\n  model_score &lt;- polr(as.formula(paste(variable, \"~ score_normalise_LASSO\")), data = my_data_frame, method = \"logistic\")\n  \n  # Modèle avec sexe comme prédicteur\n  model_sex &lt;- polr(as.formula(paste(variable, \"~ SEXE\")), data = my_data_frame, method = \"logistic\")\n  \n  # Comparer l'AIC des deux modèles\n  aic_score &lt;- AIC(model_score)\n  aic_sex &lt;- AIC(model_sex)\n  \n  # Comparer et retourner le meilleur modèle\n  if (aic_score &lt; aic_sex) {\n    return(data.frame(variable = variable, best_predictor = \"Score\", AIC_score = aic_score, AIC_sex = aic_sex))\n  } else {\n    return(data.frame(variable = variable, best_predictor = \"Sex\", AIC_score = aic_score, AIC_sex = aic_sex))\n  }\n}\n\n# Liste des variables d'intérêt à analyser\nvariables &lt;- c(\"DIPLOM\", \"CLASSIF\", \"SITUA\", \"satisfaction\", \"Health\", \"Income\", \"CS2D\")\n\n# Appliquer la fonction pour chaque variable d'intérêt et combiner les résultats\nresults &lt;- do.call(rbind, lapply(variables, compare_models))\n\n\nTraitement de la variable : DIPLOM \nTraitement de la variable : CLASSIF \nTraitement de la variable : SITUA \nTraitement de la variable : satisfaction \nTraitement de la variable : Health \nTraitement de la variable : Income \nTraitement de la variable : CS2D \n\n\ncode R\n# Afficher les résultats sous forme de tableau\nprint(results)\n\n\n      variable best_predictor AIC_score   AIC_sex\n1       DIPLOM          Score 11289.847 41877.259\n2      CLASSIF          Score  2397.286  9303.852\n3        SITUA          Score  7175.685 24316.900\n4 satisfaction          Score  5550.873 20141.519\n5       Health          Score  3288.556 14578.985\n6       Income          Score  4835.411 17469.113\n7         CS2D          Score  8191.713 29114.292\n\n\n\n\ncode R\n# Convertir les variables en facteurs si nécessaire\nmy_data_frame$DIPLOM &lt;- as.factor(my_data_frame$DIPLOM)\nmy_data_frame$SEXE &lt;- as.factor(my_data_frame$SEXE)\nmy_data_frame$CLASSIF &lt;- as.factor(my_data_frame$CLASSIF)\nmy_data_frame$Income &lt;- as.factor(my_data_frame$Income)\nmy_data_frame$Health &lt;- as.factor(my_data_frame$Health)\nmy_data_frame$satisfaction &lt;- as.factor(my_data_frame$satisfaction)\nmy_data_frame$SITUA &lt;- as.factor(my_data_frame$SITUA)\nmy_data_frame$CS2D &lt;- as.factor(my_data_frame$CS2D)\n\n# Créer une fonction pour comparer les modèles avec 'score' et 'Sex' comme prédicteurs\ncompare_models &lt;- function(variable) {\n  # Affichage de la variable actuellement traitée\n  cat(\"Traitement de la variable :\", variable, \"\\n\")\n  \n  # Modèle avec score comme prédicteur\n  model_score &lt;- polr(as.formula(paste(variable, \"~ score_normalise_LASSO\")), data = my_data_frame, method = \"logistic\")\n  \n  # Modèle avec sexe comme prédicteur\n  model_id &lt;- polr(as.formula(paste(variable, \"~ identity\")), data = my_data_frame, method = \"logistic\")\n  \n  # Comparer l'AIC des deux modèles\n  aic_score &lt;- AIC(model_score)\n  aic_id &lt;- AIC(model_id)\n  \n  # Comparer et retourner le meilleur modèle\n  if (aic_score &lt; aic_id) {\n    return(data.frame(variable = variable, best_predictor = \"Score\", AIC_score = aic_score, AIC_id = aic_id))\n  } else {\n    return(data.frame(variable = variable, best_predictor = \"id\", AIC_score = aic_score, AIC_id = aic_id))\n  }\n}\n\n# Liste des variables d'intérêt à analyser\nvariables &lt;- c(\"satisfaction\", \"Health\", \"Income\")\n\n# Appliquer la fonction pour chaque variable d'intérêt et combiner les résultats\nresults &lt;- do.call(rbind, lapply(variables, compare_models))\n\n\nTraitement de la variable : satisfaction \nTraitement de la variable : Health \nTraitement de la variable : Income \n\n\ncode R\n# Afficher les résultats sous forme de tableau\nprint(results)\n\n\n      variable best_predictor AIC_score   AIC_id\n1 satisfaction          Score  5550.873 20142.02\n2       Health          Score  3288.556 14580.80\n3       Income          Score  4835.411 17466.37",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mesures Continues du Genre</span>"
    ]
  },
  {
    "objectID": "en_cours.html#variables-socio-économiques-et-score-de-genre",
    "href": "en_cours.html#variables-socio-économiques-et-score-de-genre",
    "title": "3  Mesures Continues du Genre",
    "section": "3.7 Variables socio-économiques et score de genre",
    "text": "3.7 Variables socio-économiques et score de genre\n\n\ncode R\ndf_femmes &lt;- my_data_frame %&gt;% \n  filter(Sex == \"Women\")\n\n# Choix des variables explicatives\ngroup_vars &lt;- c(\"Income\", \"age_group\", \"DIPLOMA\", \"Health\")\n\n# Créer un tableau avec score_scale en colonnes et les variables explicatives en lignes\ntable_lasso_femmes_inverse &lt;- \n  df_femmes %&gt;%\n  tbl_summary(\n    by = score_scale,              # score_scale en colonnes\n    include = all_of(group_vars),  # variables explicatives en lignes\n    statistic = all_categorical() ~ \"{p}%\",\n    missing = \"no\"\n  )%&gt;%\n  add_p()\ntable_lasso_femmes_inverse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nVery Masculine N = 11\n1 N = 191\n2 N = 2231\n3 N = 5941\n4 N = 5141\n5 N = 2241\nVery Feminine N = 601\np-value\n\n\n\n\nIncome\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    High\n0%\n33%\n39%\n40%\n42%\n41%\n38%\n\n\n\n\n    Low\n0%\n28%\n28%\n23%\n24%\n26%\n30%\n\n\n\n\n    Medium\n100%\n39%\n34%\n37%\n34%\n34%\n32%\n\n\n\n\nage_group\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    [15-38[\n0%\n37%\n30%\n30%\n29%\n33%\n28%\n\n\n\n\n    [38-54[\n0%\n32%\n34%\n36%\n35%\n26%\n30%\n\n\n\n\n    [54-67[\n100%\n26%\n28%\n28%\n29%\n35%\n33%\n\n\n\n\n    [67-97[\n0%\n5.3%\n7.6%\n6.6%\n7.0%\n6.3%\n8.3%\n\n\n\n\nDIPLOMA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Bac général / technologique\n0%\n11%\n16%\n18%\n17%\n16%\n22%\n\n\n\n\n    Bac professionnel / équivalent\n0%\n16%\n6.3%\n4.2%\n4.5%\n3.6%\n3.3%\n\n\n\n\n    Bac+2 à Bac+5 (hors doctorat)\n100%\n21%\n43%\n42%\n48%\n54%\n57%\n\n\n\n\n    CAP / BEP\n0%\n16%\n16%\n15%\n14%\n9.4%\n6.7%\n\n\n\n\n    Capacité / DAEU / ESEU\n0%\n0%\n0.5%\n0.3%\n0.4%\n0.4%\n0%\n\n\n\n\n    CEP / Brevet / DNB\n0%\n16%\n11%\n14%\n13%\n12%\n10%\n\n\n\n\n    Doctorat\n0%\n0%\n2.3%\n1.0%\n1.0%\n1.8%\n1.7%\n\n\n\n\n    Sans diplôme\n0%\n21%\n5.0%\n4.7%\n2.9%\n3.6%\n0%\n\n\n\n\nHealth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Bad\n0%\n0%\n7.7%\n5.2%\n4.9%\n6.7%\n5.0%\n\n\n\n\n    Good\n100%\n84%\n77%\n79%\n77%\n75%\n70%\n\n\n\n\n    Medium\n0%\n16%\n16%\n16%\n18%\n18%\n25%\n\n\n\n\n\n1 \n\n\n\n\n\n\n\n\n\n\ncode R\ndf_hommes &lt;- my_data_frame %&gt;% \n  filter(Sex == \"Men\")\n\n# Choix des variables explicatives\ngroup_vars &lt;- c(\"Income\", \"age_group\", \"DIPLOMA\", \"Health\")\n\n# Créer un tableau avec score_scale en colonnes et les variables explicatives en lignes\ntable_lasso_hommes_inverse &lt;- \n  df_hommes %&gt;%\n  tbl_summary(\n    by = score_scale,              # score_scale en colonnes\n    include = all_of(group_vars),  # variables explicatives en lignes\n    statistic = all_categorical() ~ \"{p}%\",\n    missing = \"no\"\n  ) %&gt;%\n  add_p()\ntable_lasso_hommes_inverse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nVery Masculine N = 251\n1 N = 1861\n2 N = 4411\n3 N = 2511\n4 N = 321\n5 N = 31\nVery Feminine N = 11\np-value\n\n\n\n\nIncome\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    High\n55%\n47%\n49%\n42%\n63%\n100%\n100%\n\n\n\n\n    Low\n18%\n15%\n17%\n21%\n10%\n0%\n0%\n\n\n\n\n    Medium\n27%\n38%\n34%\n37%\n27%\n0%\n0%\n\n\n\n\nage_group\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    [15-38[\n40%\n39%\n27%\n30%\n38%\n33%\n0%\n\n\n\n\n    [38-54[\n36%\n37%\n32%\n35%\n22%\n67%\n0%\n\n\n\n\n    [54-67[\n20%\n22%\n34%\n28%\n25%\n0%\n0%\n\n\n\n\n    [67-97[\n4.0%\n3.2%\n7.5%\n6.8%\n16%\n0%\n100%\n\n\n\n\nDIPLOMA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Bac général / technologique\n8.0%\n13%\n16%\n12%\n9.4%\n33%\n0%\n\n\n\n\n    Bac professionnel / équivalent\n8.0%\n5.9%\n7.3%\n8.0%\n3.1%\n0%\n0%\n\n\n\n\n    Bac+2 à Bac+5 (hors doctorat)\n32%\n45%\n42%\n48%\n63%\n67%\n100%\n\n\n\n\n    CAP / BEP\n24%\n16%\n20%\n15%\n6.3%\n0%\n0%\n\n\n\n\n    Capacité / DAEU / ESEU\n0%\n0.5%\n0.2%\n0%\n0%\n0%\n0%\n\n\n\n\n    CEP / Brevet / DNB\n24%\n15%\n9.3%\n10%\n3.1%\n0%\n0%\n\n\n\n\n    Doctorat\n0%\n1.6%\n2.7%\n3.2%\n9.4%\n0%\n0%\n\n\n\n\n    Sans diplôme\n4.0%\n2.7%\n3.2%\n4.0%\n6.3%\n0%\n0%\n\n\n\n\nHealth\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Bad\n0%\n2.2%\n5.3%\n6.4%\n6.3%\n0%\n0%\n\n\n\n\n    Good\n88%\n85%\n82%\n76%\n81%\n100%\n100%\n\n\n\n\n    Medium\n12%\n13%\n13%\n17%\n13%\n0%\n0%\n\n\n\n\n\n1",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mesures Continues du Genre</span>"
    ]
  },
  {
    "objectID": "en_cours.html#distance-aux-normes",
    "href": "en_cours.html#distance-aux-normes",
    "title": "3  Mesures Continues du Genre",
    "section": "3.8 Distance aux normes",
    "text": "3.8 Distance aux normes\n\n\ncode R\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# S'assurer que SEXE est bien un facteur clair\nmy_data_frame$Sex &lt;- factor(my_data_frame$Sex, levels = c(\"Men\", \"Women\"))\n\n# Calcul direct du z-score par groupe (pas de jointure)\nmy_data_frame &lt;- my_data_frame %&gt;%\n  group_by(Sex) %&gt;%\n  mutate(\n    mean_gender = mean(score_normalise_LASSO, na.rm = TRUE),\n    sd_gender = sd(score_normalise_LASSO, na.rm = TRUE),\n    distance_abs = abs((score_normalise_LASSO - mean_gender) / sd_gender)\n  ) %&gt;%\n  ungroup()\n\n# Calcul des moyennes des distances par sexe\nmean_distances &lt;- my_data_frame %&gt;%\n  group_by(Sex) %&gt;%\n  summarise(\n    mean_distance = mean(distance_abs, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# Visualisation\nggplot(my_data_frame, aes(x = distance_abs, color = Sex, fill = Sex)) +\n  geom_density(alpha = 0.4) +\n  labs(\n    title = \"Density of Distance to the Norm (Score), by Sex\",\n    x = \"Distance to the Norm (Z-score)\",\n    y = \"Density\"\n  ) +\n  scale_fill_manual(values = c(\"blue\", \"pink\")) +\n  scale_color_manual(values = c(\"blue\", \"pink\")) +\n  theme_minimal() +\n  geom_vline(\n    data = mean_distances,\n    aes(xintercept = mean_distance, color = Sex),\n    linetype = \"dashed\"\n  ) +\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\ncode R\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# Convertir DIPLOM et Sex en facteurs\nmy_data_frame$DIPLOM &lt;- as.factor(my_data_frame$DIPLOM)\nmy_data_frame$Sex &lt;- as.factor(my_data_frame$Sex)\n\n# Création des quartiles de distance_abs\nmy_data_frame &lt;- my_data_frame %&gt;%\n  mutate(quartile_distance = cut(distance_abs, \n                                 breaks = quantile(distance_abs, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE), \n                                 include.lowest = TRUE, \n                                 labels = c(\"Q1\", \"Q2\", \"Q3\", \"Q4\")))  # Étiquettes des quartiles\n\n# Créer un tableau de proportions\ndf_proportions &lt;- my_data_frame %&gt;%\n  group_by(Sex, DIPLOM, quartile_distance) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  group_by(Sex, DIPLOM) %&gt;%\n  mutate(proportion = count / sum(count))  # Calcul de la proportion\n\n# Ajouter une colonne avec les descriptions des diplômes\ndiplome_labels &lt;- c(\n  \"Vous n'avez jamais été à l'école ou vous l'avez quittée avant la fin du primaire\",\n  \"Aucun diplôme et scolarité interrompue à la fin du primaire ou avant la fin du collège\",\n  \"Aucun diplôme et scolarité jusqu'à la fin du collège et au-delà\",\n  \"CEP\",\n  \"BEPC, brevet élémentaire, brevet des collèges, DNB\",\n  \"CAP, BEP ou diplôme équivalent\",\n  \"Baccalauréat général ou technologique, brevet supérieur\",\n  \"Capacité en droit, DAEU, ESEU\",\n  \"Baccalauréat professionnel, brevet professionnel, de technicien ou d'enseignement, diplôme équivalent\",\n  \"BTS, DUT, DEUST, diplôme de la santé ou social de niveau Bac+2 ou diplôme équivalent\",\n  \"Licence, licence pro, maîtrise ou autre diplôme de niveau Bac+3 ou 4 ou diplôme équivalent\",\n  \"Master, DEA, DESS, diplôme grande école de niveau Bac+5, doctorat de santé\",\n  \"Doctorat de recherche (hors santé)\",\n  \"NSP\",\n  \"REF\"\n)\n\n# Ajouter les libellés des diplômes à df_proportions\ndf_proportions &lt;- df_proportions %&gt;%\n  mutate(DIPLOM_label = diplome_labels[as.numeric(DIPLOM)])\n\n# Séparer les données en deux sous-ensembles (Hommes et Femmes)\ndf_men &lt;- df_proportions %&gt;% filter(Sex == \"Men\")\ndf_women &lt;- df_proportions %&gt;% filter(Sex == \"Women\")\n\n# Graphique pour les hommes\nfig_men &lt;- plot_ly(df_men, \n                   x = ~DIPLOM, \n                   y = ~proportion, \n                   color = ~quartile_distance, \n                   type = \"bar\",\n                   text = ~paste(DIPLOM_label, \"&lt;br&gt;\", round(proportion*100, 1), \"%\"),  # Affichage du libellé et proportion\n                   textposition = \"inside\") %&gt;%\n  layout(title = \"Proportion de score_scale par niveau de diplôme (Hommes)\",\n         xaxis = list(title = \"Niveau de diplôme\"),\n         yaxis = list(title = \"Proportion\", tickformat = \"%\"),\n         barmode = \"stack\",  # Empilement des barres\n         hovermode = \"closest\")  # Afficher les informations les plus proches du survol\n\n# Graphique pour les femmes\nfig_women &lt;- plot_ly(df_women, \n                     x = ~DIPLOM, \n                     y = ~proportion, \n                     color = ~quartile_distance, \n                     type = \"bar\",\n                     text = ~paste(DIPLOM_label, \"&lt;br&gt;\", round(proportion*100, 1), \"%\"),  # Affichage du libellé et proportion\n                     textposition = \"inside\") %&gt;%\n  layout(title = \"Proportion de score_scale par niveau de diplôme (Femmes)\",\n         xaxis = list(title = \"Niveau de diplôme\"),\n         yaxis = list(title = \"Proportion\", tickformat = \"%\"),\n         barmode = \"stack\",  # Empilement des barres\n         hovermode = \"closest\")  # Afficher les informations les plus proches du survol\n\n# Afficher les deux graphiques séparés\nfig_men\n\n\n\n\n\n\ncode R\nfig_women",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mesures Continues du Genre</span>"
    ]
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "4  Conclusion",
    "section": "",
    "text": "Nous avons pu voir l’intérêt que portent les économistes aux questions d’identité.\nChamp récent de la discipline, l’économie de l’identité propose plusieurs directions de recherche: d’un point de vue théorique, elle cherche à introduire dans des modèles économiques traditionnels la variable identité, afin d’enrichir notre compréhension des phénomènes économiques.\nParce qu’elle influence les choix, l’identité doit être prise en compte dans une discipline où ces choix individuels sont un objet d’études.\nL’identité influence les préférences individuelles et notamment la coopération (à la participation de biens publics par exemple), elle agit sur les performances individuelles et influence les actions des individus.\nCes derniers font face à des arbitrages entre leurs caractéristiques intrinsèques et les normes sociales (ou prescriptions) qui prévalent dans leur environnement.\nIl y a donc là de nombreux questionnements sur les dynamiques de formation de l’identité et ses répercussions socio-économiques .\nD’un point de vue empirique, l’une des premières difficultés auxquelles fait face le chercheur est la mesure de cette variable aux contours flous et aux multiples dimensions.\nL’emploi de variables catégorielles (comme la variable binaire homme/femme) contient des limites lorsque l’objectif est de mesurer la distance aux normes d’identité.\nLes données continues provenant de déclarations et positionnements individuels sur une échelle graduée (par exemple, dans quelle mesure je me perçois comme très masculin/féminin), répond en partie aux problèmes évoqués précédemment, cependant, les données sont rares et ces déclarations subjectives peuvent souffrir de biais de désirabilité.\nUne autre possibilité est de construire des indices continus basés sur des dimensions de l’identité identifiée a priori ou non.\nEn outre, une mesure continue semble plus appropriée mais pose des questions quand à sa construction, à l’existence de données adéquates, à la reproductibilité des indicateurs pour des comparaisons dans le temps et l’espace.\nNous avons proposé une mesure continue du genre basée sur les pratiques culturelles des français. Notre indice converge vers les indices d’échelle dans la mesure où il indique que la plupart des individus ne sont pas totalement conformes, que peu d’individus s’écartent des normes (entendues dans notre étude comme un comportement moyen), que ces divergences ou convergences sont reliées aux caractéristiques socio-économiques des individus.\nEnfin, nous avons proposé d’étudier empiriquement la relation entre identité et satisfaction. Celle-ci n’apparaît pas comme évidente et est sensible au niveau de revenus des individus ainsi qu’à leur sexe biologique.\nLes premiers résultats observés indiquent une relation négative entre distance aux normes de genre et satisfaction individuelle pour les femmes, cette relation n’est pas aussi prononcée chez les hommes.\nLa satisfaction (en termes de disposition de son temps libre) semble décroître avec l’augmentation de la distance aux normes chez les individus aux revenus les plus faibles.\nCes résultats sont préliminaires et méritent d’être approfondis.\nLa notion d’identité est donc complexe, mouvante, relative. Sa mesure pose des difficultés de comparaisons dans le temps et l’espace. L’enquête sur les pratiques culturelles des français a été répétée dans le temps et cela pourrait être une piste de recherche d’étudier l’évolution de cet indice d’identité de genre à travers le temps, pour une vision dynamique de cette mesure.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Economie et Identité: quelles intéractions?",
    "section": "",
    "text": "1.1 Utilité et Identité\nL’économie de l’identité est un courant récent de la discipline.\nLes travaux fondateurs d’ Akerlof et Kranton (George A. Akerlof and Kranton (2000b) ) ont mis en lumière la nécessité d’intégrer dans les modèles économiques traditionnels cette notion fondamentale qu’est l’identité.\nPour un économiste, le concept d’utilité est central. Il s’agit d’une mesure de la satisfaction individuelle.\nUn individu, par exemple un consommateur, réalise ses choix en fonction du niveau de satisfaction qu’il peut retirer. C’est son objectif, modélisé sous forme de fonction.\nDans les modèles traditionnels, l’utilité dépend de quelques variables objectives, qui ont l’intérêt d’être mesurables.\nPar exemple, pour un consommateur, \\(U=F(x,y)\\) , où \\(x\\) et \\(y\\) sont les quantités de biens consommées.\nL’apport d’Akerlof et Kranton, est d’indiquer que les choix des individus sont influencés par le sentiment qu’ils ont d’eux même, leur identité.\nEnrichir les modèles traditionnels de cette nouvelle variable permettrait de mieux comprendre ce qui parfois échappe à la théorie classique.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Economie et Identité: quelles intéractions?</span>"
    ]
  },
  {
    "objectID": "intro.html#modèle-avec-identité",
    "href": "intro.html#modèle-avec-identité",
    "title": "1  Economie et Identité: quelles intéractions?",
    "section": "1.2 Modèle avec Identité",
    "text": "1.2 Modèle avec Identité\nReprenons ici le modèle proposé par Akerlof et Kranton,\nla fonction d’utilité d’un individu est la suivante:\n\\(U_j = U_j(a_j, a_j I_j)\\)\noù :\n\n\\(a_j\\) représente les actions de l’individu \\(j\\)\n\\(a_j\\) \\(I_j\\) capture les intéractions entre les actions de \\(j\\) et son identité \\(I_j\\)\n\nCette fonction d’identite \\(I_j\\) dépend elle même de plusieurs facteurs:\n\\(I_j = I_j(a_j, a_{-j}, c_j, E_j, P)\\)\noù :\n\n\\(a_j\\) représente les actions de l’individu \\(j\\),\n\\(a_{-j}\\) repésente les actions des autres individus,\n\\(c_j\\) est la catégorie sociale à laquelle appartien \\(j\\),\n\\(E_j\\) sont les caractéristiques données de \\(j\\),\n\\(P\\) sont les prescriptions (ou normes sociales) associées à la catégorie \\(c_j\\).\n\nCe modèle formalise cette tension qui peut exister pour les individus entre se conformer ou non aux normes de sa catégorie sociale assignée, en fonction de la distance qui peut exister entre ses propres caractéristiques et les prescriptions assignées.\nIl suppose aussi l’existence possible de sanctions de la part des pairs si les normes ne sont pas suivies (moqueries, mise à l’écart ou même violence)\nPar exemple, dans leur papier (George A. Akerlof and Kranton, n.d.) complètent les théories traditionnelles de l’économie de l’éducation en expliquant le plus ou moins grand investissement scolaire des étudiants en fonction de leurs caractéristiques identitaires (les sportifs, les intellos et les rebelles)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Economie et Identité: quelles intéractions?</span>"
    ]
  },
  {
    "objectID": "intro.html#identité-et-choix-des-individus",
    "href": "intro.html#identité-et-choix-des-individus",
    "title": "1  Economie et Identité: quelles intéractions?",
    "section": "1.3 Identité et choix des individus",
    "text": "1.3 Identité et choix des individus\nL’économie étudie comment les agents font leur choix (de consommation, de production…), ces choix dépendent de l’identité des individus.\nEn effet, le sens que l’on a de soi, influence nos décisions, et ces décisions influencent notre identité en retour.\nDans un premier temps, la catégorie sociale à laquelle j’appartiens peut influencer mes préférences (Chen and Li (2009)) ,mes comportements pro-sociaux (Charness, Cobo-Reyes, and Jiménez (2014)) et donc mes décisions.\nDans un second temps, l’individu arbitre entre ses propres caractéristiques et les prescriptions de sa catégorie sociale (ou les prescriptions supposées).\nVais-je me conformer à ce qui est attendu? Mes propres caractéristiques sont-elles plus ou moins proches des normes en vigueur? Si je ne me conforme pas, quelle sera la réaction de mes pairs?\nCet arbitrage et cette possibilité pour autrui de répondre à mes actions a été représenté sous forme d’arbre de décision par George A. Akerlof and Kranton (2000a)\n\n\n\n\n\nCette friction entre adhérer ou non aux normes de ma catégorie sociale a conduit la recherche des économistes de l’identité vers les questions de conflits inter-groupes (Austen-Smith and Fryer (2005), Chakravarty et al. (2015), Fryer, Fryer, and Torelli (2010), Bénabou and Tirole (2004).)\nOn s’interroge sur les normes, l’adhésion ou non à ces dernières et le rôle que peuvent jouer les politiques publiques sur ces prescriptions.\nMais l’identité joue également un rôle fondamental sur les performances individuelles.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Economie et Identité: quelles intéractions?</span>"
    ]
  },
  {
    "objectID": "intro.html#identité-et-performances",
    "href": "intro.html#identité-et-performances",
    "title": "1  Economie et Identité: quelles intéractions?",
    "section": "1.4 Identité et Performances",
    "text": "1.4 Identité et Performances\nDans une étude particulièrement intéressante, Shih, Pittinsky, and Trahan (2006) ont montré comment l’activation d’une identité particulière, ou tout du moins comment les stéréotypes associés à cette identité, pouvaient avoir un impact sur les performances individuelles.\nEn réalisant une étude auprès d’étudiantes asiatiques aux Etats Unis, les chercheurs ont proposé l’expérience suivante:\nUn questionnaire était fourni aux participantes avant de réaliser un test de mathématiques.\nUne partie des participantes répondaient à un questionnaire dont les questions portaient sur leur identité asiatique, pour les autres participantes le questionnaire activait leur identité féminine, un groupe de contrôle était également implémanté.\nCe simple questionnaire en préambule a eu des effets notables sur les performances aux tests de mathématiques réalisés ensuite, puisque en moyenne, les étudiantes dont l’identité asiatique avait été mise en évidence performaient significativement mieux aux tests de mathématiques que leurs homologues dont l’identité féminine avait été activée.\nCette étude plaide donc pour la nécessité de s’interroger sur la notion d’identité, dès lors que cette variable peut significativement avoir des répercussions sur les résultats socio-économiques des individus.\nCependant, les critiques apportées à ce nouveau courant sont notamment que ce concept fondamental d’identité est trop flou, comment intégrer dans les modèles ou bien encore dans les études empiriques cette dimension si polymorphe?\nLa question de la mesure de l’identité se pose alors…\n\n\n\n\nAkerlof, George A., and R. Kranton. 2000a. “Economics and Identity.” Quarterly Journal of Economics 115: 715–53. https://doi.org/10.1162/003355300554881.\n\n\nAkerlof, George A., and Rachel E. Kranton. 2000b. “Economics and Identity.” The Quarterly Journal of Economics 115 (3): 715–53. https://www.jstor.org/stable/2586894.\n\n\nAkerlof, George A, and Rachel E Kranton. n.d. “Identity and Schooling: Some Lessons for the Economics of Education,” 36.\n\n\nAusten-Smith, D., and Roland G. Fryer. 2005. “An Economic Analysis of ‘Acting White’.” Quarterly Journal of Economics 120: 551–83. https://doi.org/10.1093/QJE/120.2.551.\n\n\nBénabou, R., and J. Tirole. 2004. “Incentives and Prosocial Behavior.” IZA Institute of Labor Economics Discussion Paper Series null: null. https://doi.org/10.2139/ssrn.639043.\n\n\nChakravarty, Surajeet, Miguel A. Fonseca, S. Ghosh, and S. Marjit. 2015. “Religious Fragmentation , Social Identity and Cooperation : Evidence from an Artefactual Field Experiment in India ∗.” https://doi.org/10.1016/j.euroecorev.2015.12.006.\n\n\nCharness, G., Ramón Cobo-Reyes, and Natalia Jiménez. 2014. “Identities, Selection, and Contributions in a Public-Goods Game.” Games Econ. Behav. 87: 322–38. https://doi.org/10.1016/J.GEB.2014.05.002.\n\n\nChen, Yan, and S. Li. 2009. “Group Identity and Social Preferences.” The American Economic Review 99: 431–57. https://doi.org/10.1257/AER.99.1.431.\n\n\nFryer, Roland G., Roland G. Fryer, and Paul Torelli. 2010. “An Empirical Analysis of ‘Acting White’.” Journal of Public Economics 94: 380–96. https://doi.org/10.1016/J.JPUBECO.2009.10.011.\n\n\nShih, Margaret, Todd L. Pittinsky, and Amy Trahan. 2006. “Domain-Specific Effects of Stereotypes on Performance.” Self and Identity 5 (1): 1–14. https://doi.org/10.1080/15298860500338534.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Economie et Identité: quelles intéractions?</span>"
    ]
  },
  {
    "objectID": "mesure.html",
    "href": "mesure.html",
    "title": "2  Mesurer l’identité: une impossibilité?",
    "section": "",
    "text": "2.1 L’approche dichotomique: Hommes/Femmes\nSi nous acceptons l’idée qu’il est pertinent pour les économistes d’intégrer dans leurs modèles la variable Identité , alors la question de sa mesure est fondamentale.\nL’identité est multiple, dans ce document, nous nous focalisons sur l’identité de genre des individus.\nUne des raisons pour lesquelles nous portons notre attention sur cette dimension est que l’identité de genre nous semble être l’une des plus importantes dans la construction individuelle.\nAvant même la naissance d’un enfant, la question fondamentale de son sexe biologique est omniprésente: c’est une fille ou un garçon?\nL’organisation de la société est centrée autour de cette distinction genrée, les inégalités persistantes entre hommes et femmes justifient également notre intérêt pour cette dimension de l’identité.\nLes questionnements sur la non-binarité influencent également notre réflexion, peut-on proposer une mesure de l’identité de genre qui tienne compte d’un continuum entre deux pôles (masculin et féminin), permettant ainsi de mesurer une distance à ces extremum?\nNous verrons donc comment est abordée la mesure de l’identité de genre dans la littérature existante, puis proposerons une mesure continue de cette identité, avec une approche empirique basée sur les pratiques culturelles (genrées) des français.\nLorsque la dimension du genre veut être prise en compte dans les études économiques, bien souvent on se réfère au sexe biologique des individus: homme/femme.\nCette approche binaire est notamment liée à la commodité des données.\nEn effet, dans les bases de données, cette information figure presque toujours, elle permet d’étudier et de mettre en évidence des différences, souvent des inégalités, entre les deux sexes biologiques.\nCependant, certains individus ne se retrouvent pas dans cette dichotomie, alors la possibilité d’intégrer une troisième option dans les questionnaires est parfois envisagée.\nMais là encore, une approche catégorielle peine à saisir ce qui nous semble fondamental dans une étude empirique de l’identité: la distance aux Prescriptions ou normes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Mesurer l'identité: une impossibilité?</span>"
    ]
  },
  {
    "objectID": "mesure.html#les-approches-de-mesure-continue",
    "href": "mesure.html#les-approches-de-mesure-continue",
    "title": "2  Mesurer l’identité: une impossibilité?",
    "section": "2.2 Les approches de mesure continue",
    "text": "2.2 Les approches de mesure continue\nAfin de prendre en compte la diversité des positions individuelles le long d’un axe Masculin/Féminin, des études ont proposé une approche continue de mesure de l’identité de genre. Nous les distinguons de la façon suivante: certaines études reposent sur un positionnement individuel de l’individu sur une échelle de mesure.\nD’autres études proposent la construction d’indices composites pour mesurer la dimension continue du genre.\n\n2.2.1 Des échelles de mesure\nLes travaux proposant des mesures continues du genre basées sur des échelles de gradation reposent sur les déclarations individuelles des enquêtés, qui se positionnent le long d’un ou plusieurs axes.\nPar exemple, @magliozzi_scaling_2016 propose aux enquêtés de se situer sur plusieurs échelles (comment je me perçois: de très masculin à pas du tout masculin, et de très féminin à pas du tout féminin), mais aussi comment les autres me perçoivent.\n\n\n\n\n\nEn France, l’étude Virage a permis de poser des questions similaires, les résultats de cette étude ont fait l’objet d’un papier rédigé par @trachman_tres_2022.\nIl est intéressant de voir qu’en effet, l’identité de genre est faite de nuances, la plupart des individus interrogés ne s’identifient pas aux pôles extrêmes de leur sexe biologique (23,3% des femmes interrogées s’identifient comme très féminines; 30,6% des hommes interrogés s’identifient comme très masculins).\nPeu d’individus dévient des normes (1% des femmes interrogées se disent très masculines, 2,3% des hommes interrogés se disent très féminins.)\nCes résultats mettent en lumière la complexité de l’identité de genre, et peut-être confirment la nécessité d’aller au delà du binaire dans les mesures proposées.\nCette approche par gradation a l’avantage de demander directement aux individus le sentiment qu’ils ont d’eux même, et donc de tendre vers la définition même de l’identité.\nL’inconvénient repose sur l’accessibilité des données, elle suppose d’intégrer ces questions dans les questionnaires et ces informations sont donc peu disponibles mais liées à des enquêtes bien spécifiques.\nUn autre biais est peut-être également que cette approche repose sur la subjectivité des personnes interrogées, elles peuvent être influencées par le biais de la désirabilité sociale (je réponds avec la peur d’être jugé si je réponds mal, je réponds ce qui me semble être conforme aux normes).\nIl peut donc être intéressant de combiner ces approches avec d’autres mesures plus indirectes mais, peut-être, moins subjectives.\n\n\n2.2.2 Les indices composites\nDans la famille des mesures continues de l’identité de genre, certains chercheurs ont construit leurs propres indices de mesures continues.\n\n2.2.2.1 Avec Définitions a priori des dimensions genrées\nParmi les indices composites, un outil très utilisé est le Bem Sex Role Inventory (@bem_measurement_1974).\nIl s’agit de créer un indice composite à partir de réponses des enquêtés qui se classent par rapport à différents items.\nCes items sont identifiés au préalable comme plutôt masculin (ex:agressif), plutôt féminin (ex: lunatique) ou neutres (ex: naïf).\nCette approche permet de capturer une distance aux normes, cependant elle suppose de définir au préalable ce qui relève de l’ordre du masculin et du féminin.\nUne approche originale récente d’économistes a combiné les 2 approches vues jusqu’ici (échelle de gradation et indice composite), il s’agit des travaux de @brenoe_continuous_2022.\n\n\n2.2.2.2 Sans Définitions a priori\nUne autre approche consiste à construire un indice composite à partir de variables identifiées statistiquement comme genrées, c’est à dire déduire de l’analyse statistique les pratiques ou comportements plus ou moins masculins ou féminins (dans la mesure où ils sont statistiquement significativement différenciés selon les sexes biologiques) et de construire un indice en fonction des poids que représentent chaque variable sur un axe masculin/féminin.\nCette approche est notamment utilisée en médecine (@pelletier_composite_2015.)\nNous avons suivi cette dernière approche pour notre étude, en nous référant notamment aux travaux de @cipriani qui offrent un guide pratique pour la réalisation d’un tel indicateur.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Mesurer l'identité: une impossibilité?</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Akerlof, George A., and R. Kranton. 2000a. “Economics and\nIdentity.” Quarterly Journal of Economics 115: 715–53.\nhttps://doi.org/10.1162/003355300554881.\n\n\nAkerlof, George A., and Rachel E. Kranton. 2000b. “Economics and\nIdentity.” The Quarterly Journal of Economics 115 (3):\n715–53. https://www.jstor.org/stable/2586894.\n\n\nAkerlof, George A, and Rachel E Kranton. n.d. “Identity and\nSchooling: Some Lessons for the Economics of Education,” 36.\n\n\nAusten-Smith, D., and Roland G. Fryer. 2005. “An Economic Analysis\nof ‘Acting White’.” Quarterly Journal of\nEconomics 120: 551–83. https://doi.org/10.1093/QJE/120.2.551.\n\n\nBem, Sandra L. 1974. “The Measurement of Psychological\nAndrogyny.” Journal of Consulting and Clinical\nPsychology 42 (2): 155–62. https://doi.org/10.1037/h0036215.\n\n\nBénabou, R., and J. Tirole. 2004. “Incentives and Prosocial\nBehavior.” IZA Institute of Labor Economics\nDiscussion Paper Series null: null. https://doi.org/10.2139/ssrn.639043.\n\n\nBrenøe, Anne Ardila, Lea Heursen, Eva Ranehill, and Roberto A. Weber.\n2022. “Continuous Gender Identity and Economics.”\nAEA Papers and Proceedings 112 (May): 573–77. https://doi.org/10.1257/pandp.20221083.\n\n\nChakravarty, Surajeet, Miguel A. Fonseca, S. Ghosh, and S. Marjit. 2015.\n“Religious Fragmentation , Social Identity and Cooperation :\nEvidence from an Artefactual Field Experiment in India ∗.” https://doi.org/10.1016/j.euroecorev.2015.12.006.\n\n\nCharness, G., Ramón Cobo-Reyes, and Natalia Jiménez. 2014.\n“Identities, Selection, and Contributions in a Public-Goods\nGame.” Games Econ. Behav. 87: 322–38. https://doi.org/10.1016/J.GEB.2014.05.002.\n\n\nChen, Yan, and S. Li. 2009. “Group Identity and Social\nPreferences.” The American Economic Review 99: 431–57.\nhttps://doi.org/10.1257/AER.99.1.431.\n\n\nCipriani, Enzo, Charles-Edouard Giguère, Eugénie Samson, Ioana Cotocea,\nand Robert-Paul Juster. n.d. “Comment mesurer indirectement le\ngenre en recherche sur les humains?” 21.\n\n\nFryer, Roland G., Roland G. Fryer, and Paul Torelli. 2010. “An\nEmpirical Analysis of ‘Acting White’.” Journal\nof Public Economics 94: 380–96. https://doi.org/10.1016/J.JPUBECO.2009.10.011.\n\n\nMagliozzi, Devon, Aliya Saperstein, and Laurel Westbrook. 2016.\n“Scaling up: Representing Gender Diversity in Survey\nResearch.” Socius 2 (January): 2378023116664352. https://doi.org/10.1177/2378023116664352.\n\n\nPelletier, Roxanne, Blaine Ditto, and Louise Pilote. 2015. “A\nComposite Measure of Gender and Its Association with Risk Factors in\nPatients with Premature Acute Coronary Syndrome.”\nPsychosomatic Medicine 77 (5): 517–26. https://doi.org/10.1097/PSY.0000000000000186.\n\n\nShih, Margaret, Todd L. Pittinsky, and Amy Trahan. 2006.\n“Domain-Specific Effects of Stereotypes on Performance.”\nSelf and Identity 5 (1): 1–14. https://doi.org/10.1080/15298860500338534.\n\n\nTrachman, Mathieu. 2022. “Très masculin, pas très féminine. Les\nvariations sociales du genre:” Population & Sociétés\nN° 605 (10): 1–4. https://doi.org/10.3917/popsoc.605.0001.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "en_cours.html#présentation-des-données",
    "href": "en_cours.html#présentation-des-données",
    "title": "3  Mesures Continues du Genre",
    "section": "",
    "text": "Encadré Technique 1: Détails de la méthode ACM\n\n\n\nL’ACM permet d’explorer les relations entre plusieurs variables qualitatives en projetant les individus et les modalités dans un espace de faible dimension. Elle est souvent utilisée pour analyser des questionnaires et des tableaux de contingence complexes.\nPrincipaux résultats d’une ACM\n\nInertie totale\n\nMesure la dispersion des données et est donnée par :\n\\(I_{\\text{total}} = \\frac{q}{q-1} \\sum_{k} \\lambda_k\\)\noù \\(\\lambda_k\\) sont les valeurs propres et \\(q\\) est le nombre total de modalités.\n\nValeurs propres \\(\\lambda_k\\)\n\nElles indiquent la variance expliquée par chaque axe factoriel. Plus une valeur propre est élevée, plus l’axe correspondant est important dans l’analyse.\n\nRapports de corrélation \\(\\eta^2\\)\n\nLe rapport de corrélation \\(\\eta^2\\) mesure la liaison entre une variable et un axe factoriel :\n\\(\\eta^2 = \\frac{\\sum_{i} f_i d_{i,k}^2}{\\sum_{i} f_i d_{i}^2}\\)\noù $f_i $ est la fréquence de l’individu/modalité $i $, et \\(d_{i,k}\\)est sa distance à l’axe \\(k\\) .\n\nCoordonnées des individus et modalités\n\nElles sont obtenues à partir des vecteurs propres et permettent la représentation graphique des données :\n\\(C_{i,k} = \\frac{v_{i,k}}{\\sqrt{\\lambda_k}}\\)\noù \\(v_{i,k}\\) est le vecteur propre associé à l’axe \\(k\\).\n\nCos² (Qualité de représentation)\n\nIndique dans quelle mesure un point est bien représenté sur un axe donné. Une valeur proche de **1** signifie que la projection sur cet axe est pertinente.\n\nContributions\n\nElles mesurent l’importance d’une modalité ou d’un individu dans la construction d’un axe. Plus une contribution est élevée, plus l’élément joue un rôle important dans l’interprétation de l’axe.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mesures Continues du Genre</span>"
    ]
  },
  {
    "objectID": "en_cours.html#précision-de-lindice-accuracy",
    "href": "en_cours.html#précision-de-lindice-accuracy",
    "title": "3  Mesures Continues du Genre",
    "section": "3.2 Précision de l’indice (Accuracy)",
    "text": "3.2 Précision de l’indice (Accuracy)\n\n\ncode R\npredictor_var &lt;- my_data_frame$identity\n\n# List of cultural activities\ncultural_activities &lt;- c(\n   \"Knitting\" , \n                      \"Cards_games\",  \n                      \"Gambling\" , \n                      \"Cooking\" , \n                      \"DIY\"  ,\n                      \"Vegetable_garden\" , \n                      \"Fishing_hunting\" , \n                      \"Collection\"  ,\n                      \"Vehicle_custom\",\n                      \"Making_music\"   ,\n                      \"Diary\" ,\n                      \"Writing\" ,  \n                      \"Painting\",  \n                      \"Montage\"  , \n                      \"Pottery\" , \n                      \"Theater\" , \n                      \"Drawing\" , \n                      \"Dancing\",  \n                      \"Photography\"  ,\n                      \"Genealogy\" , \n                      \"Science\"  ,\n                      \"None\"  ,\n                      \"Video_games\"  ,\n                      \"Library\"  ,\n                      \"Concert\"\n)\n\n# Initialiser un tableau vide pour les résultats\nresult_table &lt;- data.frame(Activity = character(), Accuracy = numeric(), stringsAsFactors = FALSE)\n\n# Boucle sur chaque activité culturelle\nfor (activity in cultural_activities) {\n  \n  # Créer la formule du modèle\n  model_formula &lt;- as.formula(paste(activity, \"~ identity\"))\n  \n  # Estimer le modèle Probit\n  model &lt;- glm(model_formula, data = my_data_frame, family = binomial(link = \"probit\"))\n  \n  # Prédictions\n  predicted &lt;- ifelse(predict(model, type = \"response\") &gt;= 0.5, 1, 0)\n  \n  # Calcul de l'exactitude\n  correct_predictions &lt;- sum(predicted == my_data_frame[[activity]], na.rm = TRUE)\n  total_predictions &lt;- nrow(my_data_frame)\n  accuracy &lt;- (correct_predictions / total_predictions) * 100\n  \n  # Ajouter la ligne au tableau de résultats\n  result_table[nrow(result_table) + 1, ] &lt;- list(Activity = activity, Accuracy = accuracy)\n}\n\n# Afficher le tableau final\nprint(result_table)\n\n\n           Activity Accuracy\n1          Knitting 84.40546\n2       Cards_games 50.49816\n3          Gambling 79.21811\n4           Cooking 56.15118\n5               DIY 52.83734\n6  Vegetable_garden 72.55794\n7   Fishing_hunting 93.40481\n8        Collection 92.49513\n9    Vehicle_custom 97.04353\n10     Making_music 66.36344\n11            Diary 84.96859\n12          Writing 87.48105\n13         Painting 78.66580\n14          Montage 84.41629\n15          Pottery 89.50617\n16          Theater 86.10570\n17          Drawing 76.72731\n18          Dancing 79.33723\n19      Photography 74.53974\n20        Genealogy 88.21746\n21          Science 88.32575\n22             None 70.14295\n23      Video_games 61.93416\n24          Library 16.60169\n25          Concert 82.06628",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mesures Continues du Genre</span>"
    ]
  },
  {
    "objectID": "en_cours.html#variables-socio-éco-et-influence-sur-le-score-de-genre",
    "href": "en_cours.html#variables-socio-éco-et-influence-sur-le-score-de-genre",
    "title": "3  Mesures Continues du Genre",
    "section": "3.9 Variables Socio-éco et influence sur le score de Genre",
    "text": "3.9 Variables Socio-éco et influence sur le score de Genre\n\n\ncode R\nanova = aov(score_LASSO ~ DIPLOMA+SITUA_lab+Income+age_group, data=my_data_frame)\nsummary(anova)\n\n\n              Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nDIPLOMA        7    127   18.14   3.628 0.000677 ***\nSITUA_lab      7    150   21.50   4.300 9.78e-05 ***\nIncome         2     95   47.36   9.471 8.02e-05 ***\nage_group      3     17    5.55   1.110 0.343547    \nResiduals   2247  11235    5.00                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n6967 observations effacées parce que manquantes\n\n\n\n\ncode R\n# Installer les packages si nécessaire\n# install.packages(\"plotly\")\n# install.packages(\"dplyr\")\n\nlibrary(plotly)\nlibrary(dplyr)\n\n# -----------------------------\n# 1️⃣ ANOVA multi-facteurs\n# -----------------------------\nanova_model &lt;- aov(score_LASSO ~ DIPLOMA + SITUA_lab + Income + age_group, data = my_data_frame)\nsummary(anova_model)\n\n\n              Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nDIPLOMA        7    127   18.14   3.628 0.000677 ***\nSITUA_lab      7    150   21.50   4.300 9.78e-05 ***\nIncome         2     95   47.36   9.471 8.02e-05 ***\nage_group      3     17    5.55   1.110 0.343547    \nResiduals   2247  11235    5.00                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n6967 observations effacées parce que manquantes\n\n\ncode R\n# -----------------------------\n# 2️⃣ Moyennes par catégorie\n# -----------------------------\ncategorical_vars &lt;- c(\"DIPLOMA\", \"SITUA_lab\", \"Income\", \"age_group\")\nmean_tables &lt;- list()\n\nfor (var in categorical_vars) {\n  mean_tables[[var]] &lt;- my_data_frame %&gt;%\n    group_by(.data[[var]]) %&gt;%\n    summarise(mean_score = mean(score_LASSO, na.rm = TRUE)) %&gt;%\n    arrange(desc(mean_score))\n  \n  cat(\"\\nMoyennes pour\", var, \":\\n\")\n  print(mean_tables[[var]])\n}\n\n\n\nMoyennes pour DIPLOMA :\n# A tibble: 9 × 2\n  DIPLOMA                        mean_score\n  &lt;chr&gt;                               &lt;dbl&gt;\n1 Capacité / DAEU / ESEU              1.80 \n2 Bac+2 à Bac+5 (hors doctorat)       1.67 \n3 Bac général / technologique         1.60 \n4 CEP / Brevet / DNB                  1.45 \n5 Doctorat                            1.23 \n6 Sans diplôme                        1.17 \n7 CAP / BEP                           1.07 \n8 Bac professionnel / équivalent      0.970\n9 &lt;NA&gt;                                0.727\n\nMoyennes pour SITUA_lab :\n# A tibble: 10 × 2\n   SITUA_lab                                               mean_score\n   &lt;chr&gt;                                                        &lt;dbl&gt;\n 1 Femme ou homme au foyer                                      2.12 \n 2 Autre situation d'inactivité                                 1.87 \n 3 Chômeur (inscrit ou non à Pôle Emploi)                       1.85 \n 4 Retraité ou retiré des affaires ou en préretraite            1.59 \n 5 Inactif ou inactive pour cause d'invalidité                  1.54 \n 6 Occupe un emploi                                             1.43 \n 7 Etudiant, élève, en formation ou stagiaire non rémunéré      1.20 \n 8 Apprenti sous contrat ou stagiaire rémunéré                 -0.137\n 9 NSP                                                         -1.88 \n10 REF                                                        NaN    \n\nMoyennes pour Income :\n# A tibble: 4 × 2\n  Income mean_score\n  &lt;fct&gt;       &lt;dbl&gt;\n1 Low          1.73\n2 &lt;NA&gt;         1.48\n3 High         1.40\n4 Medium       1.40\n\nMoyennes pour age_group :\n# A tibble: 4 × 2\n  age_group mean_score\n  &lt;fct&gt;          &lt;dbl&gt;\n1 [67-97[         1.69\n2 [54-67[         1.58\n3 [15-38[         1.41\n4 [38-54[         1.39",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mesures Continues du Genre</span>"
    ]
  }
]